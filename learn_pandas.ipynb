{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "227941c8",
   "metadata": {},
   "source": [
    "## 十分钟入门 Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bea394b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn_pandas\n",
    "#\n",
    "# created by LuYF-Lemon-love on November 27, 2022\n",
    "#\n",
    "# 参考文档链接: https://www.pypandas.cn/docs/getting_started/10min.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb145d61",
   "metadata": {},
   "source": [
    "## 导入 Pandas 与 NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "109b75e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff8147f",
   "metadata": {},
   "source": [
    "## 生成对象"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5854d77",
   "metadata": {},
   "source": [
    "用**列表**生成 **Series** 时，**Pandas** 默认**自动生成整数索引**："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2996a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    3.0\n",
       "2    5.0\n",
       "3    NaN\n",
       "4    6.0\n",
       "5    8.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series([1, 3, 5, np.nan, 6, 8])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7b82a1",
   "metadata": {},
   "source": [
    "用含**日期时间索引**与**标签 (列名)**的 **NumPy 数组**生成 **DataFrame** ："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03e01002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function date_range in module pandas.core.indexes.datetimes:\n",
      "\n",
      "date_range(start=None, end=None, periods=None, freq=None, tz=None, normalize: 'bool' = False, name: 'Hashable' = None, closed=None, **kwargs) -> 'DatetimeIndex'\n",
      "    Return a fixed frequency DatetimeIndex.\n",
      "    \n",
      "    Returns the range of equally spaced time points (where the difference between any\n",
      "    two adjacent points is specified by the given frequency) such that they all\n",
      "    satisfy `start <[=] x <[=] end`, where the first one and the last one are, resp.,\n",
      "    the first and last time points in that range that fall on the boundary of ``freq``\n",
      "    (if given as a frequency string) or that are valid for ``freq`` (if given as a\n",
      "    :class:`pandas.tseries.offsets.DateOffset`). (If exactly one of ``start``,\n",
      "    ``end``, or ``freq`` is *not* specified, this missing parameter can be computed\n",
      "    given ``periods``, the number of timesteps in the range. See the note below.)\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    start : str or datetime-like, optional\n",
      "        Left bound for generating dates.\n",
      "    end : str or datetime-like, optional\n",
      "        Right bound for generating dates.\n",
      "    periods : int, optional\n",
      "        Number of periods to generate.\n",
      "    freq : str or DateOffset, default 'D'\n",
      "        Frequency strings can have multiples, e.g. '5H'. See\n",
      "        :ref:`here <timeseries.offset_aliases>` for a list of\n",
      "        frequency aliases.\n",
      "    tz : str or tzinfo, optional\n",
      "        Time zone name for returning localized DatetimeIndex, for example\n",
      "        'Asia/Hong_Kong'. By default, the resulting DatetimeIndex is\n",
      "        timezone-naive.\n",
      "    normalize : bool, default False\n",
      "        Normalize start/end dates to midnight before generating date range.\n",
      "    name : str, default None\n",
      "        Name of the resulting DatetimeIndex.\n",
      "    closed : {None, 'left', 'right'}, optional\n",
      "        Make the interval closed with respect to the given frequency to\n",
      "        the 'left', 'right', or both sides (None, the default).\n",
      "    **kwargs\n",
      "        For compatibility. Has no effect on the result.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    rng : DatetimeIndex\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    DatetimeIndex : An immutable container for datetimes.\n",
      "    timedelta_range : Return a fixed frequency TimedeltaIndex.\n",
      "    period_range : Return a fixed frequency PeriodIndex.\n",
      "    interval_range : Return a fixed frequency IntervalIndex.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Of the four parameters ``start``, ``end``, ``periods``, and ``freq``,\n",
      "    exactly three must be specified. If ``freq`` is omitted, the resulting\n",
      "    ``DatetimeIndex`` will have ``periods`` linearly spaced elements between\n",
      "    ``start`` and ``end`` (closed on both sides).\n",
      "    \n",
      "    To learn more about the frequency strings, please see `this link\n",
      "    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    **Specifying the values**\n",
      "    \n",
      "    The next four examples generate the same `DatetimeIndex`, but vary\n",
      "    the combination of `start`, `end` and `periods`.\n",
      "    \n",
      "    Specify `start` and `end`, with the default daily frequency.\n",
      "    \n",
      "    >>> pd.date_range(start='1/1/2018', end='1/08/2018')\n",
      "    DatetimeIndex(['2018-01-01', '2018-01-02', '2018-01-03', '2018-01-04',\n",
      "                   '2018-01-05', '2018-01-06', '2018-01-07', '2018-01-08'],\n",
      "                  dtype='datetime64[ns]', freq='D')\n",
      "    \n",
      "    Specify `start` and `periods`, the number of periods (days).\n",
      "    \n",
      "    >>> pd.date_range(start='1/1/2018', periods=8)\n",
      "    DatetimeIndex(['2018-01-01', '2018-01-02', '2018-01-03', '2018-01-04',\n",
      "                   '2018-01-05', '2018-01-06', '2018-01-07', '2018-01-08'],\n",
      "                  dtype='datetime64[ns]', freq='D')\n",
      "    \n",
      "    Specify `end` and `periods`, the number of periods (days).\n",
      "    \n",
      "    >>> pd.date_range(end='1/1/2018', periods=8)\n",
      "    DatetimeIndex(['2017-12-25', '2017-12-26', '2017-12-27', '2017-12-28',\n",
      "                   '2017-12-29', '2017-12-30', '2017-12-31', '2018-01-01'],\n",
      "                  dtype='datetime64[ns]', freq='D')\n",
      "    \n",
      "    Specify `start`, `end`, and `periods`; the frequency is generated\n",
      "    automatically (linearly spaced).\n",
      "    \n",
      "    >>> pd.date_range(start='2018-04-24', end='2018-04-27', periods=3)\n",
      "    DatetimeIndex(['2018-04-24 00:00:00', '2018-04-25 12:00:00',\n",
      "                   '2018-04-27 00:00:00'],\n",
      "                  dtype='datetime64[ns]', freq=None)\n",
      "    \n",
      "    **Other Parameters**\n",
      "    \n",
      "    Changed the `freq` (frequency) to ``'M'`` (month end frequency).\n",
      "    \n",
      "    >>> pd.date_range(start='1/1/2018', periods=5, freq='M')\n",
      "    DatetimeIndex(['2018-01-31', '2018-02-28', '2018-03-31', '2018-04-30',\n",
      "                   '2018-05-31'],\n",
      "                  dtype='datetime64[ns]', freq='M')\n",
      "    \n",
      "    Multiples are allowed\n",
      "    \n",
      "    >>> pd.date_range(start='1/1/2018', periods=5, freq='3M')\n",
      "    DatetimeIndex(['2018-01-31', '2018-04-30', '2018-07-31', '2018-10-31',\n",
      "                   '2019-01-31'],\n",
      "                  dtype='datetime64[ns]', freq='3M')\n",
      "    \n",
      "    `freq` can also be specified as an Offset object.\n",
      "    \n",
      "    >>> pd.date_range(start='1/1/2018', periods=5, freq=pd.offsets.MonthEnd(3))\n",
      "    DatetimeIndex(['2018-01-31', '2018-04-30', '2018-07-31', '2018-10-31',\n",
      "                   '2019-01-31'],\n",
      "                  dtype='datetime64[ns]', freq='3M')\n",
      "    \n",
      "    Specify `tz` to set the timezone.\n",
      "    \n",
      "    >>> pd.date_range(start='1/1/2018', periods=5, tz='Asia/Tokyo')\n",
      "    DatetimeIndex(['2018-01-01 00:00:00+09:00', '2018-01-02 00:00:00+09:00',\n",
      "                   '2018-01-03 00:00:00+09:00', '2018-01-04 00:00:00+09:00',\n",
      "                   '2018-01-05 00:00:00+09:00'],\n",
      "                  dtype='datetime64[ns, Asia/Tokyo]', freq='D')\n",
      "    \n",
      "    `closed` controls whether to include `start` and `end` that are on the\n",
      "    boundary. The default includes boundary points on either end.\n",
      "    \n",
      "    >>> pd.date_range(start='2017-01-01', end='2017-01-04', closed=None)\n",
      "    DatetimeIndex(['2017-01-01', '2017-01-02', '2017-01-03', '2017-01-04'],\n",
      "                  dtype='datetime64[ns]', freq='D')\n",
      "    \n",
      "    Use ``closed='left'`` to exclude `end` if it falls on the boundary.\n",
      "    \n",
      "    >>> pd.date_range(start='2017-01-01', end='2017-01-04', closed='left')\n",
      "    DatetimeIndex(['2017-01-01', '2017-01-02', '2017-01-03'],\n",
      "                  dtype='datetime64[ns]', freq='D')\n",
      "    \n",
      "    Use ``closed='right'`` to exclude `start` if it falls on the boundary.\n",
      "    \n",
      "    >>> pd.date_range(start='2017-01-01', end='2017-01-04', closed='right')\n",
      "    DatetimeIndex(['2017-01-02', '2017-01-03', '2017-01-04'],\n",
      "                  dtype='datetime64[ns]', freq='D')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.date_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9974c972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2013-01-01', '2013-01-02', '2013-01-03', '2013-01-04',\n",
       "               '2013-01-05', '2013-01-06'],\n",
       "              dtype='datetime64[ns]', freq='D')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = pd.date_range('20130101', periods=6)\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fa34187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>0.478640</td>\n",
       "      <td>0.400149</td>\n",
       "      <td>0.523567</td>\n",
       "      <td>0.266236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>-0.107001</td>\n",
       "      <td>-0.540959</td>\n",
       "      <td>0.366554</td>\n",
       "      <td>-0.800809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>0.520048</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>-1.019059</td>\n",
       "      <td>-0.728874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>-0.407414</td>\n",
       "      <td>1.032829</td>\n",
       "      <td>0.287981</td>\n",
       "      <td>-1.614230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>0.274511</td>\n",
       "      <td>0.155498</td>\n",
       "      <td>1.271314</td>\n",
       "      <td>0.991062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-06</th>\n",
       "      <td>1.242259</td>\n",
       "      <td>0.025517</td>\n",
       "      <td>2.056000</td>\n",
       "      <td>-0.882241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2013-01-01  0.478640  0.400149  0.523567  0.266236\n",
       "2013-01-02 -0.107001 -0.540959  0.366554 -0.800809\n",
       "2013-01-03  0.520048  0.000538 -1.019059 -0.728874\n",
       "2013-01-04 -0.407414  1.032829  0.287981 -1.614230\n",
       "2013-01-05  0.274511  0.155498  1.271314  0.991062\n",
       "2013-01-06  1.242259  0.025517  2.056000 -0.882241"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(6, 4), index=dates, columns=list('ABCD'))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb6f264",
   "metadata": {},
   "source": [
    "用 **Series** **字典**对象生成 **DataFrame**："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "defa51df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A          B    C  D      E    F\n",
       "0  1.0 2013-01-02  1.0  3   test  foo\n",
       "1  1.0 2013-01-02  1.0  3  train  foo\n",
       "2  1.0 2013-01-02  1.0  3   test  foo\n",
       "3  1.0 2013-01-02  1.0  3  train  foo"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame({'A': 1.,\n",
    "                    'B': pd.Timestamp('20130102'),\n",
    "                    'C': pd.Series(1, index=list(range(4)), dtype='float32'),\n",
    "                    'D': np.array([3] * 4, dtype='int32'),\n",
    "                    'E': pd.Categorical([\"test\", \"train\", \"test\", \"train\"]),\n",
    "                    'F': 'foo'})\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f694e45",
   "metadata": {},
   "source": [
    "**DataFrame** 的**列**有**不同数据类型**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2d6b2ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A           float64\n",
       "B    datetime64[ns]\n",
       "C           float32\n",
       "D             int32\n",
       "E          category\n",
       "F            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2794f64",
   "metadata": {},
   "source": [
    "**IPython** 支持 **tab** 键**自动补全列名与公共属性**。列 **A**、**B**、**C**、**D** 和 **E** 都可以**自动补全**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "191bcb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.<TAB>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1468f28e",
   "metadata": {},
   "source": [
    "## 查看数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ec8e8e",
   "metadata": {},
   "source": [
    "查看 **DataFrame** **头部**和**尾部**数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2a55afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>0.478640</td>\n",
       "      <td>0.400149</td>\n",
       "      <td>0.523567</td>\n",
       "      <td>0.266236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>-0.107001</td>\n",
       "      <td>-0.540959</td>\n",
       "      <td>0.366554</td>\n",
       "      <td>-0.800809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>0.520048</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>-1.019059</td>\n",
       "      <td>-0.728874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>-0.407414</td>\n",
       "      <td>1.032829</td>\n",
       "      <td>0.287981</td>\n",
       "      <td>-1.614230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>0.274511</td>\n",
       "      <td>0.155498</td>\n",
       "      <td>1.271314</td>\n",
       "      <td>0.991062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2013-01-01  0.478640  0.400149  0.523567  0.266236\n",
       "2013-01-02 -0.107001 -0.540959  0.366554 -0.800809\n",
       "2013-01-03  0.520048  0.000538 -1.019059 -0.728874\n",
       "2013-01-04 -0.407414  1.032829  0.287981 -1.614230\n",
       "2013-01-05  0.274511  0.155498  1.271314  0.991062"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e49e18e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>-0.407414</td>\n",
       "      <td>1.032829</td>\n",
       "      <td>0.287981</td>\n",
       "      <td>-1.614230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>0.274511</td>\n",
       "      <td>0.155498</td>\n",
       "      <td>1.271314</td>\n",
       "      <td>0.991062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-06</th>\n",
       "      <td>1.242259</td>\n",
       "      <td>0.025517</td>\n",
       "      <td>2.056000</td>\n",
       "      <td>-0.882241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2013-01-04 -0.407414  1.032829  0.287981 -1.614230\n",
       "2013-01-05  0.274511  0.155498  1.271314  0.991062\n",
       "2013-01-06  1.242259  0.025517  2.056000 -0.882241"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65095466",
   "metadata": {},
   "source": [
    "显示**索引**与**列名**："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86c202b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2013-01-01', '2013-01-02', '2013-01-03', '2013-01-04',\n",
       "               '2013-01-05', '2013-01-06'],\n",
       "              dtype='datetime64[ns]', freq='D')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e11587e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['A', 'B', 'C', 'D'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c4ef84",
   "metadata": {},
   "source": [
    "**DataFrame.to_numpy()** 输出底层数据的 **NumPy** 对象。注意，**DataFrame** 的列由**多种数据类型**组成时，该操作**耗费系统资源较大**，这也是 **Pandas** 和 **NumPy** 的本质区别：**NumPy 数组只有一种数据类型，DataFrame 每列的数据类型各不相同**。调用 **DataFrame.to_numpy()** 时，**Pandas** 查找**支持 DataFrame 里所有数据类型**的 **NumPy 数据类型**。还有一种数据类型是 **object**，可以把 **DataFrame** 列里的值强制转换为 **Python** 对象。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b5170b",
   "metadata": {},
   "source": [
    "下面的 **df** 这个 **DataFrame** 里的值都是**浮点数**，**DataFrame.to_numpy()** 的**操作会很快**，而且**不复制数据**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a56d60c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.78640182e-01,  4.00148714e-01,  5.23566924e-01,\n",
       "         2.66236197e-01],\n",
       "       [-1.07001077e-01, -5.40959398e-01,  3.66553946e-01,\n",
       "        -8.00808986e-01],\n",
       "       [ 5.20047516e-01,  5.38268244e-04, -1.01905896e+00,\n",
       "        -7.28873697e-01],\n",
       "       [-4.07413561e-01,  1.03282870e+00,  2.87980842e-01,\n",
       "        -1.61423049e+00],\n",
       "       [ 2.74510576e-01,  1.55497835e-01,  1.27131374e+00,\n",
       "         9.91062103e-01],\n",
       "       [ 1.24225883e+00,  2.55168029e-02,  2.05600008e+00,\n",
       "        -8.82240557e-01]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf6e121",
   "metadata": {},
   "source": [
    "**df2** 这个 **DataFrame** 包含了**多种类型**，**DataFrame.to_numpy()** 操作会**耗费较多资源**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13092986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0, Timestamp('2013-01-02 00:00:00'), 1.0, 3, 'test', 'foo'],\n",
       "       [1.0, Timestamp('2013-01-02 00:00:00'), 1.0, 3, 'train', 'foo'],\n",
       "       [1.0, Timestamp('2013-01-02 00:00:00'), 1.0, 3, 'test', 'foo'],\n",
       "       [1.0, Timestamp('2013-01-02 00:00:00'), 1.0, 3, 'train', 'foo']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980732ac",
   "metadata": {},
   "source": [
    ">**DataFrame.to_numpy()** 的**输出**不包含**行索引**和**列标签**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94e83c5",
   "metadata": {},
   "source": [
    "**describe()** 可以**快速查看数据的统计摘要**："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca448695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.333507</td>\n",
       "      <td>0.178928</td>\n",
       "      <td>0.581059</td>\n",
       "      <td>-0.461476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.570646</td>\n",
       "      <td>0.520044</td>\n",
       "      <td>1.034166</td>\n",
       "      <td>0.930802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.407414</td>\n",
       "      <td>-0.540959</td>\n",
       "      <td>-1.019059</td>\n",
       "      <td>-1.614230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.011623</td>\n",
       "      <td>0.006783</td>\n",
       "      <td>0.307624</td>\n",
       "      <td>-0.861883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.376575</td>\n",
       "      <td>0.090507</td>\n",
       "      <td>0.445060</td>\n",
       "      <td>-0.764841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.509696</td>\n",
       "      <td>0.338986</td>\n",
       "      <td>1.084377</td>\n",
       "      <td>0.017459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.242259</td>\n",
       "      <td>1.032829</td>\n",
       "      <td>2.056000</td>\n",
       "      <td>0.991062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              A         B         C         D\n",
       "count  6.000000  6.000000  6.000000  6.000000\n",
       "mean   0.333507  0.178928  0.581059 -0.461476\n",
       "std    0.570646  0.520044  1.034166  0.930802\n",
       "min   -0.407414 -0.540959 -1.019059 -1.614230\n",
       "25%   -0.011623  0.006783  0.307624 -0.861883\n",
       "50%    0.376575  0.090507  0.445060 -0.764841\n",
       "75%    0.509696  0.338986  1.084377  0.017459\n",
       "max    1.242259  1.032829  2.056000  0.991062"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438dd7e2",
   "metadata": {},
   "source": [
    "转置数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbf2e347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2013-01-01</th>\n",
       "      <th>2013-01-02</th>\n",
       "      <th>2013-01-03</th>\n",
       "      <th>2013-01-04</th>\n",
       "      <th>2013-01-05</th>\n",
       "      <th>2013-01-06</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>0.478640</td>\n",
       "      <td>-0.107001</td>\n",
       "      <td>0.520048</td>\n",
       "      <td>-0.407414</td>\n",
       "      <td>0.274511</td>\n",
       "      <td>1.242259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.400149</td>\n",
       "      <td>-0.540959</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>1.032829</td>\n",
       "      <td>0.155498</td>\n",
       "      <td>0.025517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0.523567</td>\n",
       "      <td>0.366554</td>\n",
       "      <td>-1.019059</td>\n",
       "      <td>0.287981</td>\n",
       "      <td>1.271314</td>\n",
       "      <td>2.056000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>0.266236</td>\n",
       "      <td>-0.800809</td>\n",
       "      <td>-0.728874</td>\n",
       "      <td>-1.614230</td>\n",
       "      <td>0.991062</td>\n",
       "      <td>-0.882241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   2013-01-01  2013-01-02  2013-01-03  2013-01-04  2013-01-05  2013-01-06\n",
       "A    0.478640   -0.107001    0.520048   -0.407414    0.274511    1.242259\n",
       "B    0.400149   -0.540959    0.000538    1.032829    0.155498    0.025517\n",
       "C    0.523567    0.366554   -1.019059    0.287981    1.271314    2.056000\n",
       "D    0.266236   -0.800809   -0.728874   -1.614230    0.991062   -0.882241"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b657da",
   "metadata": {},
   "source": [
    "按轴排序："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c8d99e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method sort_index in module pandas.core.frame:\n",
      "\n",
      "sort_index(axis: 'Axis' = 0, level: 'Level | None' = None, ascending: 'bool | int | Sequence[bool | int]' = True, inplace: 'bool' = False, kind: 'str' = 'quicksort', na_position: 'str' = 'last', sort_remaining: 'bool' = True, ignore_index: 'bool' = False, key: 'IndexKeyFunc' = None) method of pandas.core.frame.DataFrame instance\n",
      "    Sort object by labels (along an axis).\n",
      "    \n",
      "    Returns a new DataFrame sorted by label if `inplace` argument is\n",
      "    ``False``, otherwise updates the original DataFrame and returns None.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "        The axis along which to sort.  The value 0 identifies the rows,\n",
      "        and 1 identifies the columns.\n",
      "    level : int or level name or list of ints or list of level names\n",
      "        If not None, sort on values in specified index level(s).\n",
      "    ascending : bool or list-like of bools, default True\n",
      "        Sort ascending vs. descending. When the index is a MultiIndex the\n",
      "        sort direction can be controlled for each level individually.\n",
      "    inplace : bool, default False\n",
      "        If True, perform operation in-place.\n",
      "    kind : {'quicksort', 'mergesort', 'heapsort', 'stable'}, default 'quicksort'\n",
      "        Choice of sorting algorithm. See also :func:`numpy.sort` for more\n",
      "        information. `mergesort` and `stable` are the only stable algorithms. For\n",
      "        DataFrames, this option is only applied when sorting on a single\n",
      "        column or label.\n",
      "    na_position : {'first', 'last'}, default 'last'\n",
      "        Puts NaNs at the beginning if `first`; `last` puts NaNs at the end.\n",
      "        Not implemented for MultiIndex.\n",
      "    sort_remaining : bool, default True\n",
      "        If True and sorting by level and index is multilevel, sort by other\n",
      "        levels too (in order) after sorting by specified level.\n",
      "    ignore_index : bool, default False\n",
      "        If True, the resulting axis will be labeled 0, 1, …, n - 1.\n",
      "    \n",
      "        .. versionadded:: 1.0.0\n",
      "    \n",
      "    key : callable, optional\n",
      "        If not None, apply the key function to the index values\n",
      "        before sorting. This is similar to the `key` argument in the\n",
      "        builtin :meth:`sorted` function, with the notable difference that\n",
      "        this `key` function should be *vectorized*. It should expect an\n",
      "        ``Index`` and return an ``Index`` of the same shape. For MultiIndex\n",
      "        inputs, the key is applied *per level*.\n",
      "    \n",
      "        .. versionadded:: 1.1.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame or None\n",
      "        The original DataFrame sorted by the labels or None if ``inplace=True``.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    Series.sort_index : Sort Series by the index.\n",
      "    DataFrame.sort_values : Sort DataFrame by the value.\n",
      "    Series.sort_values : Sort Series by the value.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = pd.DataFrame([1, 2, 3, 4, 5], index=[100, 29, 234, 1, 150],\n",
      "    ...                   columns=['A'])\n",
      "    >>> df.sort_index()\n",
      "         A\n",
      "    1    4\n",
      "    29   2\n",
      "    100  1\n",
      "    150  5\n",
      "    234  3\n",
      "    \n",
      "    By default, it sorts in ascending order, to sort in descending order,\n",
      "    use ``ascending=False``\n",
      "    \n",
      "    >>> df.sort_index(ascending=False)\n",
      "         A\n",
      "    234  3\n",
      "    150  5\n",
      "    100  1\n",
      "    29   2\n",
      "    1    4\n",
      "    \n",
      "    A key function can be specified which is applied to the index before\n",
      "    sorting. For a ``MultiIndex`` this is applied to each level separately.\n",
      "    \n",
      "    >>> df = pd.DataFrame({\"a\": [1, 2, 3, 4]}, index=['A', 'b', 'C', 'd'])\n",
      "    >>> df.sort_index(key=lambda x: x.str.lower())\n",
      "       a\n",
      "    A  1\n",
      "    b  2\n",
      "    C  3\n",
      "    d  4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(df.sort_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3698a741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D</th>\n",
       "      <th>C</th>\n",
       "      <th>B</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>0.266236</td>\n",
       "      <td>0.523567</td>\n",
       "      <td>0.400149</td>\n",
       "      <td>0.478640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>-0.800809</td>\n",
       "      <td>0.366554</td>\n",
       "      <td>-0.540959</td>\n",
       "      <td>-0.107001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>-0.728874</td>\n",
       "      <td>-1.019059</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.520048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>-1.614230</td>\n",
       "      <td>0.287981</td>\n",
       "      <td>1.032829</td>\n",
       "      <td>-0.407414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>0.991062</td>\n",
       "      <td>1.271314</td>\n",
       "      <td>0.155498</td>\n",
       "      <td>0.274511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-06</th>\n",
       "      <td>-0.882241</td>\n",
       "      <td>2.056000</td>\n",
       "      <td>0.025517</td>\n",
       "      <td>1.242259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   D         C         B         A\n",
       "2013-01-01  0.266236  0.523567  0.400149  0.478640\n",
       "2013-01-02 -0.800809  0.366554 -0.540959 -0.107001\n",
       "2013-01-03 -0.728874 -1.019059  0.000538  0.520048\n",
       "2013-01-04 -1.614230  0.287981  1.032829 -0.407414\n",
       "2013-01-05  0.991062  1.271314  0.155498  0.274511\n",
       "2013-01-06 -0.882241  2.056000  0.025517  1.242259"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_index(axis=1, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9efbda9",
   "metadata": {},
   "source": [
    "按值排序："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e928229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method sort_values in module pandas.core.frame:\n",
      "\n",
      "sort_values(by, axis: 'Axis' = 0, ascending=True, inplace: 'bool' = False, kind: 'str' = 'quicksort', na_position: 'str' = 'last', ignore_index: 'bool' = False, key: 'ValueKeyFunc' = None) method of pandas.core.frame.DataFrame instance\n",
      "    Sort by the values along either axis.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "            by : str or list of str\n",
      "                Name or list of names to sort by.\n",
      "    \n",
      "                - if `axis` is 0 or `'index'` then `by` may contain index\n",
      "                  levels and/or column labels.\n",
      "                - if `axis` is 1 or `'columns'` then `by` may contain column\n",
      "                  levels and/or index labels.\n",
      "    axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "         Axis to be sorted.\n",
      "    ascending : bool or list of bool, default True\n",
      "         Sort ascending vs. descending. Specify list for multiple sort\n",
      "         orders.  If this is a list of bools, must match the length of\n",
      "         the by.\n",
      "    inplace : bool, default False\n",
      "         If True, perform operation in-place.\n",
      "    kind : {'quicksort', 'mergesort', 'heapsort', 'stable'}, default 'quicksort'\n",
      "         Choice of sorting algorithm. See also :func:`numpy.sort` for more\n",
      "         information. `mergesort` and `stable` are the only stable algorithms. For\n",
      "         DataFrames, this option is only applied when sorting on a single\n",
      "         column or label.\n",
      "    na_position : {'first', 'last'}, default 'last'\n",
      "         Puts NaNs at the beginning if `first`; `last` puts NaNs at the\n",
      "         end.\n",
      "    ignore_index : bool, default False\n",
      "         If True, the resulting axis will be labeled 0, 1, …, n - 1.\n",
      "    \n",
      "         .. versionadded:: 1.0.0\n",
      "    \n",
      "    key : callable, optional\n",
      "        Apply the key function to the values\n",
      "        before sorting. This is similar to the `key` argument in the\n",
      "        builtin :meth:`sorted` function, with the notable difference that\n",
      "        this `key` function should be *vectorized*. It should expect a\n",
      "        ``Series`` and return a Series with the same shape as the input.\n",
      "        It will be applied to each column in `by` independently.\n",
      "    \n",
      "        .. versionadded:: 1.1.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame or None\n",
      "        DataFrame with sorted values or None if ``inplace=True``.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.sort_index : Sort a DataFrame by the index.\n",
      "    Series.sort_values : Similar method for a Series.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = pd.DataFrame({\n",
      "    ...     'col1': ['A', 'A', 'B', np.nan, 'D', 'C'],\n",
      "    ...     'col2': [2, 1, 9, 8, 7, 4],\n",
      "    ...     'col3': [0, 1, 9, 4, 2, 3],\n",
      "    ...     'col4': ['a', 'B', 'c', 'D', 'e', 'F']\n",
      "    ... })\n",
      "    >>> df\n",
      "      col1  col2  col3 col4\n",
      "    0    A     2     0    a\n",
      "    1    A     1     1    B\n",
      "    2    B     9     9    c\n",
      "    3  NaN     8     4    D\n",
      "    4    D     7     2    e\n",
      "    5    C     4     3    F\n",
      "    \n",
      "    Sort by col1\n",
      "    \n",
      "    >>> df.sort_values(by=['col1'])\n",
      "      col1  col2  col3 col4\n",
      "    0    A     2     0    a\n",
      "    1    A     1     1    B\n",
      "    2    B     9     9    c\n",
      "    5    C     4     3    F\n",
      "    4    D     7     2    e\n",
      "    3  NaN     8     4    D\n",
      "    \n",
      "    Sort by multiple columns\n",
      "    \n",
      "    >>> df.sort_values(by=['col1', 'col2'])\n",
      "      col1  col2  col3 col4\n",
      "    1    A     1     1    B\n",
      "    0    A     2     0    a\n",
      "    2    B     9     9    c\n",
      "    5    C     4     3    F\n",
      "    4    D     7     2    e\n",
      "    3  NaN     8     4    D\n",
      "    \n",
      "    Sort Descending\n",
      "    \n",
      "    >>> df.sort_values(by='col1', ascending=False)\n",
      "      col1  col2  col3 col4\n",
      "    4    D     7     2    e\n",
      "    5    C     4     3    F\n",
      "    2    B     9     9    c\n",
      "    0    A     2     0    a\n",
      "    1    A     1     1    B\n",
      "    3  NaN     8     4    D\n",
      "    \n",
      "    Putting NAs first\n",
      "    \n",
      "    >>> df.sort_values(by='col1', ascending=False, na_position='first')\n",
      "      col1  col2  col3 col4\n",
      "    3  NaN     8     4    D\n",
      "    4    D     7     2    e\n",
      "    5    C     4     3    F\n",
      "    2    B     9     9    c\n",
      "    0    A     2     0    a\n",
      "    1    A     1     1    B\n",
      "    \n",
      "    Sorting with a key function\n",
      "    \n",
      "    >>> df.sort_values(by='col4', key=lambda col: col.str.lower())\n",
      "       col1  col2  col3 col4\n",
      "    0    A     2     0    a\n",
      "    1    A     1     1    B\n",
      "    2    B     9     9    c\n",
      "    3  NaN     8     4    D\n",
      "    4    D     7     2    e\n",
      "    5    C     4     3    F\n",
      "    \n",
      "    Natural sort with the key argument,\n",
      "    using the `natsort <https://github.com/SethMMorton/natsort>` package.\n",
      "    \n",
      "    >>> df = pd.DataFrame({\n",
      "    ...    \"time\": ['0hr', '128hr', '72hr', '48hr', '96hr'],\n",
      "    ...    \"value\": [10, 20, 30, 40, 50]\n",
      "    ... })\n",
      "    >>> df\n",
      "        time  value\n",
      "    0    0hr     10\n",
      "    1  128hr     20\n",
      "    2   72hr     30\n",
      "    3   48hr     40\n",
      "    4   96hr     50\n",
      "    >>> from natsort import index_natsorted\n",
      "    >>> df.sort_values(\n",
      "    ...    by=\"time\",\n",
      "    ...    key=lambda x: np.argsort(index_natsorted(df[\"time\"]))\n",
      "    ... )\n",
      "        time  value\n",
      "    0    0hr     10\n",
      "    3   48hr     40\n",
      "    2   72hr     30\n",
      "    4   96hr     50\n",
      "    1  128hr     20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(df.sort_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58828340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>-0.107001</td>\n",
       "      <td>-0.540959</td>\n",
       "      <td>0.366554</td>\n",
       "      <td>-0.800809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>0.520048</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>-1.019059</td>\n",
       "      <td>-0.728874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-06</th>\n",
       "      <td>1.242259</td>\n",
       "      <td>0.025517</td>\n",
       "      <td>2.056000</td>\n",
       "      <td>-0.882241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>0.274511</td>\n",
       "      <td>0.155498</td>\n",
       "      <td>1.271314</td>\n",
       "      <td>0.991062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>0.478640</td>\n",
       "      <td>0.400149</td>\n",
       "      <td>0.523567</td>\n",
       "      <td>0.266236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>-0.407414</td>\n",
       "      <td>1.032829</td>\n",
       "      <td>0.287981</td>\n",
       "      <td>-1.614230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2013-01-02 -0.107001 -0.540959  0.366554 -0.800809\n",
       "2013-01-03  0.520048  0.000538 -1.019059 -0.728874\n",
       "2013-01-06  1.242259  0.025517  2.056000 -0.882241\n",
       "2013-01-05  0.274511  0.155498  1.271314  0.991062\n",
       "2013-01-01  0.478640  0.400149  0.523567  0.266236\n",
       "2013-01-04 -0.407414  1.032829  0.287981 -1.614230"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='B')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458db4e6",
   "metadata": {},
   "source": [
    "## 选择"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207fea44",
   "metadata": {},
   "source": [
    "选择、设置标准 **Python / Numpy** 的表达式已经非常直观，交互也很方便，但对于**生产代码**，还是**推荐优化过的 Pandas 数据访问方法**：**.at**、**.iat**、**.loc** 和 **.iloc**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f0d5a8",
   "metadata": {},
   "source": [
    "### 获取数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717e9d53",
   "metadata": {},
   "source": [
    "选择**单列**，产生 **Series**，与 **df.A** 等效："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42e8d43d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2013-01-01    0.478640\n",
       "2013-01-02   -0.107001\n",
       "2013-01-03    0.520048\n",
       "2013-01-04   -0.407414\n",
       "2013-01-05    0.274511\n",
       "2013-01-06    1.242259\n",
       "Freq: D, Name: A, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['A']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a6ed15",
   "metadata": {},
   "source": [
    "用 **[]** 切片**行**："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6465713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>0.478640</td>\n",
       "      <td>0.400149</td>\n",
       "      <td>0.523567</td>\n",
       "      <td>0.266236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>-0.107001</td>\n",
       "      <td>-0.540959</td>\n",
       "      <td>0.366554</td>\n",
       "      <td>-0.800809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>0.520048</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>-1.019059</td>\n",
       "      <td>-0.728874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2013-01-01  0.478640  0.400149  0.523567  0.266236\n",
       "2013-01-02 -0.107001 -0.540959  0.366554 -0.800809\n",
       "2013-01-03  0.520048  0.000538 -1.019059 -0.728874"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3edea33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>-0.107001</td>\n",
       "      <td>-0.540959</td>\n",
       "      <td>0.366554</td>\n",
       "      <td>-0.800809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>0.520048</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>-1.019059</td>\n",
       "      <td>-0.728874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>-0.407414</td>\n",
       "      <td>1.032829</td>\n",
       "      <td>0.287981</td>\n",
       "      <td>-1.614230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2013-01-02 -0.107001 -0.540959  0.366554 -0.800809\n",
       "2013-01-03  0.520048  0.000538 -1.019059 -0.728874\n",
       "2013-01-04 -0.407414  1.032829  0.287981 -1.614230"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['20130102':'20130104']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75d0c976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>-0.107001</td>\n",
       "      <td>-0.540959</td>\n",
       "      <td>0.366554</td>\n",
       "      <td>-0.800809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>0.520048</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>-1.019059</td>\n",
       "      <td>-0.728874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>-0.407414</td>\n",
       "      <td>1.032829</td>\n",
       "      <td>0.287981</td>\n",
       "      <td>-1.614230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2013-01-02 -0.107001 -0.540959  0.366554 -0.800809\n",
       "2013-01-03  0.520048  0.000538 -1.019059 -0.728874\n",
       "2013-01-04 -0.407414  1.032829  0.287981 -1.614230"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['2013-01-02':'2013-01-04']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4fa4e471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>-0.107001</td>\n",
       "      <td>-0.540959</td>\n",
       "      <td>0.366554</td>\n",
       "      <td>-0.800809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>0.520048</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>-1.019059</td>\n",
       "      <td>-0.728874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>-0.407414</td>\n",
       "      <td>1.032829</td>\n",
       "      <td>0.287981</td>\n",
       "      <td>-1.614230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2013-01-02 -0.107001 -0.540959  0.366554 -0.800809\n",
       "2013-01-03  0.520048  0.000538 -1.019059 -0.728874\n",
       "2013-01-04 -0.407414  1.032829  0.287981 -1.614230"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['2013/01/02':'2013/01/04']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35fbe5a",
   "metadata": {},
   "source": [
    "### 按标签选择"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb358a54",
   "metadata": {},
   "source": [
    "用**标签**提取**一行数据**："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "11884944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    0.478640\n",
       "B    0.400149\n",
       "C    0.523567\n",
       "D    0.266236\n",
       "Name: 2013-01-01 00:00:00, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[dates[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d9f014",
   "metadata": {},
   "source": [
    "用**标签**选择**多列数据**："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d124285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>0.478640</td>\n",
       "      <td>0.400149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>-0.107001</td>\n",
       "      <td>-0.540959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>0.520048</td>\n",
       "      <td>0.000538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>-0.407414</td>\n",
       "      <td>1.032829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>0.274511</td>\n",
       "      <td>0.155498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-06</th>\n",
       "      <td>1.242259</td>\n",
       "      <td>0.025517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B\n",
       "2013-01-01  0.478640  0.400149\n",
       "2013-01-02 -0.107001 -0.540959\n",
       "2013-01-03  0.520048  0.000538\n",
       "2013-01-04 -0.407414  1.032829\n",
       "2013-01-05  0.274511  0.155498\n",
       "2013-01-06  1.242259  0.025517"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, ['A', 'B']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbf0810",
   "metadata": {},
   "source": [
    "用**标签切片**，包含**行**与**列**结束点："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d064c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>-0.107001</td>\n",
       "      <td>-0.540959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>0.520048</td>\n",
       "      <td>0.000538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>-0.407414</td>\n",
       "      <td>1.032829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B\n",
       "2013-01-02 -0.107001 -0.540959\n",
       "2013-01-03  0.520048  0.000538\n",
       "2013-01-04 -0.407414  1.032829"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc['20130102':'20130104', ['A', 'B']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9219c9f1",
   "metadata": {},
   "source": [
    "返回对象："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7858ebca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A   -0.107001\n",
       "B   -0.540959\n",
       "Name: 2013-01-02 00:00:00, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc['20130102', ['A', 'B']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c184d9f",
   "metadata": {},
   "source": [
    "提取标量值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a93bfefa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4786401824007937"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[dates[0], 'A']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dffcb5",
   "metadata": {},
   "source": [
    "快速访问标量，与上述方法等效："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a5034ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4786401824007937"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.at[dates[0], 'A']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baeca5e5",
   "metadata": {},
   "source": [
    "### 按位置选择"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f92547",
   "metadata": {},
   "source": [
    "用**整数位置**选择："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dbeca9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A   -0.407414\n",
       "B    1.032829\n",
       "C    0.287981\n",
       "D   -1.614230\n",
       "Name: 2013-01-04 00:00:00, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814cf797",
   "metadata": {},
   "source": [
    "类似 **NumPy / Python**，用**整数切片**："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f669d000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>-0.407414</td>\n",
       "      <td>1.032829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>0.274511</td>\n",
       "      <td>0.155498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B\n",
       "2013-01-04 -0.407414  1.032829\n",
       "2013-01-05  0.274511  0.155498"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[3:5, 0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ac6060",
   "metadata": {},
   "source": [
    "类似 **NumPy / Python**，用**整数列表**按**位置切片**："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f33e97ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>-0.107001</td>\n",
       "      <td>0.366554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>0.520048</td>\n",
       "      <td>-1.019059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>0.274511</td>\n",
       "      <td>1.271314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         C\n",
       "2013-01-02 -0.107001  0.366554\n",
       "2013-01-03  0.520048 -1.019059\n",
       "2013-01-05  0.274511  1.271314"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[[1, 2, 4], [0, 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353348d4",
   "metadata": {},
   "source": [
    "显式**整行切片**："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0a36408e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>-0.107001</td>\n",
       "      <td>-0.540959</td>\n",
       "      <td>0.366554</td>\n",
       "      <td>-0.800809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>0.520048</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>-1.019059</td>\n",
       "      <td>-0.728874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2013-01-02 -0.107001 -0.540959  0.366554 -0.800809\n",
       "2013-01-03  0.520048  0.000538 -1.019059 -0.728874"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1:3, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8dc5583",
   "metadata": {},
   "source": [
    "显式**整列切片**："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a8c4d9dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>0.400149</td>\n",
       "      <td>0.523567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>-0.540959</td>\n",
       "      <td>0.366554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>0.000538</td>\n",
       "      <td>-1.019059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>1.032829</td>\n",
       "      <td>0.287981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>0.155498</td>\n",
       "      <td>1.271314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-06</th>\n",
       "      <td>0.025517</td>\n",
       "      <td>2.056000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   B         C\n",
       "2013-01-01  0.400149  0.523567\n",
       "2013-01-02 -0.540959  0.366554\n",
       "2013-01-03  0.000538 -1.019059\n",
       "2013-01-04  1.032829  0.287981\n",
       "2013-01-05  0.155498  1.271314\n",
       "2013-01-06  0.025517  2.056000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:, 1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d170472",
   "metadata": {},
   "source": [
    "显式**提取值**："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fae6864e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5409593978801435"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e6c5ec",
   "metadata": {},
   "source": [
    "快速**访问标量**，与**上述方法**等效："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b9c8d7a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5409593978801435"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iat[1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f479543",
   "metadata": {},
   "source": [
    "### 布尔索引"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da1fb3b",
   "metadata": {},
   "source": [
    "用**单列的值**选择数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "11469ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>0.478640</td>\n",
       "      <td>0.400149</td>\n",
       "      <td>0.523567</td>\n",
       "      <td>0.266236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>0.520048</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>-1.019059</td>\n",
       "      <td>-0.728874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>0.274511</td>\n",
       "      <td>0.155498</td>\n",
       "      <td>1.271314</td>\n",
       "      <td>0.991062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-06</th>\n",
       "      <td>1.242259</td>\n",
       "      <td>0.025517</td>\n",
       "      <td>2.056000</td>\n",
       "      <td>-0.882241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2013-01-01  0.478640  0.400149  0.523567  0.266236\n",
       "2013-01-03  0.520048  0.000538 -1.019059 -0.728874\n",
       "2013-01-05  0.274511  0.155498  1.271314  0.991062\n",
       "2013-01-06  1.242259  0.025517  2.056000 -0.882241"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.A > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93842bb",
   "metadata": {},
   "source": [
    "选择 **DataFrame** 里**满足条件**的值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bd63d1dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>0.478640</td>\n",
       "      <td>0.400149</td>\n",
       "      <td>0.523567</td>\n",
       "      <td>0.266236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.366554</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>0.520048</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.032829</td>\n",
       "      <td>0.287981</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>0.274511</td>\n",
       "      <td>0.155498</td>\n",
       "      <td>1.271314</td>\n",
       "      <td>0.991062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-06</th>\n",
       "      <td>1.242259</td>\n",
       "      <td>0.025517</td>\n",
       "      <td>2.056000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2013-01-01  0.478640  0.400149  0.523567  0.266236\n",
       "2013-01-02       NaN       NaN  0.366554       NaN\n",
       "2013-01-03  0.520048  0.000538       NaN       NaN\n",
       "2013-01-04       NaN  1.032829  0.287981       NaN\n",
       "2013-01-05  0.274511  0.155498  1.271314  0.991062\n",
       "2013-01-06  1.242259  0.025517  2.056000       NaN"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3100d075",
   "metadata": {},
   "source": [
    "用 **isin()** 筛选："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "db6b6a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>0.478640</td>\n",
       "      <td>0.400149</td>\n",
       "      <td>0.523567</td>\n",
       "      <td>0.266236</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>-0.107001</td>\n",
       "      <td>-0.540959</td>\n",
       "      <td>0.366554</td>\n",
       "      <td>-0.800809</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>0.520048</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>-1.019059</td>\n",
       "      <td>-0.728874</td>\n",
       "      <td>two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>-0.407414</td>\n",
       "      <td>1.032829</td>\n",
       "      <td>0.287981</td>\n",
       "      <td>-1.614230</td>\n",
       "      <td>three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>0.274511</td>\n",
       "      <td>0.155498</td>\n",
       "      <td>1.271314</td>\n",
       "      <td>0.991062</td>\n",
       "      <td>four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-06</th>\n",
       "      <td>1.242259</td>\n",
       "      <td>0.025517</td>\n",
       "      <td>2.056000</td>\n",
       "      <td>-0.882241</td>\n",
       "      <td>three</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D      E\n",
       "2013-01-01  0.478640  0.400149  0.523567  0.266236    one\n",
       "2013-01-02 -0.107001 -0.540959  0.366554 -0.800809    one\n",
       "2013-01-03  0.520048  0.000538 -1.019059 -0.728874    two\n",
       "2013-01-04 -0.407414  1.032829  0.287981 -1.614230  three\n",
       "2013-01-05  0.274511  0.155498  1.271314  0.991062   four\n",
       "2013-01-06  1.242259  0.025517  2.056000 -0.882241  three"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.copy()\n",
    "df2['E'] = ['one', 'one', 'two', 'three', 'four', 'three']\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f1941280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method isin in module pandas.core.series:\n",
      "\n",
      "isin(values) -> 'Series' method of pandas.core.series.Series instance\n",
      "    Whether elements in Series are contained in `values`.\n",
      "    \n",
      "    Return a boolean Series showing whether each element in the Series\n",
      "    matches an element in the passed sequence of `values` exactly.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    values : set or list-like\n",
      "        The sequence of values to test. Passing in a single string will\n",
      "        raise a ``TypeError``. Instead, turn a single string into a\n",
      "        list of one element.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    Series\n",
      "        Series of booleans indicating if each element is in values.\n",
      "    \n",
      "    Raises\n",
      "    ------\n",
      "    TypeError\n",
      "      * If `values` is a string\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.isin : Equivalent method on DataFrame.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> s = pd.Series(['lama', 'cow', 'lama', 'beetle', 'lama',\n",
      "    ...                'hippo'], name='animal')\n",
      "    >>> s.isin(['cow', 'lama'])\n",
      "    0     True\n",
      "    1     True\n",
      "    2     True\n",
      "    3    False\n",
      "    4     True\n",
      "    5    False\n",
      "    Name: animal, dtype: bool\n",
      "    \n",
      "    Passing a single string as ``s.isin('lama')`` will raise an error. Use\n",
      "    a list of one element instead:\n",
      "    \n",
      "    >>> s.isin(['lama'])\n",
      "    0     True\n",
      "    1    False\n",
      "    2     True\n",
      "    3    False\n",
      "    4     True\n",
      "    5    False\n",
      "    Name: animal, dtype: bool\n",
      "    \n",
      "    Strings and integers are distinct and are therefore not comparable:\n",
      "    \n",
      "    >>> pd.Series([1]).isin(['1'])\n",
      "    0    False\n",
      "    dtype: bool\n",
      "    >>> pd.Series([1.1]).isin(['1.1'])\n",
      "    0    False\n",
      "    dtype: bool\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(df2['E'].isin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3cc3256e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>0.520048</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>-1.019059</td>\n",
       "      <td>-0.728874</td>\n",
       "      <td>two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>0.274511</td>\n",
       "      <td>0.155498</td>\n",
       "      <td>1.271314</td>\n",
       "      <td>0.991062</td>\n",
       "      <td>four</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D     E\n",
       "2013-01-03  0.520048  0.000538 -1.019059 -0.728874   two\n",
       "2013-01-05  0.274511  0.155498  1.271314  0.991062  four"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[df2['E'].isin(['two', 'four'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b62388",
   "metadata": {},
   "source": [
    "### 赋值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5697375",
   "metadata": {},
   "source": [
    "用**索引**自动对齐**新增列的数据**："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6b5fd76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>0.478640</td>\n",
       "      <td>0.400149</td>\n",
       "      <td>0.523567</td>\n",
       "      <td>0.266236</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>-0.107001</td>\n",
       "      <td>-0.540959</td>\n",
       "      <td>0.366554</td>\n",
       "      <td>-0.800809</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>0.520048</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>-1.019059</td>\n",
       "      <td>-0.728874</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>-0.407414</td>\n",
       "      <td>1.032829</td>\n",
       "      <td>0.287981</td>\n",
       "      <td>-1.614230</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>0.274511</td>\n",
       "      <td>0.155498</td>\n",
       "      <td>1.271314</td>\n",
       "      <td>0.991062</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-06</th>\n",
       "      <td>1.242259</td>\n",
       "      <td>0.025517</td>\n",
       "      <td>2.056000</td>\n",
       "      <td>-0.882241</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D    F\n",
       "2013-01-01  0.478640  0.400149  0.523567  0.266236  NaN\n",
       "2013-01-02 -0.107001 -0.540959  0.366554 -0.800809  1.0\n",
       "2013-01-03  0.520048  0.000538 -1.019059 -0.728874  2.0\n",
       "2013-01-04 -0.407414  1.032829  0.287981 -1.614230  3.0\n",
       "2013-01-05  0.274511  0.155498  1.271314  0.991062  4.0\n",
       "2013-01-06  1.242259  0.025517  2.056000 -0.882241  5.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = pd.Series([1, 2, 3, 4, 5, 6], index=pd.date_range('20130102', periods=6))\n",
    "df['F'] = s1\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f824c95",
   "metadata": {},
   "source": [
    "按**标签赋值**："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cfbeb94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.at[dates[0], 'A'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01abcf67",
   "metadata": {},
   "source": [
    "按**位置赋值**："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3946926d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iat[0, 1] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b60c49",
   "metadata": {},
   "source": [
    "按 **NumPy 数组**赋值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "032f616c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'D'] = np.array([5] * len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea098cb9",
   "metadata": {},
   "source": [
    "上述**赋值结果**："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dde499e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.523567</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>-0.107001</td>\n",
       "      <td>-0.540959</td>\n",
       "      <td>0.366554</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>0.520048</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>-1.019059</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>-0.407414</td>\n",
       "      <td>1.032829</td>\n",
       "      <td>0.287981</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>0.274511</td>\n",
       "      <td>0.155498</td>\n",
       "      <td>1.271314</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-06</th>\n",
       "      <td>1.242259</td>\n",
       "      <td>0.025517</td>\n",
       "      <td>2.056000</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C  D    F\n",
       "2013-01-01  0.000000  0.000000  0.523567  5  NaN\n",
       "2013-01-02 -0.107001 -0.540959  0.366554  5  1.0\n",
       "2013-01-03  0.520048  0.000538 -1.019059  5  2.0\n",
       "2013-01-04 -0.407414  1.032829  0.287981  5  3.0\n",
       "2013-01-05  0.274511  0.155498  1.271314  5  4.0\n",
       "2013-01-06  1.242259  0.025517  2.056000  5  5.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417c97a8",
   "metadata": {},
   "source": [
    "用 **where** 条件赋值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0bc795d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.523567</td>\n",
       "      <td>-5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>-0.107001</td>\n",
       "      <td>-0.540959</td>\n",
       "      <td>-0.366554</td>\n",
       "      <td>-5</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>-0.520048</td>\n",
       "      <td>-0.000538</td>\n",
       "      <td>-1.019059</td>\n",
       "      <td>-5</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>-0.407414</td>\n",
       "      <td>-1.032829</td>\n",
       "      <td>-0.287981</td>\n",
       "      <td>-5</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>-0.274511</td>\n",
       "      <td>-0.155498</td>\n",
       "      <td>-1.271314</td>\n",
       "      <td>-5</td>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-06</th>\n",
       "      <td>-1.242259</td>\n",
       "      <td>-0.025517</td>\n",
       "      <td>-2.056000</td>\n",
       "      <td>-5</td>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C  D    F\n",
       "2013-01-01  0.000000  0.000000 -0.523567 -5  NaN\n",
       "2013-01-02 -0.107001 -0.540959 -0.366554 -5 -1.0\n",
       "2013-01-03 -0.520048 -0.000538 -1.019059 -5 -2.0\n",
       "2013-01-04 -0.407414 -1.032829 -0.287981 -5 -3.0\n",
       "2013-01-05 -0.274511 -0.155498 -1.271314 -5 -4.0\n",
       "2013-01-06 -1.242259 -0.025517 -2.056000 -5 -5.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.copy()\n",
    "df2[df2 > 0] = -df2\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69af8c25",
   "metadata": {},
   "source": [
    "## 缺失值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeef1241",
   "metadata": {},
   "source": [
    "**Pandas** 主要用 **np.nan** 表示**缺失数据**。计算时，默认不包含空值。\n",
    "\n",
    "**重建索引**（reindex）可以**更改**、**添加**、**删除**指定轴的索引，并**返回数据副本**，即不更改原数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7857ed39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>F</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.523567</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>-0.107001</td>\n",
       "      <td>-0.540959</td>\n",
       "      <td>0.366554</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>0.520048</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>-1.019059</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>-0.407414</td>\n",
       "      <td>1.032829</td>\n",
       "      <td>0.287981</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C  D    F    E\n",
       "2013-01-01  0.000000  0.000000  0.523567  5  NaN  1.0\n",
       "2013-01-02 -0.107001 -0.540959  0.366554  5  1.0  1.0\n",
       "2013-01-03  0.520048  0.000538 -1.019059  5  2.0  NaN\n",
       "2013-01-04 -0.407414  1.032829  0.287981  5  3.0  NaN"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.reindex(index=dates[0:4], columns=list(df.columns) + ['E'])\n",
    "df1.loc[dates[0]:dates[1], 'E'] = 1\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78eeb526",
   "metadata": {},
   "source": [
    "**删除**所有**含缺失值的行**："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "229ae0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method dropna in module pandas.core.frame:\n",
      "\n",
      "dropna(axis: 'Axis' = 0, how: 'str' = 'any', thresh=None, subset=None, inplace: 'bool' = False) method of pandas.core.frame.DataFrame instance\n",
      "    Remove missing values.\n",
      "    \n",
      "    See the :ref:`User Guide <missing_data>` for more on which values are\n",
      "    considered missing, and how to work with missing data.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "        Determine if rows or columns which contain missing values are\n",
      "        removed.\n",
      "    \n",
      "        * 0, or 'index' : Drop rows which contain missing values.\n",
      "        * 1, or 'columns' : Drop columns which contain missing value.\n",
      "    \n",
      "        .. versionchanged:: 1.0.0\n",
      "    \n",
      "           Pass tuple or list to drop on multiple axes.\n",
      "           Only a single axis is allowed.\n",
      "    \n",
      "    how : {'any', 'all'}, default 'any'\n",
      "        Determine if row or column is removed from DataFrame, when we have\n",
      "        at least one NA or all NA.\n",
      "    \n",
      "        * 'any' : If any NA values are present, drop that row or column.\n",
      "        * 'all' : If all values are NA, drop that row or column.\n",
      "    \n",
      "    thresh : int, optional\n",
      "        Require that many non-NA values.\n",
      "    subset : array-like, optional\n",
      "        Labels along other axis to consider, e.g. if you are dropping rows\n",
      "        these would be a list of columns to include.\n",
      "    inplace : bool, default False\n",
      "        If True, do operation inplace and return None.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame or None\n",
      "        DataFrame with NA entries dropped from it or None if ``inplace=True``.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.isna: Indicate missing values.\n",
      "    DataFrame.notna : Indicate existing (non-missing) values.\n",
      "    DataFrame.fillna : Replace missing values.\n",
      "    Series.dropna : Drop missing values.\n",
      "    Index.dropna : Drop missing indices.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = pd.DataFrame({\"name\": ['Alfred', 'Batman', 'Catwoman'],\n",
      "    ...                    \"toy\": [np.nan, 'Batmobile', 'Bullwhip'],\n",
      "    ...                    \"born\": [pd.NaT, pd.Timestamp(\"1940-04-25\"),\n",
      "    ...                             pd.NaT]})\n",
      "    >>> df\n",
      "           name        toy       born\n",
      "    0    Alfred        NaN        NaT\n",
      "    1    Batman  Batmobile 1940-04-25\n",
      "    2  Catwoman   Bullwhip        NaT\n",
      "    \n",
      "    Drop the rows where at least one element is missing.\n",
      "    \n",
      "    >>> df.dropna()\n",
      "         name        toy       born\n",
      "    1  Batman  Batmobile 1940-04-25\n",
      "    \n",
      "    Drop the columns where at least one element is missing.\n",
      "    \n",
      "    >>> df.dropna(axis='columns')\n",
      "           name\n",
      "    0    Alfred\n",
      "    1    Batman\n",
      "    2  Catwoman\n",
      "    \n",
      "    Drop the rows where all elements are missing.\n",
      "    \n",
      "    >>> df.dropna(how='all')\n",
      "           name        toy       born\n",
      "    0    Alfred        NaN        NaT\n",
      "    1    Batman  Batmobile 1940-04-25\n",
      "    2  Catwoman   Bullwhip        NaT\n",
      "    \n",
      "    Keep only the rows with at least 2 non-NA values.\n",
      "    \n",
      "    >>> df.dropna(thresh=2)\n",
      "           name        toy       born\n",
      "    1    Batman  Batmobile 1940-04-25\n",
      "    2  Catwoman   Bullwhip        NaT\n",
      "    \n",
      "    Define in which columns to look for missing values.\n",
      "    \n",
      "    >>> df.dropna(subset=['name', 'toy'])\n",
      "           name        toy       born\n",
      "    1    Batman  Batmobile 1940-04-25\n",
      "    2  Catwoman   Bullwhip        NaT\n",
      "    \n",
      "    Keep the DataFrame with valid entries in the same variable.\n",
      "    \n",
      "    >>> df.dropna(inplace=True)\n",
      "    >>> df\n",
      "         name        toy       born\n",
      "    1  Batman  Batmobile 1940-04-25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(df1.dropna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "49329869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>F</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>-0.107001</td>\n",
       "      <td>-0.540959</td>\n",
       "      <td>0.366554</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C  D    F    E\n",
       "2013-01-02 -0.107001 -0.540959  0.366554  5  1.0  1.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dropna(how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234ea7f9",
   "metadata": {},
   "source": [
    "填充缺失值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c5c757b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>F</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.523567</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>-0.107001</td>\n",
       "      <td>-0.540959</td>\n",
       "      <td>0.366554</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>0.520048</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>-1.019059</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>-0.407414</td>\n",
       "      <td>1.032829</td>\n",
       "      <td>0.287981</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C  D    F    E\n",
       "2013-01-01  0.000000  0.000000  0.523567  5  5.0  1.0\n",
       "2013-01-02 -0.107001 -0.540959  0.366554  5  1.0  1.0\n",
       "2013-01-03  0.520048  0.000538 -1.019059  5  2.0  5.0\n",
       "2013-01-04 -0.407414  1.032829  0.287981  5  3.0  5.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.fillna(value=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b144075",
   "metadata": {},
   "source": [
    "提取 **nan** 值的**布尔掩码**："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a74561a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>F</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                A      B      C      D      F      E\n",
       "2013-01-01  False  False  False  False   True  False\n",
       "2013-01-02  False  False  False  False  False  False\n",
       "2013-01-03  False  False  False  False  False   True\n",
       "2013-01-04  False  False  False  False  False   True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isna(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76380695",
   "metadata": {},
   "source": [
    "## 运算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c032e2ac",
   "metadata": {},
   "source": [
    "### 统计"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434747b1",
   "metadata": {},
   "source": [
    "一般情况下，运算时**排除缺失值**。\n",
    "\n",
    "描述性统计："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0b8e209b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    0.253734\n",
       "B    0.112237\n",
       "C    0.581059\n",
       "D    5.000000\n",
       "F    3.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7149ce",
   "metadata": {},
   "source": [
    "在**另一个轴(即，行)**上执行同样的操作："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "089032b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2013-01-01    1.380892\n",
       "2013-01-02    1.143719\n",
       "2013-01-03    1.300305\n",
       "2013-01-04    1.782679\n",
       "2013-01-05    2.140264\n",
       "2013-01-06    2.664755\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mean(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938f7de0",
   "metadata": {},
   "source": [
    "**不同维度对象运算**时，**要先对齐**。 此外，**Pandas** 自动**沿指定维度广播**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "87c30c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method shift in module pandas.core.series:\n",
      "\n",
      "shift(periods=1, freq=None, axis=0, fill_value=None) -> 'Series' method of pandas.core.series.Series instance\n",
      "    Shift index by desired number of periods with an optional time `freq`.\n",
      "    \n",
      "    When `freq` is not passed, shift the index without realigning the data.\n",
      "    If `freq` is passed (in this case, the index must be date or datetime,\n",
      "    or it will raise a `NotImplementedError`), the index will be\n",
      "    increased using the periods and the `freq`. `freq` can be inferred\n",
      "    when specified as \"infer\" as long as either freq or inferred_freq\n",
      "    attribute is set in the index.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    periods : int\n",
      "        Number of periods to shift. Can be positive or negative.\n",
      "    freq : DateOffset, tseries.offsets, timedelta, or str, optional\n",
      "        Offset to use from the tseries module or time rule (e.g. 'EOM').\n",
      "        If `freq` is specified then the index values are shifted but the\n",
      "        data is not realigned. That is, use `freq` if you would like to\n",
      "        extend the index when shifting and preserve the original data.\n",
      "        If `freq` is specified as \"infer\" then it will be inferred from\n",
      "        the freq or inferred_freq attributes of the index. If neither of\n",
      "        those attributes exist, a ValueError is thrown.\n",
      "    axis : {0 or 'index', 1 or 'columns', None}, default None\n",
      "        Shift direction.\n",
      "    fill_value : object, optional\n",
      "        The scalar value to use for newly introduced missing values.\n",
      "        the default depends on the dtype of `self`.\n",
      "        For numeric data, ``np.nan`` is used.\n",
      "        For datetime, timedelta, or period data, etc. :attr:`NaT` is used.\n",
      "        For extension dtypes, ``self.dtype.na_value`` is used.\n",
      "    \n",
      "        .. versionchanged:: 1.1.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    Series\n",
      "        Copy of input object, shifted.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    Index.shift : Shift values of Index.\n",
      "    DatetimeIndex.shift : Shift values of DatetimeIndex.\n",
      "    PeriodIndex.shift : Shift values of PeriodIndex.\n",
      "    tshift : Shift the time index, using the index's frequency if\n",
      "        available.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = pd.DataFrame({\"Col1\": [10, 20, 15, 30, 45],\n",
      "    ...                    \"Col2\": [13, 23, 18, 33, 48],\n",
      "    ...                    \"Col3\": [17, 27, 22, 37, 52]},\n",
      "    ...                   index=pd.date_range(\"2020-01-01\", \"2020-01-05\"))\n",
      "    >>> df\n",
      "                Col1  Col2  Col3\n",
      "    2020-01-01    10    13    17\n",
      "    2020-01-02    20    23    27\n",
      "    2020-01-03    15    18    22\n",
      "    2020-01-04    30    33    37\n",
      "    2020-01-05    45    48    52\n",
      "    \n",
      "    >>> df.shift(periods=3)\n",
      "                Col1  Col2  Col3\n",
      "    2020-01-01   NaN   NaN   NaN\n",
      "    2020-01-02   NaN   NaN   NaN\n",
      "    2020-01-03   NaN   NaN   NaN\n",
      "    2020-01-04  10.0  13.0  17.0\n",
      "    2020-01-05  20.0  23.0  27.0\n",
      "    \n",
      "    >>> df.shift(periods=1, axis=\"columns\")\n",
      "                Col1  Col2  Col3\n",
      "    2020-01-01   NaN    10    13\n",
      "    2020-01-02   NaN    20    23\n",
      "    2020-01-03   NaN    15    18\n",
      "    2020-01-04   NaN    30    33\n",
      "    2020-01-05   NaN    45    48\n",
      "    \n",
      "    >>> df.shift(periods=3, fill_value=0)\n",
      "                Col1  Col2  Col3\n",
      "    2020-01-01     0     0     0\n",
      "    2020-01-02     0     0     0\n",
      "    2020-01-03     0     0     0\n",
      "    2020-01-04    10    13    17\n",
      "    2020-01-05    20    23    27\n",
      "    \n",
      "    >>> df.shift(periods=3, freq=\"D\")\n",
      "                Col1  Col2  Col3\n",
      "    2020-01-04    10    13    17\n",
      "    2020-01-05    20    23    27\n",
      "    2020-01-06    15    18    22\n",
      "    2020-01-07    30    33    37\n",
      "    2020-01-08    45    48    52\n",
      "    \n",
      "    >>> df.shift(periods=3, freq=\"infer\")\n",
      "                Col1  Col2  Col3\n",
      "    2020-01-04    10    13    17\n",
      "    2020-01-05    20    23    27\n",
      "    2020-01-06    15    18    22\n",
      "    2020-01-07    30    33    37\n",
      "    2020-01-08    45    48    52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.Series([1, 3, 5, np.nan, 6, 8], index=dates).shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "22997059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2013-01-01    NaN\n",
       "2013-01-02    NaN\n",
       "2013-01-03    1.0\n",
       "2013-01-04    3.0\n",
       "2013-01-05    5.0\n",
       "2013-01-06    NaN\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series([1, 3, 5, np.nan, 6, 8], index=dates).shift(2)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2358bfa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method sub in module pandas.core.ops:\n",
      "\n",
      "sub(other, axis='columns', level=None, fill_value=None) method of pandas.core.frame.DataFrame instance\n",
      "    Get Subtraction of dataframe and other, element-wise (binary operator `sub`).\n",
      "    \n",
      "    Equivalent to ``dataframe - other``, but with support to substitute a fill_value\n",
      "    for missing data in one of the inputs. With reverse version, `rsub`.\n",
      "    \n",
      "    Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      "    arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    other : scalar, sequence, Series, or DataFrame\n",
      "        Any single or multiple element data structure, or list-like object.\n",
      "    axis : {0 or 'index', 1 or 'columns'}\n",
      "        Whether to compare by the index (0 or 'index') or columns\n",
      "        (1 or 'columns'). For Series input, axis to match Series index on.\n",
      "    level : int or label\n",
      "        Broadcast across a level, matching Index values on the\n",
      "        passed MultiIndex level.\n",
      "    fill_value : float or None, default None\n",
      "        Fill existing missing (NaN) values, and any new element needed for\n",
      "        successful DataFrame alignment, with this value before computation.\n",
      "        If data in both corresponding DataFrame locations is missing\n",
      "        the result will be missing.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame\n",
      "        Result of the arithmetic operation.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.add : Add DataFrames.\n",
      "    DataFrame.sub : Subtract DataFrames.\n",
      "    DataFrame.mul : Multiply DataFrames.\n",
      "    DataFrame.div : Divide DataFrames (float division).\n",
      "    DataFrame.truediv : Divide DataFrames (float division).\n",
      "    DataFrame.floordiv : Divide DataFrames (integer division).\n",
      "    DataFrame.mod : Calculate modulo (remainder after division).\n",
      "    DataFrame.pow : Calculate exponential power.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Mismatched indices will be unioned together.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      "    ...                    'degrees': [360, 180, 360]},\n",
      "    ...                   index=['circle', 'triangle', 'rectangle'])\n",
      "    >>> df\n",
      "               angles  degrees\n",
      "    circle          0      360\n",
      "    triangle        3      180\n",
      "    rectangle       4      360\n",
      "    \n",
      "    Add a scalar with operator version which return the same\n",
      "    results.\n",
      "    \n",
      "    >>> df + 1\n",
      "               angles  degrees\n",
      "    circle          1      361\n",
      "    triangle        4      181\n",
      "    rectangle       5      361\n",
      "    \n",
      "    >>> df.add(1)\n",
      "               angles  degrees\n",
      "    circle          1      361\n",
      "    triangle        4      181\n",
      "    rectangle       5      361\n",
      "    \n",
      "    Divide by constant with reverse version.\n",
      "    \n",
      "    >>> df.div(10)\n",
      "               angles  degrees\n",
      "    circle        0.0     36.0\n",
      "    triangle      0.3     18.0\n",
      "    rectangle     0.4     36.0\n",
      "    \n",
      "    >>> df.rdiv(10)\n",
      "                 angles   degrees\n",
      "    circle          inf  0.027778\n",
      "    triangle   3.333333  0.055556\n",
      "    rectangle  2.500000  0.027778\n",
      "    \n",
      "    Subtract a list and Series by axis with operator version.\n",
      "    \n",
      "    >>> df - [1, 2]\n",
      "               angles  degrees\n",
      "    circle         -1      358\n",
      "    triangle        2      178\n",
      "    rectangle       3      358\n",
      "    \n",
      "    >>> df.sub([1, 2], axis='columns')\n",
      "               angles  degrees\n",
      "    circle         -1      358\n",
      "    triangle        2      178\n",
      "    rectangle       3      358\n",
      "    \n",
      "    >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      "    ...        axis='index')\n",
      "               angles  degrees\n",
      "    circle         -1      359\n",
      "    triangle        2      179\n",
      "    rectangle       3      359\n",
      "    \n",
      "    Multiply a DataFrame of different shape with operator version.\n",
      "    \n",
      "    >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      "    ...                      index=['circle', 'triangle', 'rectangle'])\n",
      "    >>> other\n",
      "               angles\n",
      "    circle          0\n",
      "    triangle        3\n",
      "    rectangle       4\n",
      "    \n",
      "    >>> df * other\n",
      "               angles  degrees\n",
      "    circle          0      NaN\n",
      "    triangle        9      NaN\n",
      "    rectangle      16      NaN\n",
      "    \n",
      "    >>> df.mul(other, fill_value=0)\n",
      "               angles  degrees\n",
      "    circle          0      0.0\n",
      "    triangle        9      0.0\n",
      "    rectangle      16      0.0\n",
      "    \n",
      "    Divide by a MultiIndex by level.\n",
      "    \n",
      "    >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      "    ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      "    ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      "    ...                                    ['circle', 'triangle', 'rectangle',\n",
      "    ...                                     'square', 'pentagon', 'hexagon']])\n",
      "    >>> df_multindex\n",
      "                 angles  degrees\n",
      "    A circle          0      360\n",
      "      triangle        3      180\n",
      "      rectangle       4      360\n",
      "    B square          4      360\n",
      "      pentagon        5      540\n",
      "      hexagon         6      720\n",
      "    \n",
      "    >>> df.div(df_multindex, level=1, fill_value=0)\n",
      "                 angles  degrees\n",
      "    A circle        NaN      1.0\n",
      "      triangle      1.0      1.0\n",
      "      rectangle     1.0      1.0\n",
      "    B square        0.0      0.0\n",
      "      pentagon      0.0      0.0\n",
      "      hexagon       0.0      0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(df.sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cd6a868f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>-0.479952</td>\n",
       "      <td>-0.999462</td>\n",
       "      <td>-2.019059</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>-3.407414</td>\n",
       "      <td>-1.967171</td>\n",
       "      <td>-2.712019</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>-4.725489</td>\n",
       "      <td>-4.844502</td>\n",
       "      <td>-3.728686</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-06</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C    D    F\n",
       "2013-01-01       NaN       NaN       NaN  NaN  NaN\n",
       "2013-01-02       NaN       NaN       NaN  NaN  NaN\n",
       "2013-01-03 -0.479952 -0.999462 -2.019059  4.0  1.0\n",
       "2013-01-04 -3.407414 -1.967171 -2.712019  2.0  0.0\n",
       "2013-01-05 -4.725489 -4.844502 -3.728686  0.0 -1.0\n",
       "2013-01-06       NaN       NaN       NaN  NaN  NaN"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sub(s, axis='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422add72",
   "metadata": {},
   "source": [
    "### Apply 函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f1f386",
   "metadata": {},
   "source": [
    "**Apply** 函数处理数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2a4120fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.523567</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>-0.107001</td>\n",
       "      <td>-0.540959</td>\n",
       "      <td>0.890121</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>0.413046</td>\n",
       "      <td>-0.540421</td>\n",
       "      <td>-0.128938</td>\n",
       "      <td>15</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>0.005633</td>\n",
       "      <td>0.492408</td>\n",
       "      <td>0.159043</td>\n",
       "      <td>20</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>0.280143</td>\n",
       "      <td>0.647905</td>\n",
       "      <td>1.430356</td>\n",
       "      <td>25</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-06</th>\n",
       "      <td>1.522402</td>\n",
       "      <td>0.673422</td>\n",
       "      <td>3.486357</td>\n",
       "      <td>30</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C   D     F\n",
       "2013-01-01  0.000000  0.000000  0.523567   5   NaN\n",
       "2013-01-02 -0.107001 -0.540959  0.890121  10   1.0\n",
       "2013-01-03  0.413046 -0.540421 -0.128938  15   3.0\n",
       "2013-01-04  0.005633  0.492408  0.159043  20   6.0\n",
       "2013-01-05  0.280143  0.647905  1.430356  25  10.0\n",
       "2013-01-06  1.522402  0.673422  3.486357  30  15.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.apply(np.cumsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b5e4a27c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    1.649672\n",
       "B    1.573788\n",
       "C    3.075059\n",
       "D    0.000000\n",
       "F    4.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.apply(lambda x: x.max() - x.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d828673c",
   "metadata": {},
   "source": [
    "### 直方图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cd94d2cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5\n",
       "1    3\n",
       "2    2\n",
       "3    6\n",
       "4    3\n",
       "5    6\n",
       "6    2\n",
       "7    3\n",
       "8    3\n",
       "9    5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(np.random.randint(0, 7, size=10))\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bc88a1f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    4\n",
       "5    2\n",
       "2    2\n",
       "6    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00f63db",
   "metadata": {},
   "source": [
    "### 字符串方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e969626f",
   "metadata": {},
   "source": [
    "**Series** 的 **str** 属性包含**一组字符串处理功能**，如下列代码所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "83b10bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       a\n",
       "1       b\n",
       "2       c\n",
       "3    aaba\n",
       "4    baca\n",
       "5     NaN\n",
       "6    caba\n",
       "7     dog\n",
       "8     cat\n",
       "dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(['A', 'B', 'C', 'Aaba', 'Baca', np.nan, 'CABA', 'dog', 'cat'])\n",
    "s.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15703e39",
   "metadata": {},
   "source": [
    "## 合并（Merge）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b955464e",
   "metadata": {},
   "source": [
    "### 结合（Concat）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c91d3fd",
   "metadata": {},
   "source": [
    "**Pandas** 提供了多种**将 Series、DataFrame 对象组合**在一起的功能，用**索引**与**关联**代数功能的**多种设置逻辑**可执行**连接（join）与合并（merge）**操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fe5940",
   "metadata": {},
   "source": [
    "**concat()** 用于连接 **Pandas** 对象："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "68b42bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.413695</td>\n",
       "      <td>-0.474337</td>\n",
       "      <td>1.119029</td>\n",
       "      <td>-1.477214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.337496</td>\n",
       "      <td>-0.469700</td>\n",
       "      <td>-1.005206</td>\n",
       "      <td>1.420110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.037803</td>\n",
       "      <td>-1.180721</td>\n",
       "      <td>0.638706</td>\n",
       "      <td>0.407220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.268550</td>\n",
       "      <td>-0.482290</td>\n",
       "      <td>-0.584129</td>\n",
       "      <td>0.057961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.861340</td>\n",
       "      <td>1.162071</td>\n",
       "      <td>0.354420</td>\n",
       "      <td>-0.489965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.541881</td>\n",
       "      <td>-2.225279</td>\n",
       "      <td>-1.290135</td>\n",
       "      <td>-1.737622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.668690</td>\n",
       "      <td>-1.011641</td>\n",
       "      <td>0.632592</td>\n",
       "      <td>0.471642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.562179</td>\n",
       "      <td>0.453225</td>\n",
       "      <td>0.769147</td>\n",
       "      <td>-0.081813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.188952</td>\n",
       "      <td>-1.192804</td>\n",
       "      <td>0.038848</td>\n",
       "      <td>0.226716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.310763</td>\n",
       "      <td>1.217358</td>\n",
       "      <td>-0.745495</td>\n",
       "      <td>-0.692988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3\n",
       "0 -0.413695 -0.474337  1.119029 -1.477214\n",
       "1 -0.337496 -0.469700 -1.005206  1.420110\n",
       "2  0.037803 -1.180721  0.638706  0.407220\n",
       "3  0.268550 -0.482290 -0.584129  0.057961\n",
       "4  1.861340  1.162071  0.354420 -0.489965\n",
       "5  0.541881 -2.225279 -1.290135 -1.737622\n",
       "6  0.668690 -1.011641  0.632592  0.471642\n",
       "7 -1.562179  0.453225  0.769147 -0.081813\n",
       "8  0.188952 -1.192804  0.038848  0.226716\n",
       "9  0.310763  1.217358 -0.745495 -0.692988"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(10, 4))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5d6a3c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.413695</td>\n",
       "      <td>-0.474337</td>\n",
       "      <td>1.119029</td>\n",
       "      <td>-1.477214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.337496</td>\n",
       "      <td>-0.469700</td>\n",
       "      <td>-1.005206</td>\n",
       "      <td>1.420110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.037803</td>\n",
       "      <td>-1.180721</td>\n",
       "      <td>0.638706</td>\n",
       "      <td>0.407220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.268550</td>\n",
       "      <td>-0.482290</td>\n",
       "      <td>-0.584129</td>\n",
       "      <td>0.057961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.861340</td>\n",
       "      <td>1.162071</td>\n",
       "      <td>0.354420</td>\n",
       "      <td>-0.489965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.541881</td>\n",
       "      <td>-2.225279</td>\n",
       "      <td>-1.290135</td>\n",
       "      <td>-1.737622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.668690</td>\n",
       "      <td>-1.011641</td>\n",
       "      <td>0.632592</td>\n",
       "      <td>0.471642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.562179</td>\n",
       "      <td>0.453225</td>\n",
       "      <td>0.769147</td>\n",
       "      <td>-0.081813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.188952</td>\n",
       "      <td>-1.192804</td>\n",
       "      <td>0.038848</td>\n",
       "      <td>0.226716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.310763</td>\n",
       "      <td>1.217358</td>\n",
       "      <td>-0.745495</td>\n",
       "      <td>-0.692988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3\n",
       "0 -0.413695 -0.474337  1.119029 -1.477214\n",
       "1 -0.337496 -0.469700 -1.005206  1.420110\n",
       "2  0.037803 -1.180721  0.638706  0.407220\n",
       "3  0.268550 -0.482290 -0.584129  0.057961\n",
       "4  1.861340  1.162071  0.354420 -0.489965\n",
       "5  0.541881 -2.225279 -1.290135 -1.737622\n",
       "6  0.668690 -1.011641  0.632592  0.471642\n",
       "7 -1.562179  0.453225  0.769147 -0.081813\n",
       "8  0.188952 -1.192804  0.038848  0.226716\n",
       "9  0.310763  1.217358 -0.745495 -0.692988"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 分解为多组\n",
    "pieces = [df[:3], df[3:7], df[7:]]\n",
    "pd.concat(pieces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e09729c",
   "metadata": {},
   "source": [
    "### 连接（join）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109ca074",
   "metadata": {},
   "source": [
    "**SQL** 风格的合并。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "22d874c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>lval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>foo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>foo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   key  lval\n",
       "0  foo     1\n",
       "1  foo     2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left = pd.DataFrame({'key': ['foo', 'foo'], 'lval': [1, 2]})\n",
    "right = pd.DataFrame({'key': ['foo', 'foo'], 'rval': [4, 5]})\n",
    "left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "135320ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>rval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>foo</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>foo</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   key  rval\n",
       "0  foo     4\n",
       "1  foo     5"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "42fbb74f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>lval</th>\n",
       "      <th>rval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>foo</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>foo</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>foo</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>foo</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   key  lval  rval\n",
       "0  foo     1     4\n",
       "1  foo     1     5\n",
       "2  foo     2     4\n",
       "3  foo     2     5"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(left, right, on='key')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff2f60b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fecaf14f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>lval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>foo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bar</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   key  lval\n",
       "0  foo     1\n",
       "1  bar     2"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left = pd.DataFrame({'key': ['foo', 'bar'], 'lval': [1, 2]})\n",
    "right = pd.DataFrame({'key': ['foo', 'bar'], 'rval': [4, 5]})\n",
    "left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "265d0fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>rval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>foo</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bar</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   key  rval\n",
       "0  foo     4\n",
       "1  bar     5"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e0f1180c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>lval</th>\n",
       "      <th>rval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>foo</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bar</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   key  lval  rval\n",
       "0  foo     1     4\n",
       "1  bar     2     5"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(left, right, on='key')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caed3d8c",
   "metadata": {},
   "source": [
    "### 追加（Append）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb3b53b",
   "metadata": {},
   "source": [
    "为 **DataFrame** 追加行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ba256c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.086357</td>\n",
       "      <td>0.277443</td>\n",
       "      <td>-0.361474</td>\n",
       "      <td>-0.229857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.502080</td>\n",
       "      <td>0.042270</td>\n",
       "      <td>-0.539350</td>\n",
       "      <td>-0.444695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.364625</td>\n",
       "      <td>0.468748</td>\n",
       "      <td>-0.413906</td>\n",
       "      <td>0.224215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.776840</td>\n",
       "      <td>-1.185414</td>\n",
       "      <td>1.143900</td>\n",
       "      <td>-0.277411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.058171</td>\n",
       "      <td>0.760081</td>\n",
       "      <td>-0.674117</td>\n",
       "      <td>-1.339868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.403904</td>\n",
       "      <td>-0.933528</td>\n",
       "      <td>0.094520</td>\n",
       "      <td>2.310217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.497589</td>\n",
       "      <td>-0.455963</td>\n",
       "      <td>-0.200920</td>\n",
       "      <td>-0.596147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.679670</td>\n",
       "      <td>-1.163084</td>\n",
       "      <td>1.192630</td>\n",
       "      <td>1.455118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         B         C         D\n",
       "0 -0.086357  0.277443 -0.361474 -0.229857\n",
       "1 -0.502080  0.042270 -0.539350 -0.444695\n",
       "2 -0.364625  0.468748 -0.413906  0.224215\n",
       "3  1.776840 -1.185414  1.143900 -0.277411\n",
       "4  0.058171  0.760081 -0.674117 -1.339868\n",
       "5 -0.403904 -0.933528  0.094520  2.310217\n",
       "6  0.497589 -0.455963 -0.200920 -0.596147\n",
       "7 -0.679670 -1.163084  1.192630  1.455118"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(8, 4), columns=['A', 'B', 'C', 'D'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "30144d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.086357</td>\n",
       "      <td>0.277443</td>\n",
       "      <td>-0.361474</td>\n",
       "      <td>-0.229857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.502080</td>\n",
       "      <td>0.042270</td>\n",
       "      <td>-0.539350</td>\n",
       "      <td>-0.444695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.364625</td>\n",
       "      <td>0.468748</td>\n",
       "      <td>-0.413906</td>\n",
       "      <td>0.224215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.776840</td>\n",
       "      <td>-1.185414</td>\n",
       "      <td>1.143900</td>\n",
       "      <td>-0.277411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.058171</td>\n",
       "      <td>0.760081</td>\n",
       "      <td>-0.674117</td>\n",
       "      <td>-1.339868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.403904</td>\n",
       "      <td>-0.933528</td>\n",
       "      <td>0.094520</td>\n",
       "      <td>2.310217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.497589</td>\n",
       "      <td>-0.455963</td>\n",
       "      <td>-0.200920</td>\n",
       "      <td>-0.596147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.679670</td>\n",
       "      <td>-1.163084</td>\n",
       "      <td>1.192630</td>\n",
       "      <td>1.455118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.776840</td>\n",
       "      <td>-1.185414</td>\n",
       "      <td>1.143900</td>\n",
       "      <td>-0.277411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         B         C         D\n",
       "0 -0.086357  0.277443 -0.361474 -0.229857\n",
       "1 -0.502080  0.042270 -0.539350 -0.444695\n",
       "2 -0.364625  0.468748 -0.413906  0.224215\n",
       "3  1.776840 -1.185414  1.143900 -0.277411\n",
       "4  0.058171  0.760081 -0.674117 -1.339868\n",
       "5 -0.403904 -0.933528  0.094520  2.310217\n",
       "6  0.497589 -0.455963 -0.200920 -0.596147\n",
       "7 -0.679670 -1.163084  1.192630  1.455118\n",
       "8  1.776840 -1.185414  1.143900 -0.277411"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = df.iloc[3]\n",
    "df.append(s, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36685bf5",
   "metadata": {},
   "source": [
    "## 分组（Grouping）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e937633",
   "metadata": {},
   "source": [
    "“group by” 指的是涵盖下列一项或多项步骤的处理流程：\n",
    "\n",
    "- **分割**：按条件把数据分割成多组；\n",
    "\n",
    "- **应用**：为每组单独应用函数；\n",
    "\n",
    "- **组合**：将处理结果组合成一个数据结构。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0b6b8b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>foo</td>\n",
       "      <td>one</td>\n",
       "      <td>0.530552</td>\n",
       "      <td>0.960056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bar</td>\n",
       "      <td>one</td>\n",
       "      <td>-1.147416</td>\n",
       "      <td>-0.676909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>foo</td>\n",
       "      <td>two</td>\n",
       "      <td>1.742953</td>\n",
       "      <td>1.060401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bar</td>\n",
       "      <td>three</td>\n",
       "      <td>-0.908172</td>\n",
       "      <td>0.667082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>foo</td>\n",
       "      <td>two</td>\n",
       "      <td>-0.028742</td>\n",
       "      <td>-0.204268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bar</td>\n",
       "      <td>two</td>\n",
       "      <td>1.012929</td>\n",
       "      <td>-0.221234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>foo</td>\n",
       "      <td>one</td>\n",
       "      <td>1.120060</td>\n",
       "      <td>0.532136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>foo</td>\n",
       "      <td>three</td>\n",
       "      <td>-1.013321</td>\n",
       "      <td>-1.983258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A      B         C         D\n",
       "0  foo    one  0.530552  0.960056\n",
       "1  bar    one -1.147416 -0.676909\n",
       "2  foo    two  1.742953  1.060401\n",
       "3  bar  three -0.908172  0.667082\n",
       "4  foo    two -0.028742 -0.204268\n",
       "5  bar    two  1.012929 -0.221234\n",
       "6  foo    one  1.120060  0.532136\n",
       "7  foo  three -1.013321 -1.983258"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'A': ['foo', 'bar', 'foo', 'bar',\n",
    "                         'foo', 'bar', 'foo', 'foo'],\n",
    "                   'B': ['one', 'one', 'two', 'three',\n",
    "                         'two', 'two', 'one', 'three'],\n",
    "                   'C': np.random.randn(8),\n",
    "                   'D': np.random.randn(8)})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a36c36",
   "metadata": {},
   "source": [
    "先分组，再用 **sum()** 函数计算每组的汇总数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ad250b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bar</th>\n",
       "      <td>-1.042659</td>\n",
       "      <td>-0.231061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foo</th>\n",
       "      <td>2.351501</td>\n",
       "      <td>0.365067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            C         D\n",
       "A                      \n",
       "bar -1.042659 -0.231061\n",
       "foo  2.351501  0.365067"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('A').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea12d25",
   "metadata": {},
   "source": [
    "多列**分组**后，生成**多层索引**，也可以应用 **sum** 函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e895f5ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">bar</th>\n",
       "      <th>one</th>\n",
       "      <td>-1.147416</td>\n",
       "      <td>-0.676909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>three</th>\n",
       "      <td>-0.908172</td>\n",
       "      <td>0.667082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>1.012929</td>\n",
       "      <td>-0.221234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">foo</th>\n",
       "      <th>one</th>\n",
       "      <td>1.650612</td>\n",
       "      <td>1.492192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>three</th>\n",
       "      <td>-1.013321</td>\n",
       "      <td>-1.983258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>1.714210</td>\n",
       "      <td>0.856133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  C         D\n",
       "A   B                        \n",
       "bar one   -1.147416 -0.676909\n",
       "    three -0.908172  0.667082\n",
       "    two    1.012929 -0.221234\n",
       "foo one    1.650612  1.492192\n",
       "    three -1.013321 -1.983258\n",
       "    two    1.714210  0.856133"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['A', 'B']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e852c19a",
   "metadata": {},
   "source": [
    "## 重塑（Reshaping）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fbe701",
   "metadata": {},
   "source": [
    "### 堆叠（Stack）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "21e5e0bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bar', 'one'),\n",
       " ('bar', 'two'),\n",
       " ('baz', 'one'),\n",
       " ('baz', 'two'),\n",
       " ('foo', 'one'),\n",
       " ('foo', 'two'),\n",
       " ('qux', 'one'),\n",
       " ('qux', 'two')]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuples = list(zip(*[['bar', 'bar', 'baz', 'baz',\n",
    "                     'foo', 'foo', 'qux', 'qux'],\n",
    "                    ['one', 'two', 'one', 'two',\n",
    "                     'one', 'two', 'one', 'two']]))\n",
    "tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "697e7609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method from_tuples in module pandas.core.indexes.multi:\n",
      "\n",
      "from_tuples(tuples: 'Iterable[tuple[Hashable, ...]]', sortorder: 'int | None' = None, names: 'Sequence[Hashable] | None' = None) -> 'MultiIndex' method of builtins.type instance\n",
      "    Convert list of tuples to MultiIndex.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    tuples : list / sequence of tuple-likes\n",
      "        Each tuple is the index of one row/column.\n",
      "    sortorder : int or None\n",
      "        Level of sortedness (must be lexicographically sorted by that\n",
      "        level).\n",
      "    names : list / sequence of str, optional\n",
      "        Names for the levels in the index.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    MultiIndex\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    MultiIndex.from_arrays : Convert list of arrays to MultiIndex.\n",
      "    MultiIndex.from_product : Make a MultiIndex from cartesian product\n",
      "                              of iterables.\n",
      "    MultiIndex.from_frame : Make a MultiIndex from a DataFrame.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> tuples = [(1, 'red'), (1, 'blue'),\n",
      "    ...           (2, 'red'), (2, 'blue')]\n",
      "    >>> pd.MultiIndex.from_tuples(tuples, names=('number', 'color'))\n",
      "    MultiIndex([(1,  'red'),\n",
      "                (1, 'blue'),\n",
      "                (2,  'red'),\n",
      "                (2, 'blue')],\n",
      "               names=['number', 'color'])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.MultiIndex.from_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "40d8033f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <th>second</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">bar</th>\n",
       "      <th>one</th>\n",
       "      <td>1.011819</td>\n",
       "      <td>-1.239451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>2.117269</td>\n",
       "      <td>1.659882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">baz</th>\n",
       "      <th>one</th>\n",
       "      <td>1.162383</td>\n",
       "      <td>1.481973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>0.023506</td>\n",
       "      <td>-2.871941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     A         B\n",
       "first second                    \n",
       "bar   one     1.011819 -1.239451\n",
       "      two     2.117269  1.659882\n",
       "baz   one     1.162383  1.481973\n",
       "      two     0.023506 -2.871941"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pd.MultiIndex.from_tuples(tuples, names=['first', 'second'])\n",
    "df = pd.DataFrame(np.random.randn(8, 2), index=index, columns=['A', 'B'])\n",
    "df2 = df[:4]\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc808317",
   "metadata": {},
   "source": [
    "**stack()** 方法把 **DataFrame** 列压缩至一层："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "66746692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method stack in module pandas.core.frame:\n",
      "\n",
      "stack(level: 'Level' = -1, dropna: 'bool' = True) method of pandas.core.frame.DataFrame instance\n",
      "    Stack the prescribed level(s) from columns to index.\n",
      "    \n",
      "    Return a reshaped DataFrame or Series having a multi-level\n",
      "    index with one or more new inner-most levels compared to the current\n",
      "    DataFrame. The new inner-most levels are created by pivoting the\n",
      "    columns of the current dataframe:\n",
      "    \n",
      "      - if the columns have a single level, the output is a Series;\n",
      "      - if the columns have multiple levels, the new index\n",
      "        level(s) is (are) taken from the prescribed level(s) and\n",
      "        the output is a DataFrame.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    level : int, str, list, default -1\n",
      "        Level(s) to stack from the column axis onto the index\n",
      "        axis, defined as one index or label, or a list of indices\n",
      "        or labels.\n",
      "    dropna : bool, default True\n",
      "        Whether to drop rows in the resulting Frame/Series with\n",
      "        missing values. Stacking a column level onto the index\n",
      "        axis can create combinations of index and column values\n",
      "        that are missing from the original dataframe. See Examples\n",
      "        section.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame or Series\n",
      "        Stacked dataframe or series.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.unstack : Unstack prescribed level(s) from index axis\n",
      "         onto column axis.\n",
      "    DataFrame.pivot : Reshape dataframe from long format to wide\n",
      "         format.\n",
      "    DataFrame.pivot_table : Create a spreadsheet-style pivot table\n",
      "         as a DataFrame.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    The function is named by analogy with a collection of books\n",
      "    being reorganized from being side by side on a horizontal\n",
      "    position (the columns of the dataframe) to being stacked\n",
      "    vertically on top of each other (in the index of the\n",
      "    dataframe).\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    **Single level columns**\n",
      "    \n",
      "    >>> df_single_level_cols = pd.DataFrame([[0, 1], [2, 3]],\n",
      "    ...                                     index=['cat', 'dog'],\n",
      "    ...                                     columns=['weight', 'height'])\n",
      "    \n",
      "    Stacking a dataframe with a single level column axis returns a Series:\n",
      "    \n",
      "    >>> df_single_level_cols\n",
      "         weight height\n",
      "    cat       0      1\n",
      "    dog       2      3\n",
      "    >>> df_single_level_cols.stack()\n",
      "    cat  weight    0\n",
      "         height    1\n",
      "    dog  weight    2\n",
      "         height    3\n",
      "    dtype: int64\n",
      "    \n",
      "    **Multi level columns: simple case**\n",
      "    \n",
      "    >>> multicol1 = pd.MultiIndex.from_tuples([('weight', 'kg'),\n",
      "    ...                                        ('weight', 'pounds')])\n",
      "    >>> df_multi_level_cols1 = pd.DataFrame([[1, 2], [2, 4]],\n",
      "    ...                                     index=['cat', 'dog'],\n",
      "    ...                                     columns=multicol1)\n",
      "    \n",
      "    Stacking a dataframe with a multi-level column axis:\n",
      "    \n",
      "    >>> df_multi_level_cols1\n",
      "         weight\n",
      "             kg    pounds\n",
      "    cat       1        2\n",
      "    dog       2        4\n",
      "    >>> df_multi_level_cols1.stack()\n",
      "                weight\n",
      "    cat kg           1\n",
      "        pounds       2\n",
      "    dog kg           2\n",
      "        pounds       4\n",
      "    \n",
      "    **Missing values**\n",
      "    \n",
      "    >>> multicol2 = pd.MultiIndex.from_tuples([('weight', 'kg'),\n",
      "    ...                                        ('height', 'm')])\n",
      "    >>> df_multi_level_cols2 = pd.DataFrame([[1.0, 2.0], [3.0, 4.0]],\n",
      "    ...                                     index=['cat', 'dog'],\n",
      "    ...                                     columns=multicol2)\n",
      "    \n",
      "    It is common to have missing values when stacking a dataframe\n",
      "    with multi-level columns, as the stacked dataframe typically\n",
      "    has more values than the original dataframe. Missing values\n",
      "    are filled with NaNs:\n",
      "    \n",
      "    >>> df_multi_level_cols2\n",
      "        weight height\n",
      "            kg      m\n",
      "    cat    1.0    2.0\n",
      "    dog    3.0    4.0\n",
      "    >>> df_multi_level_cols2.stack()\n",
      "            height  weight\n",
      "    cat kg     NaN     1.0\n",
      "        m      2.0     NaN\n",
      "    dog kg     NaN     3.0\n",
      "        m      4.0     NaN\n",
      "    \n",
      "    **Prescribing the level(s) to be stacked**\n",
      "    \n",
      "    The first parameter controls which level or levels are stacked:\n",
      "    \n",
      "    >>> df_multi_level_cols2.stack(0)\n",
      "                 kg    m\n",
      "    cat height  NaN  2.0\n",
      "        weight  1.0  NaN\n",
      "    dog height  NaN  4.0\n",
      "        weight  3.0  NaN\n",
      "    >>> df_multi_level_cols2.stack([0, 1])\n",
      "    cat  height  m     2.0\n",
      "         weight  kg    1.0\n",
      "    dog  height  m     4.0\n",
      "         weight  kg    3.0\n",
      "    dtype: float64\n",
      "    \n",
      "    **Dropping missing values**\n",
      "    \n",
      "    >>> df_multi_level_cols3 = pd.DataFrame([[None, 1.0], [2.0, 3.0]],\n",
      "    ...                                     index=['cat', 'dog'],\n",
      "    ...                                     columns=multicol2)\n",
      "    \n",
      "    Note that rows where all values are missing are dropped by\n",
      "    default but this behaviour can be controlled via the dropna\n",
      "    keyword parameter:\n",
      "    \n",
      "    >>> df_multi_level_cols3\n",
      "        weight height\n",
      "            kg      m\n",
      "    cat    NaN    1.0\n",
      "    dog    2.0    3.0\n",
      "    >>> df_multi_level_cols3.stack(dropna=False)\n",
      "            height  weight\n",
      "    cat kg     NaN     NaN\n",
      "        m      1.0     NaN\n",
      "    dog kg     NaN     2.0\n",
      "        m      3.0     NaN\n",
      "    >>> df_multi_level_cols3.stack(dropna=True)\n",
      "            height  weight\n",
      "    cat m      1.0     NaN\n",
      "    dog kg     NaN     2.0\n",
      "        m      3.0     NaN\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(df2.stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1df0fa9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first  second   \n",
       "bar    one     A    1.011819\n",
       "               B   -1.239451\n",
       "       two     A    2.117269\n",
       "               B    1.659882\n",
       "baz    one     A    1.162383\n",
       "               B    1.481973\n",
       "       two     A    0.023506\n",
       "               B   -2.871941\n",
       "dtype: float64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked = df2.stack()\n",
    "stacked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8824b1",
   "metadata": {},
   "source": [
    "**压缩后**的 **DataFrame** 或 **Series** 具有多层索引，**stack()** 的逆操作是 **unstack()**，默认为**拆叠**最后一层："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e6a67bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method unstack in module pandas.core.series:\n",
      "\n",
      "unstack(level=-1, fill_value=None) -> 'DataFrame' method of pandas.core.series.Series instance\n",
      "    Unstack, also known as pivot, Series with MultiIndex to produce DataFrame.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    level : int, str, or list of these, default last level\n",
      "        Level(s) to unstack, can pass level name.\n",
      "    fill_value : scalar value, default None\n",
      "        Value to use when replacing NaN values.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame\n",
      "        Unstacked Series.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> s = pd.Series([1, 2, 3, 4],\n",
      "    ...               index=pd.MultiIndex.from_product([['one', 'two'],\n",
      "    ...                                                 ['a', 'b']]))\n",
      "    >>> s\n",
      "    one  a    1\n",
      "         b    2\n",
      "    two  a    3\n",
      "         b    4\n",
      "    dtype: int64\n",
      "    \n",
      "    >>> s.unstack(level=-1)\n",
      "         a  b\n",
      "    one  1  2\n",
      "    two  3  4\n",
      "    \n",
      "    >>> s.unstack(level=0)\n",
      "       one  two\n",
      "    a    1    3\n",
      "    b    2    4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(stacked.unstack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9c454555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <th>second</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">bar</th>\n",
       "      <th>one</th>\n",
       "      <td>1.011819</td>\n",
       "      <td>-1.239451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>2.117269</td>\n",
       "      <td>1.659882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">baz</th>\n",
       "      <th>one</th>\n",
       "      <td>1.162383</td>\n",
       "      <td>1.481973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>0.023506</td>\n",
       "      <td>-2.871941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     A         B\n",
       "first second                    \n",
       "bar   one     1.011819 -1.239451\n",
       "      two     2.117269  1.659882\n",
       "baz   one     1.162383  1.481973\n",
       "      two     0.023506 -2.871941"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3246733a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <th>second</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">bar</th>\n",
       "      <th>one</th>\n",
       "      <td>1.011819</td>\n",
       "      <td>-1.239451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>2.117269</td>\n",
       "      <td>1.659882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">baz</th>\n",
       "      <th>one</th>\n",
       "      <td>1.162383</td>\n",
       "      <td>1.481973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>0.023506</td>\n",
       "      <td>-2.871941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     A         B\n",
       "first second                    \n",
       "bar   one     1.011819 -1.239451\n",
       "      two     2.117269  1.659882\n",
       "baz   one     1.162383  1.481973\n",
       "      two     0.023506 -2.871941"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked.unstack(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "80aed5cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>second</th>\n",
       "      <th>one</th>\n",
       "      <th>two</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">bar</th>\n",
       "      <th>A</th>\n",
       "      <td>1.011819</td>\n",
       "      <td>2.117269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>-1.239451</td>\n",
       "      <td>1.659882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">baz</th>\n",
       "      <th>A</th>\n",
       "      <td>1.162383</td>\n",
       "      <td>0.023506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>1.481973</td>\n",
       "      <td>-2.871941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "second        one       two\n",
       "first                      \n",
       "bar   A  1.011819  2.117269\n",
       "      B -1.239451  1.659882\n",
       "baz   A  1.162383  0.023506\n",
       "      B  1.481973 -2.871941"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked.unstack(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "204ddfdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>bar</th>\n",
       "      <th>baz</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">one</th>\n",
       "      <th>A</th>\n",
       "      <td>1.011819</td>\n",
       "      <td>1.162383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>-1.239451</td>\n",
       "      <td>1.481973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">two</th>\n",
       "      <th>A</th>\n",
       "      <td>2.117269</td>\n",
       "      <td>0.023506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>1.659882</td>\n",
       "      <td>-2.871941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "first          bar       baz\n",
       "second                      \n",
       "one    A  1.011819  1.162383\n",
       "       B -1.239451  1.481973\n",
       "two    A  2.117269  0.023506\n",
       "       B  1.659882 -2.871941"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked.unstack(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773a0ddf",
   "metadata": {},
   "source": [
    "## 数据透视表（Pivot Tables）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "26ad1179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one</td>\n",
       "      <td>A</td>\n",
       "      <td>foo</td>\n",
       "      <td>-0.000842</td>\n",
       "      <td>-0.663650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>one</td>\n",
       "      <td>B</td>\n",
       "      <td>foo</td>\n",
       "      <td>-0.725096</td>\n",
       "      <td>1.008857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>two</td>\n",
       "      <td>C</td>\n",
       "      <td>foo</td>\n",
       "      <td>-0.059434</td>\n",
       "      <td>-0.897582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>three</td>\n",
       "      <td>A</td>\n",
       "      <td>bar</td>\n",
       "      <td>1.209748</td>\n",
       "      <td>0.330340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>one</td>\n",
       "      <td>B</td>\n",
       "      <td>bar</td>\n",
       "      <td>1.395529</td>\n",
       "      <td>-1.414638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>one</td>\n",
       "      <td>C</td>\n",
       "      <td>bar</td>\n",
       "      <td>-1.375109</td>\n",
       "      <td>-0.555869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>two</td>\n",
       "      <td>A</td>\n",
       "      <td>foo</td>\n",
       "      <td>-0.326721</td>\n",
       "      <td>0.172933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>three</td>\n",
       "      <td>B</td>\n",
       "      <td>foo</td>\n",
       "      <td>-0.328824</td>\n",
       "      <td>-1.023532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>one</td>\n",
       "      <td>C</td>\n",
       "      <td>foo</td>\n",
       "      <td>0.297379</td>\n",
       "      <td>0.189351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>one</td>\n",
       "      <td>A</td>\n",
       "      <td>bar</td>\n",
       "      <td>-0.420383</td>\n",
       "      <td>0.787712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>two</td>\n",
       "      <td>B</td>\n",
       "      <td>bar</td>\n",
       "      <td>0.500231</td>\n",
       "      <td>0.970724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>three</td>\n",
       "      <td>C</td>\n",
       "      <td>bar</td>\n",
       "      <td>-2.790985</td>\n",
       "      <td>0.477222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        A  B    C         D         E\n",
       "0     one  A  foo -0.000842 -0.663650\n",
       "1     one  B  foo -0.725096  1.008857\n",
       "2     two  C  foo -0.059434 -0.897582\n",
       "3   three  A  bar  1.209748  0.330340\n",
       "4     one  B  bar  1.395529 -1.414638\n",
       "5     one  C  bar -1.375109 -0.555869\n",
       "6     two  A  foo -0.326721  0.172933\n",
       "7   three  B  foo -0.328824 -1.023532\n",
       "8     one  C  foo  0.297379  0.189351\n",
       "9     one  A  bar -0.420383  0.787712\n",
       "10    two  B  bar  0.500231  0.970724\n",
       "11  three  C  bar -2.790985  0.477222"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'A': ['one', 'one', 'two', 'three'] * 3,\n",
    "                   'B': ['A', 'B', 'C'] * 4,\n",
    "                   'C': ['foo', 'foo', 'foo', 'bar', 'bar', 'bar'] * 2,\n",
    "                   'D': np.random.randn(12),\n",
    "                   'E': np.random.randn(12)})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdf949a",
   "metadata": {},
   "source": [
    "用上述数据生成**数据透视表**非常简单："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1bb85ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function pivot_table in module pandas.core.reshape.pivot:\n",
      "\n",
      "pivot_table(data: 'DataFrame', values=None, index=None, columns=None, aggfunc: 'AggFuncType' = 'mean', fill_value=None, margins=False, dropna=True, margins_name='All', observed=False, sort=True) -> 'DataFrame'\n",
      "    Create a spreadsheet-style pivot table as a DataFrame.\n",
      "    \n",
      "    The levels in the pivot table will be stored in MultiIndex objects\n",
      "    (hierarchical indexes) on the index and columns of the result DataFrame.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    data : DataFrame\n",
      "    values : column to aggregate, optional\n",
      "    index : column, Grouper, array, or list of the previous\n",
      "        If an array is passed, it must be the same length as the data. The\n",
      "        list can contain any of the other types (except list).\n",
      "        Keys to group by on the pivot table index.  If an array is passed,\n",
      "        it is being used as the same manner as column values.\n",
      "    columns : column, Grouper, array, or list of the previous\n",
      "        If an array is passed, it must be the same length as the data. The\n",
      "        list can contain any of the other types (except list).\n",
      "        Keys to group by on the pivot table column.  If an array is passed,\n",
      "        it is being used as the same manner as column values.\n",
      "    aggfunc : function, list of functions, dict, default numpy.mean\n",
      "        If list of functions passed, the resulting pivot table will have\n",
      "        hierarchical columns whose top level are the function names\n",
      "        (inferred from the function objects themselves)\n",
      "        If dict is passed, the key is column to aggregate and value\n",
      "        is function or list of functions.\n",
      "    fill_value : scalar, default None\n",
      "        Value to replace missing values with (in the resulting pivot table,\n",
      "        after aggregation).\n",
      "    margins : bool, default False\n",
      "        Add all row / columns (e.g. for subtotal / grand totals).\n",
      "    dropna : bool, default True\n",
      "        Do not include columns whose entries are all NaN.\n",
      "    margins_name : str, default 'All'\n",
      "        Name of the row / column that will contain the totals\n",
      "        when margins is True.\n",
      "    observed : bool, default False\n",
      "        This only applies if any of the groupers are Categoricals.\n",
      "        If True: only show observed values for categorical groupers.\n",
      "        If False: show all values for categorical groupers.\n",
      "    \n",
      "        .. versionchanged:: 0.25.0\n",
      "    \n",
      "    sort : bool, default True\n",
      "        Specifies if the result should be sorted.\n",
      "    \n",
      "        .. versionadded:: 1.3.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame\n",
      "        An Excel style pivot table.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.pivot : Pivot without aggregation that can handle\n",
      "        non-numeric data.\n",
      "    DataFrame.melt: Unpivot a DataFrame from wide to long format,\n",
      "        optionally leaving identifiers set.\n",
      "    wide_to_long : Wide panel to long format. Less flexible but more\n",
      "        user-friendly than melt.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = pd.DataFrame({\"A\": [\"foo\", \"foo\", \"foo\", \"foo\", \"foo\",\n",
      "    ...                          \"bar\", \"bar\", \"bar\", \"bar\"],\n",
      "    ...                    \"B\": [\"one\", \"one\", \"one\", \"two\", \"two\",\n",
      "    ...                          \"one\", \"one\", \"two\", \"two\"],\n",
      "    ...                    \"C\": [\"small\", \"large\", \"large\", \"small\",\n",
      "    ...                          \"small\", \"large\", \"small\", \"small\",\n",
      "    ...                          \"large\"],\n",
      "    ...                    \"D\": [1, 2, 2, 3, 3, 4, 5, 6, 7],\n",
      "    ...                    \"E\": [2, 4, 5, 5, 6, 6, 8, 9, 9]})\n",
      "    >>> df\n",
      "         A    B      C  D  E\n",
      "    0  foo  one  small  1  2\n",
      "    1  foo  one  large  2  4\n",
      "    2  foo  one  large  2  5\n",
      "    3  foo  two  small  3  5\n",
      "    4  foo  two  small  3  6\n",
      "    5  bar  one  large  4  6\n",
      "    6  bar  one  small  5  8\n",
      "    7  bar  two  small  6  9\n",
      "    8  bar  two  large  7  9\n",
      "    \n",
      "    This first example aggregates values by taking the sum.\n",
      "    \n",
      "    >>> table = pd.pivot_table(df, values='D', index=['A', 'B'],\n",
      "    ...                     columns=['C'], aggfunc=np.sum)\n",
      "    >>> table\n",
      "    C        large  small\n",
      "    A   B\n",
      "    bar one    4.0    5.0\n",
      "        two    7.0    6.0\n",
      "    foo one    4.0    1.0\n",
      "        two    NaN    6.0\n",
      "    \n",
      "    We can also fill missing values using the `fill_value` parameter.\n",
      "    \n",
      "    >>> table = pd.pivot_table(df, values='D', index=['A', 'B'],\n",
      "    ...                     columns=['C'], aggfunc=np.sum, fill_value=0)\n",
      "    >>> table\n",
      "    C        large  small\n",
      "    A   B\n",
      "    bar one      4      5\n",
      "        two      7      6\n",
      "    foo one      4      1\n",
      "        two      0      6\n",
      "    \n",
      "    The next example aggregates by taking the mean across multiple columns.\n",
      "    \n",
      "    >>> table = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],\n",
      "    ...                     aggfunc={'D': np.mean,\n",
      "    ...                              'E': np.mean})\n",
      "    >>> table\n",
      "                    D         E\n",
      "    A   C\n",
      "    bar large  5.500000  7.500000\n",
      "        small  5.500000  8.500000\n",
      "    foo large  2.000000  4.500000\n",
      "        small  2.333333  4.333333\n",
      "    \n",
      "    We can also calculate multiple types of aggregations for any given\n",
      "    value column.\n",
      "    \n",
      "    >>> table = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],\n",
      "    ...                     aggfunc={'D': np.mean,\n",
      "    ...                              'E': [min, max, np.mean]})\n",
      "    >>> table\n",
      "                    D    E\n",
      "                mean  max      mean  min\n",
      "    A   C\n",
      "    bar large  5.500000  9.0  7.500000  6.0\n",
      "        small  5.500000  9.0  8.500000  8.0\n",
      "    foo large  2.000000  5.0  4.500000  4.0\n",
      "        small  2.333333  6.0  4.333333  2.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.pivot_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5446375a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>bar</th>\n",
       "      <th>foo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">one</th>\n",
       "      <th>A</th>\n",
       "      <td>-0.420383</td>\n",
       "      <td>-0.000842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>1.395529</td>\n",
       "      <td>-0.725096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>-1.375109</td>\n",
       "      <td>0.297379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">three</th>\n",
       "      <th>A</th>\n",
       "      <td>1.209748</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.328824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>-2.790985</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">two</th>\n",
       "      <th>A</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.326721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.500231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.059434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "C             bar       foo\n",
       "A     B                    \n",
       "one   A -0.420383 -0.000842\n",
       "      B  1.395529 -0.725096\n",
       "      C -1.375109  0.297379\n",
       "three A  1.209748       NaN\n",
       "      B       NaN -0.328824\n",
       "      C -2.790985       NaN\n",
       "two   A       NaN -0.326721\n",
       "      B  0.500231       NaN\n",
       "      C       NaN -0.059434"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(df, values='D', index=['A', 'B'], columns=['C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679fded0",
   "metadata": {},
   "source": [
    "## 时间序列(TimeSeries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d8deff",
   "metadata": {},
   "source": [
    "**Pandas** 为频率转换时**重采样**提供了虽然简单易用，但强大高效的功能，如，将秒级的数据转换为 **5** 分钟为频率的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9b6ab8ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2012-01-01 00:00:00', '2012-01-01 00:00:01',\n",
       "               '2012-01-01 00:00:02', '2012-01-01 00:00:03',\n",
       "               '2012-01-01 00:00:04', '2012-01-01 00:00:05',\n",
       "               '2012-01-01 00:00:06', '2012-01-01 00:00:07',\n",
       "               '2012-01-01 00:00:08', '2012-01-01 00:00:09',\n",
       "               '2012-01-01 00:00:10', '2012-01-01 00:00:11',\n",
       "               '2012-01-01 00:00:12', '2012-01-01 00:00:13',\n",
       "               '2012-01-01 00:00:14', '2012-01-01 00:00:15',\n",
       "               '2012-01-01 00:00:16', '2012-01-01 00:00:17',\n",
       "               '2012-01-01 00:00:18', '2012-01-01 00:00:19',\n",
       "               '2012-01-01 00:00:20', '2012-01-01 00:00:21',\n",
       "               '2012-01-01 00:00:22', '2012-01-01 00:00:23',\n",
       "               '2012-01-01 00:00:24', '2012-01-01 00:00:25',\n",
       "               '2012-01-01 00:00:26', '2012-01-01 00:00:27',\n",
       "               '2012-01-01 00:00:28', '2012-01-01 00:00:29',\n",
       "               '2012-01-01 00:00:30', '2012-01-01 00:00:31',\n",
       "               '2012-01-01 00:00:32', '2012-01-01 00:00:33',\n",
       "               '2012-01-01 00:00:34', '2012-01-01 00:00:35',\n",
       "               '2012-01-01 00:00:36', '2012-01-01 00:00:37',\n",
       "               '2012-01-01 00:00:38', '2012-01-01 00:00:39',\n",
       "               '2012-01-01 00:00:40', '2012-01-01 00:00:41',\n",
       "               '2012-01-01 00:00:42', '2012-01-01 00:00:43',\n",
       "               '2012-01-01 00:00:44', '2012-01-01 00:00:45',\n",
       "               '2012-01-01 00:00:46', '2012-01-01 00:00:47',\n",
       "               '2012-01-01 00:00:48', '2012-01-01 00:00:49',\n",
       "               '2012-01-01 00:00:50', '2012-01-01 00:00:51',\n",
       "               '2012-01-01 00:00:52', '2012-01-01 00:00:53',\n",
       "               '2012-01-01 00:00:54', '2012-01-01 00:00:55',\n",
       "               '2012-01-01 00:00:56', '2012-01-01 00:00:57',\n",
       "               '2012-01-01 00:00:58', '2012-01-01 00:00:59',\n",
       "               '2012-01-01 00:01:00', '2012-01-01 00:01:01',\n",
       "               '2012-01-01 00:01:02', '2012-01-01 00:01:03',\n",
       "               '2012-01-01 00:01:04', '2012-01-01 00:01:05',\n",
       "               '2012-01-01 00:01:06', '2012-01-01 00:01:07',\n",
       "               '2012-01-01 00:01:08', '2012-01-01 00:01:09',\n",
       "               '2012-01-01 00:01:10', '2012-01-01 00:01:11',\n",
       "               '2012-01-01 00:01:12', '2012-01-01 00:01:13',\n",
       "               '2012-01-01 00:01:14', '2012-01-01 00:01:15',\n",
       "               '2012-01-01 00:01:16', '2012-01-01 00:01:17',\n",
       "               '2012-01-01 00:01:18', '2012-01-01 00:01:19',\n",
       "               '2012-01-01 00:01:20', '2012-01-01 00:01:21',\n",
       "               '2012-01-01 00:01:22', '2012-01-01 00:01:23',\n",
       "               '2012-01-01 00:01:24', '2012-01-01 00:01:25',\n",
       "               '2012-01-01 00:01:26', '2012-01-01 00:01:27',\n",
       "               '2012-01-01 00:01:28', '2012-01-01 00:01:29',\n",
       "               '2012-01-01 00:01:30', '2012-01-01 00:01:31',\n",
       "               '2012-01-01 00:01:32', '2012-01-01 00:01:33',\n",
       "               '2012-01-01 00:01:34', '2012-01-01 00:01:35',\n",
       "               '2012-01-01 00:01:36', '2012-01-01 00:01:37',\n",
       "               '2012-01-01 00:01:38', '2012-01-01 00:01:39'],\n",
       "              dtype='datetime64[ns]', freq='S')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = pd.date_range('1/1/2012', periods=100, freq='S')\n",
    "rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "800f4c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function randint:\n",
      "\n",
      "randint(...) method of numpy.random.mtrand.RandomState instance\n",
      "    randint(low, high=None, size=None, dtype=int)\n",
      "    \n",
      "    Return random integers from `low` (inclusive) to `high` (exclusive).\n",
      "    \n",
      "    Return random integers from the \"discrete uniform\" distribution of\n",
      "    the specified dtype in the \"half-open\" interval [`low`, `high`). If\n",
      "    `high` is None (the default), then results are from [0, `low`).\n",
      "    \n",
      "    .. note::\n",
      "        New code should use the ``integers`` method of a ``default_rng()``\n",
      "        instance instead; please see the :ref:`random-quick-start`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    low : int or array-like of ints\n",
      "        Lowest (signed) integers to be drawn from the distribution (unless\n",
      "        ``high=None``, in which case this parameter is one above the\n",
      "        *highest* such integer).\n",
      "    high : int or array-like of ints, optional\n",
      "        If provided, one above the largest (signed) integer to be drawn\n",
      "        from the distribution (see above for behavior if ``high=None``).\n",
      "        If array-like, must contain integer values\n",
      "    size : int or tuple of ints, optional\n",
      "        Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "        ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
      "        single value is returned.\n",
      "    dtype : dtype, optional\n",
      "        Desired dtype of the result. Byteorder must be native.\n",
      "        The default value is int.\n",
      "    \n",
      "        .. versionadded:: 1.11.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    out : int or ndarray of ints\n",
      "        `size`-shaped array of random integers from the appropriate\n",
      "        distribution, or a single such random int if `size` not provided.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    random_integers : similar to `randint`, only for the closed\n",
      "        interval [`low`, `high`], and 1 is the lowest value if `high` is\n",
      "        omitted.\n",
      "    Generator.integers: which should be used for new code.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.random.randint(2, size=10)\n",
      "    array([1, 0, 0, 0, 1, 1, 0, 0, 1, 0]) # random\n",
      "    >>> np.random.randint(1, size=10)\n",
      "    array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "    \n",
      "    Generate a 2 x 4 array of ints between 0 and 4, inclusive:\n",
      "    \n",
      "    >>> np.random.randint(5, size=(2, 4))\n",
      "    array([[4, 0, 2, 1], # random\n",
      "           [3, 2, 2, 0]])\n",
      "    \n",
      "    Generate a 1 x 3 array with 3 different upper bounds\n",
      "    \n",
      "    >>> np.random.randint(1, [3, 5, 10])\n",
      "    array([2, 2, 9]) # random\n",
      "    \n",
      "    Generate a 1 by 3 array with 3 different lower bounds\n",
      "    \n",
      "    >>> np.random.randint([1, 5, 7], 10)\n",
      "    array([9, 8, 7]) # random\n",
      "    \n",
      "    Generate a 2 by 4 array using broadcasting with dtype of uint8\n",
      "    \n",
      "    >>> np.random.randint([1, 3, 5, 7], [[10], [20]], dtype=np.uint8)\n",
      "    array([[ 8,  6,  9,  7], # random\n",
      "           [ 1, 16,  9, 12]], dtype=uint8)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.random.randint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "59e5be67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-01-01 00:00:00    247\n",
       "2012-01-01 00:00:01    413\n",
       "2012-01-01 00:00:02    154\n",
       "2012-01-01 00:00:03    207\n",
       "2012-01-01 00:00:04    267\n",
       "                      ... \n",
       "2012-01-01 00:01:35    277\n",
       "2012-01-01 00:01:36    377\n",
       "2012-01-01 00:01:37     10\n",
       "2012-01-01 00:01:38    396\n",
       "2012-01-01 00:01:39    330\n",
       "Freq: S, Length: 100, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = pd.Series(np.random.randint(0, 500, len(rng)), index=rng)\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "acbe16a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method resample in module pandas.core.series:\n",
      "\n",
      "resample(rule, axis=0, closed: 'str | None' = None, label: 'str | None' = None, convention: 'str' = 'start', kind: 'str | None' = None, loffset=None, base: 'int | None' = None, on=None, level=None, origin: 'str | TimestampConvertibleTypes' = 'start_day', offset: 'TimedeltaConvertibleTypes | None' = None) -> 'Resampler' method of pandas.core.series.Series instance\n",
      "    Resample time-series data.\n",
      "    \n",
      "    Convenience method for frequency conversion and resampling of time series.\n",
      "    The object must have a datetime-like index (`DatetimeIndex`, `PeriodIndex`,\n",
      "    or `TimedeltaIndex`), or the caller must pass the label of a datetime-like\n",
      "    series/index to the ``on``/``level`` keyword parameter.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    rule : DateOffset, Timedelta or str\n",
      "        The offset string or object representing target conversion.\n",
      "    axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "        Which axis to use for up- or down-sampling. For `Series` this\n",
      "        will default to 0, i.e. along the rows. Must be\n",
      "        `DatetimeIndex`, `TimedeltaIndex` or `PeriodIndex`.\n",
      "    closed : {'right', 'left'}, default None\n",
      "        Which side of bin interval is closed. The default is 'left'\n",
      "        for all frequency offsets except for 'M', 'A', 'Q', 'BM',\n",
      "        'BA', 'BQ', and 'W' which all have a default of 'right'.\n",
      "    label : {'right', 'left'}, default None\n",
      "        Which bin edge label to label bucket with. The default is 'left'\n",
      "        for all frequency offsets except for 'M', 'A', 'Q', 'BM',\n",
      "        'BA', 'BQ', and 'W' which all have a default of 'right'.\n",
      "    convention : {'start', 'end', 's', 'e'}, default 'start'\n",
      "        For `PeriodIndex` only, controls whether to use the start or\n",
      "        end of `rule`.\n",
      "    kind : {'timestamp', 'period'}, optional, default None\n",
      "        Pass 'timestamp' to convert the resulting index to a\n",
      "        `DateTimeIndex` or 'period' to convert it to a `PeriodIndex`.\n",
      "        By default the input representation is retained.\n",
      "    loffset : timedelta, default None\n",
      "        Adjust the resampled time labels.\n",
      "    \n",
      "        .. deprecated:: 1.1.0\n",
      "            You should add the loffset to the `df.index` after the resample.\n",
      "            See below.\n",
      "    \n",
      "    base : int, default 0\n",
      "        For frequencies that evenly subdivide 1 day, the \"origin\" of the\n",
      "        aggregated intervals. For example, for '5min' frequency, base could\n",
      "        range from 0 through 4. Defaults to 0.\n",
      "    \n",
      "        .. deprecated:: 1.1.0\n",
      "            The new arguments that you should use are 'offset' or 'origin'.\n",
      "    \n",
      "    on : str, optional\n",
      "        For a DataFrame, column to use instead of index for resampling.\n",
      "        Column must be datetime-like.\n",
      "    level : str or int, optional\n",
      "        For a MultiIndex, level (name or number) to use for\n",
      "        resampling. `level` must be datetime-like.\n",
      "    origin : {'epoch', 'start', 'start_day', 'end', 'end_day'}, Timestamp\n",
      "        or str, default 'start_day'\n",
      "        The timestamp on which to adjust the grouping. The timezone of origin\n",
      "        must match the timezone of the index.\n",
      "        If a timestamp is not used, these values are also supported:\n",
      "    \n",
      "        - 'epoch': `origin` is 1970-01-01\n",
      "        - 'start': `origin` is the first value of the timeseries\n",
      "        - 'start_day': `origin` is the first day at midnight of the timeseries\n",
      "    \n",
      "        .. versionadded:: 1.1.0\n",
      "    \n",
      "        - 'end': `origin` is the last value of the timeseries\n",
      "        - 'end_day': `origin` is the ceiling midnight of the last day\n",
      "    \n",
      "        .. versionadded:: 1.3.0\n",
      "    \n",
      "    offset : Timedelta or str, default is None\n",
      "        An offset timedelta added to the origin.\n",
      "    \n",
      "        .. versionadded:: 1.1.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    pandas.core.Resampler\n",
      "        :class:`~pandas.core.Resampler` object.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    Series.resample : Resample a Series.\n",
      "    DataFrame.resample : Resample a DataFrame.\n",
      "    groupby : Group Series by mapping, function, label, or list of labels.\n",
      "    asfreq : Reindex a Series with the given frequency without grouping.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    See the `user guide\n",
      "    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#resampling>`__\n",
      "    for more.\n",
      "    \n",
      "    To learn more about the offset strings, please see `this link\n",
      "    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects>`__.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    Start by creating a series with 9 one minute timestamps.\n",
      "    \n",
      "    >>> index = pd.date_range('1/1/2000', periods=9, freq='T')\n",
      "    >>> series = pd.Series(range(9), index=index)\n",
      "    >>> series\n",
      "    2000-01-01 00:00:00    0\n",
      "    2000-01-01 00:01:00    1\n",
      "    2000-01-01 00:02:00    2\n",
      "    2000-01-01 00:03:00    3\n",
      "    2000-01-01 00:04:00    4\n",
      "    2000-01-01 00:05:00    5\n",
      "    2000-01-01 00:06:00    6\n",
      "    2000-01-01 00:07:00    7\n",
      "    2000-01-01 00:08:00    8\n",
      "    Freq: T, dtype: int64\n",
      "    \n",
      "    Downsample the series into 3 minute bins and sum the values\n",
      "    of the timestamps falling into a bin.\n",
      "    \n",
      "    >>> series.resample('3T').sum()\n",
      "    2000-01-01 00:00:00     3\n",
      "    2000-01-01 00:03:00    12\n",
      "    2000-01-01 00:06:00    21\n",
      "    Freq: 3T, dtype: int64\n",
      "    \n",
      "    Downsample the series into 3 minute bins as above, but label each\n",
      "    bin using the right edge instead of the left. Please note that the\n",
      "    value in the bucket used as the label is not included in the bucket,\n",
      "    which it labels. For example, in the original series the\n",
      "    bucket ``2000-01-01 00:03:00`` contains the value 3, but the summed\n",
      "    value in the resampled bucket with the label ``2000-01-01 00:03:00``\n",
      "    does not include 3 (if it did, the summed value would be 6, not 3).\n",
      "    To include this value close the right side of the bin interval as\n",
      "    illustrated in the example below this one.\n",
      "    \n",
      "    >>> series.resample('3T', label='right').sum()\n",
      "    2000-01-01 00:03:00     3\n",
      "    2000-01-01 00:06:00    12\n",
      "    2000-01-01 00:09:00    21\n",
      "    Freq: 3T, dtype: int64\n",
      "    \n",
      "    Downsample the series into 3 minute bins as above, but close the right\n",
      "    side of the bin interval.\n",
      "    \n",
      "    >>> series.resample('3T', label='right', closed='right').sum()\n",
      "    2000-01-01 00:00:00     0\n",
      "    2000-01-01 00:03:00     6\n",
      "    2000-01-01 00:06:00    15\n",
      "    2000-01-01 00:09:00    15\n",
      "    Freq: 3T, dtype: int64\n",
      "    \n",
      "    Upsample the series into 30 second bins.\n",
      "    \n",
      "    >>> series.resample('30S').asfreq()[0:5]   # Select first 5 rows\n",
      "    2000-01-01 00:00:00   0.0\n",
      "    2000-01-01 00:00:30   NaN\n",
      "    2000-01-01 00:01:00   1.0\n",
      "    2000-01-01 00:01:30   NaN\n",
      "    2000-01-01 00:02:00   2.0\n",
      "    Freq: 30S, dtype: float64\n",
      "    \n",
      "    Upsample the series into 30 second bins and fill the ``NaN``\n",
      "    values using the ``pad`` method.\n",
      "    \n",
      "    >>> series.resample('30S').pad()[0:5]\n",
      "    2000-01-01 00:00:00    0\n",
      "    2000-01-01 00:00:30    0\n",
      "    2000-01-01 00:01:00    1\n",
      "    2000-01-01 00:01:30    1\n",
      "    2000-01-01 00:02:00    2\n",
      "    Freq: 30S, dtype: int64\n",
      "    \n",
      "    Upsample the series into 30 second bins and fill the\n",
      "    ``NaN`` values using the ``bfill`` method.\n",
      "    \n",
      "    >>> series.resample('30S').bfill()[0:5]\n",
      "    2000-01-01 00:00:00    0\n",
      "    2000-01-01 00:00:30    1\n",
      "    2000-01-01 00:01:00    1\n",
      "    2000-01-01 00:01:30    2\n",
      "    2000-01-01 00:02:00    2\n",
      "    Freq: 30S, dtype: int64\n",
      "    \n",
      "    Pass a custom function via ``apply``\n",
      "    \n",
      "    >>> def custom_resampler(arraylike):\n",
      "    ...     return np.sum(arraylike) + 5\n",
      "    ...\n",
      "    >>> series.resample('3T').apply(custom_resampler)\n",
      "    2000-01-01 00:00:00     8\n",
      "    2000-01-01 00:03:00    17\n",
      "    2000-01-01 00:06:00    26\n",
      "    Freq: 3T, dtype: int64\n",
      "    \n",
      "    For a Series with a PeriodIndex, the keyword `convention` can be\n",
      "    used to control whether to use the start or end of `rule`.\n",
      "    \n",
      "    Resample a year by quarter using 'start' `convention`. Values are\n",
      "    assigned to the first quarter of the period.\n",
      "    \n",
      "    >>> s = pd.Series([1, 2], index=pd.period_range('2012-01-01',\n",
      "    ...                                             freq='A',\n",
      "    ...                                             periods=2))\n",
      "    >>> s\n",
      "    2012    1\n",
      "    2013    2\n",
      "    Freq: A-DEC, dtype: int64\n",
      "    >>> s.resample('Q', convention='start').asfreq()\n",
      "    2012Q1    1.0\n",
      "    2012Q2    NaN\n",
      "    2012Q3    NaN\n",
      "    2012Q4    NaN\n",
      "    2013Q1    2.0\n",
      "    2013Q2    NaN\n",
      "    2013Q3    NaN\n",
      "    2013Q4    NaN\n",
      "    Freq: Q-DEC, dtype: float64\n",
      "    \n",
      "    Resample quarters by month using 'end' `convention`. Values are\n",
      "    assigned to the last month of the period.\n",
      "    \n",
      "    >>> q = pd.Series([1, 2, 3, 4], index=pd.period_range('2018-01-01',\n",
      "    ...                                                   freq='Q',\n",
      "    ...                                                   periods=4))\n",
      "    >>> q\n",
      "    2018Q1    1\n",
      "    2018Q2    2\n",
      "    2018Q3    3\n",
      "    2018Q4    4\n",
      "    Freq: Q-DEC, dtype: int64\n",
      "    >>> q.resample('M', convention='end').asfreq()\n",
      "    2018-03    1.0\n",
      "    2018-04    NaN\n",
      "    2018-05    NaN\n",
      "    2018-06    2.0\n",
      "    2018-07    NaN\n",
      "    2018-08    NaN\n",
      "    2018-09    3.0\n",
      "    2018-10    NaN\n",
      "    2018-11    NaN\n",
      "    2018-12    4.0\n",
      "    Freq: M, dtype: float64\n",
      "    \n",
      "    For DataFrame objects, the keyword `on` can be used to specify the\n",
      "    column instead of the index for resampling.\n",
      "    \n",
      "    >>> d = {'price': [10, 11, 9, 13, 14, 18, 17, 19],\n",
      "    ...      'volume': [50, 60, 40, 100, 50, 100, 40, 50]}\n",
      "    >>> df = pd.DataFrame(d)\n",
      "    >>> df['week_starting'] = pd.date_range('01/01/2018',\n",
      "    ...                                     periods=8,\n",
      "    ...                                     freq='W')\n",
      "    >>> df\n",
      "       price  volume week_starting\n",
      "    0     10      50    2018-01-07\n",
      "    1     11      60    2018-01-14\n",
      "    2      9      40    2018-01-21\n",
      "    3     13     100    2018-01-28\n",
      "    4     14      50    2018-02-04\n",
      "    5     18     100    2018-02-11\n",
      "    6     17      40    2018-02-18\n",
      "    7     19      50    2018-02-25\n",
      "    >>> df.resample('M', on='week_starting').mean()\n",
      "                   price  volume\n",
      "    week_starting\n",
      "    2018-01-31     10.75    62.5\n",
      "    2018-02-28     17.00    60.0\n",
      "    \n",
      "    For a DataFrame with MultiIndex, the keyword `level` can be used to\n",
      "    specify on which level the resampling needs to take place.\n",
      "    \n",
      "    >>> days = pd.date_range('1/1/2000', periods=4, freq='D')\n",
      "    >>> d2 = {'price': [10, 11, 9, 13, 14, 18, 17, 19],\n",
      "    ...       'volume': [50, 60, 40, 100, 50, 100, 40, 50]}\n",
      "    >>> df2 = pd.DataFrame(\n",
      "    ...     d2,\n",
      "    ...     index=pd.MultiIndex.from_product(\n",
      "    ...         [days, ['morning', 'afternoon']]\n",
      "    ...     )\n",
      "    ... )\n",
      "    >>> df2\n",
      "                          price  volume\n",
      "    2000-01-01 morning       10      50\n",
      "               afternoon     11      60\n",
      "    2000-01-02 morning        9      40\n",
      "               afternoon     13     100\n",
      "    2000-01-03 morning       14      50\n",
      "               afternoon     18     100\n",
      "    2000-01-04 morning       17      40\n",
      "               afternoon     19      50\n",
      "    >>> df2.resample('D', level=0).sum()\n",
      "                price  volume\n",
      "    2000-01-01     21     110\n",
      "    2000-01-02     22     140\n",
      "    2000-01-03     32     150\n",
      "    2000-01-04     36      90\n",
      "    \n",
      "    If you want to adjust the start of the bins based on a fixed timestamp:\n",
      "    \n",
      "    >>> start, end = '2000-10-01 23:30:00', '2000-10-02 00:30:00'\n",
      "    >>> rng = pd.date_range(start, end, freq='7min')\n",
      "    >>> ts = pd.Series(np.arange(len(rng)) * 3, index=rng)\n",
      "    >>> ts\n",
      "    2000-10-01 23:30:00     0\n",
      "    2000-10-01 23:37:00     3\n",
      "    2000-10-01 23:44:00     6\n",
      "    2000-10-01 23:51:00     9\n",
      "    2000-10-01 23:58:00    12\n",
      "    2000-10-02 00:05:00    15\n",
      "    2000-10-02 00:12:00    18\n",
      "    2000-10-02 00:19:00    21\n",
      "    2000-10-02 00:26:00    24\n",
      "    Freq: 7T, dtype: int64\n",
      "    \n",
      "    >>> ts.resample('17min').sum()\n",
      "    2000-10-01 23:14:00     0\n",
      "    2000-10-01 23:31:00     9\n",
      "    2000-10-01 23:48:00    21\n",
      "    2000-10-02 00:05:00    54\n",
      "    2000-10-02 00:22:00    24\n",
      "    Freq: 17T, dtype: int64\n",
      "    \n",
      "    >>> ts.resample('17min', origin='epoch').sum()\n",
      "    2000-10-01 23:18:00     0\n",
      "    2000-10-01 23:35:00    18\n",
      "    2000-10-01 23:52:00    27\n",
      "    2000-10-02 00:09:00    39\n",
      "    2000-10-02 00:26:00    24\n",
      "    Freq: 17T, dtype: int64\n",
      "    \n",
      "    >>> ts.resample('17min', origin='2000-01-01').sum()\n",
      "    2000-10-01 23:24:00     3\n",
      "    2000-10-01 23:41:00    15\n",
      "    2000-10-01 23:58:00    45\n",
      "    2000-10-02 00:15:00    45\n",
      "    Freq: 17T, dtype: int64\n",
      "    \n",
      "    If you want to adjust the start of the bins with an `offset` Timedelta, the two\n",
      "    following lines are equivalent:\n",
      "    \n",
      "    >>> ts.resample('17min', origin='start').sum()\n",
      "    2000-10-01 23:30:00     9\n",
      "    2000-10-01 23:47:00    21\n",
      "    2000-10-02 00:04:00    54\n",
      "    2000-10-02 00:21:00    24\n",
      "    Freq: 17T, dtype: int64\n",
      "    \n",
      "    >>> ts.resample('17min', offset='23h30min').sum()\n",
      "    2000-10-01 23:30:00     9\n",
      "    2000-10-01 23:47:00    21\n",
      "    2000-10-02 00:04:00    54\n",
      "    2000-10-02 00:21:00    24\n",
      "    Freq: 17T, dtype: int64\n",
      "    \n",
      "    If you want to take the largest Timestamp as the end of the bins:\n",
      "    \n",
      "    >>> ts.resample('17min', origin='end').sum()\n",
      "    2000-10-01 23:35:00     0\n",
      "    2000-10-01 23:52:00    18\n",
      "    2000-10-02 00:09:00    27\n",
      "    2000-10-02 00:26:00    63\n",
      "    Freq: 17T, dtype: int64\n",
      "    \n",
      "    In contrast with the `start_day`, you can use `end_day` to take the ceiling\n",
      "    midnight of the largest Timestamp as the end of the bins and drop the bins\n",
      "    not containing data:\n",
      "    \n",
      "    >>> ts.resample('17min', origin='end_day').sum()\n",
      "    2000-10-01 23:38:00     3\n",
      "    2000-10-01 23:55:00    15\n",
      "    2000-10-02 00:12:00    45\n",
      "    2000-10-02 00:29:00    45\n",
      "    Freq: 17T, dtype: int64\n",
      "    \n",
      "    To replace the use of the deprecated `base` argument, you can now use `offset`,\n",
      "    in this example it is equivalent to have `base=2`:\n",
      "    \n",
      "    >>> ts.resample('17min', offset='2min').sum()\n",
      "    2000-10-01 23:16:00     0\n",
      "    2000-10-01 23:33:00     9\n",
      "    2000-10-01 23:50:00    36\n",
      "    2000-10-02 00:07:00    39\n",
      "    2000-10-02 00:24:00    24\n",
      "    Freq: 17T, dtype: int64\n",
      "    \n",
      "    To replace the use of the deprecated `loffset` argument:\n",
      "    \n",
      "    >>> from pandas.tseries.frequencies import to_offset\n",
      "    >>> loffset = '19min'\n",
      "    >>> ts_out = ts.resample('17min').sum()\n",
      "    >>> ts_out.index = ts_out.index + to_offset(loffset)\n",
      "    >>> ts_out\n",
      "    2000-10-01 23:33:00     0\n",
      "    2000-10-01 23:50:00     9\n",
      "    2000-10-02 00:07:00    21\n",
      "    2000-10-02 00:24:00    54\n",
      "    2000-10-02 00:41:00    24\n",
      "    Freq: 17T, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ts.resample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "279de5d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-01-01    24256\n",
       "Freq: 5T, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.resample('5Min').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40809e80",
   "metadata": {},
   "source": [
    "时区表示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3372cf32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Series in module pandas.core.series:\n",
      "\n",
      "class Series(pandas.core.base.IndexOpsMixin, pandas.core.generic.NDFrame)\n",
      " |  Series(data=None, index=None, dtype: 'Dtype | None' = None, name=None, copy: 'bool' = False, fastpath: 'bool' = False)\n",
      " |  \n",
      " |  One-dimensional ndarray with axis labels (including time series).\n",
      " |  \n",
      " |  Labels need not be unique but must be a hashable type. The object\n",
      " |  supports both integer- and label-based indexing and provides a host of\n",
      " |  methods for performing operations involving the index. Statistical\n",
      " |  methods from ndarray have been overridden to automatically exclude\n",
      " |  missing data (currently represented as NaN).\n",
      " |  \n",
      " |  Operations between Series (+, -, /, *, **) align values based on their\n",
      " |  associated index values-- they need not be the same length. The result\n",
      " |  index will be the sorted union of the two indexes.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  data : array-like, Iterable, dict, or scalar value\n",
      " |      Contains data stored in Series. If data is a dict, argument order is\n",
      " |      maintained.\n",
      " |  index : array-like or Index (1d)\n",
      " |      Values must be hashable and have the same length as `data`.\n",
      " |      Non-unique index values are allowed. Will default to\n",
      " |      RangeIndex (0, 1, 2, ..., n) if not provided. If data is dict-like\n",
      " |      and index is None, then the keys in the data are used as the index. If the\n",
      " |      index is not None, the resulting Series is reindexed with the index values.\n",
      " |  dtype : str, numpy.dtype, or ExtensionDtype, optional\n",
      " |      Data type for the output Series. If not specified, this will be\n",
      " |      inferred from `data`.\n",
      " |      See the :ref:`user guide <basics.dtypes>` for more usages.\n",
      " |  name : str, optional\n",
      " |      The name to give to the Series.\n",
      " |  copy : bool, default False\n",
      " |      Copy input data. Only affects Series or 1d ndarray input. See examples.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  Constructing Series from a dictionary with an Index specified\n",
      " |  \n",
      " |  >>> d = {'a': 1, 'b': 2, 'c': 3}\n",
      " |  >>> ser = pd.Series(data=d, index=['a', 'b', 'c'])\n",
      " |  >>> ser\n",
      " |  a   1\n",
      " |  b   2\n",
      " |  c   3\n",
      " |  dtype: int64\n",
      " |  \n",
      " |  The keys of the dictionary match with the Index values, hence the Index\n",
      " |  values have no effect.\n",
      " |  \n",
      " |  >>> d = {'a': 1, 'b': 2, 'c': 3}\n",
      " |  >>> ser = pd.Series(data=d, index=['x', 'y', 'z'])\n",
      " |  >>> ser\n",
      " |  x   NaN\n",
      " |  y   NaN\n",
      " |  z   NaN\n",
      " |  dtype: float64\n",
      " |  \n",
      " |  Note that the Index is first build with the keys from the dictionary.\n",
      " |  After this the Series is reindexed with the given Index values, hence we\n",
      " |  get all NaN as a result.\n",
      " |  \n",
      " |  Constructing Series from a list with `copy=False`.\n",
      " |  \n",
      " |  >>> r = [1, 2]\n",
      " |  >>> ser = pd.Series(r, copy=False)\n",
      " |  >>> ser.iloc[0] = 999\n",
      " |  >>> r\n",
      " |  [1, 2]\n",
      " |  >>> ser\n",
      " |  0    999\n",
      " |  1      2\n",
      " |  dtype: int64\n",
      " |  \n",
      " |  Due to input data type the Series has a `copy` of\n",
      " |  the original data even though `copy=False`, so\n",
      " |  the data is unchanged.\n",
      " |  \n",
      " |  Constructing Series from a 1d ndarray with `copy=False`.\n",
      " |  \n",
      " |  >>> r = np.array([1, 2])\n",
      " |  >>> ser = pd.Series(r, copy=False)\n",
      " |  >>> ser.iloc[0] = 999\n",
      " |  >>> r\n",
      " |  array([999,   2])\n",
      " |  >>> ser\n",
      " |  0    999\n",
      " |  1      2\n",
      " |  dtype: int64\n",
      " |  \n",
      " |  Due to input data type the Series has a `view` on\n",
      " |  the original data, so\n",
      " |  the data is changed as well.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Series\n",
      " |      pandas.core.base.IndexOpsMixin\n",
      " |      pandas.core.arraylike.OpsMixin\n",
      " |      pandas.core.generic.NDFrame\n",
      " |      pandas.core.base.PandasObject\n",
      " |      pandas.core.accessor.DirNamesMixin\n",
      " |      pandas.core.indexing.IndexingMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __array__(self, dtype: 'NpDtype | None' = None) -> 'np.ndarray'\n",
      " |      Return the values as a NumPy array.\n",
      " |      \n",
      " |      Users should not call this directly. Rather, it is invoked by\n",
      " |      :func:`numpy.array` and :func:`numpy.asarray`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : str or numpy.dtype, optional\n",
      " |          The dtype to use for the resulting NumPy array. By default,\n",
      " |          the dtype is inferred from the data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray\n",
      " |          The values in the series converted to a :class:`numpy.ndarray`\n",
      " |          with the specified `dtype`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      array : Create a new array from data.\n",
      " |      Series.array : Zero-copy view to the array backing the Series.\n",
      " |      Series.to_numpy : Series method for similar behavior.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> ser = pd.Series([1, 2, 3])\n",
      " |      >>> np.asarray(ser)\n",
      " |      array([1, 2, 3])\n",
      " |      \n",
      " |      For timezone-aware data, the timezones may be retained with\n",
      " |      ``dtype='object'``\n",
      " |      \n",
      " |      >>> tzser = pd.Series(pd.date_range('2000', periods=2, tz=\"CET\"))\n",
      " |      >>> np.asarray(tzser, dtype=\"object\")\n",
      " |      array([Timestamp('2000-01-01 00:00:00+0100', tz='CET'),\n",
      " |             Timestamp('2000-01-02 00:00:00+0100', tz='CET')],\n",
      " |            dtype=object)\n",
      " |      \n",
      " |      Or the values may be localized to UTC and the tzinfo discarded with\n",
      " |      ``dtype='datetime64[ns]'``\n",
      " |      \n",
      " |      >>> np.asarray(tzser, dtype=\"datetime64[ns]\")  # doctest: +ELLIPSIS\n",
      " |      array(['1999-12-31T23:00:00.000000000', ...],\n",
      " |            dtype='datetime64[ns]')\n",
      " |  \n",
      " |  __float__(self)\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |  \n",
      " |  __init__(self, data=None, index=None, dtype: 'Dtype | None' = None, name=None, copy: 'bool' = False, fastpath: 'bool' = False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __int__(self)\n",
      " |  \n",
      " |  __len__(self) -> 'int'\n",
      " |      Return the length of the Series.\n",
      " |  \n",
      " |  __long__ = __int__(self)\n",
      " |  \n",
      " |  __matmul__(self, other)\n",
      " |      Matrix multiplication using binary `@` operator in Python>=3.5.\n",
      " |  \n",
      " |  __repr__(self) -> 'str'\n",
      " |      Return a string representation for a particular Series.\n",
      " |  \n",
      " |  __rmatmul__(self, other)\n",
      " |      Matrix multiplication using binary `@` operator in Python>=3.5.\n",
      " |  \n",
      " |  __setitem__(self, key, value) -> 'None'\n",
      " |  \n",
      " |  add(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Return Addition of series and other, element-wise (binary operator `add`).\n",
      " |      \n",
      " |      Equivalent to ``series + other``, but with support to substitute a fill_value for\n",
      " |      missing data in either one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result of filling (at that location) will be missing.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.radd : Reverse of the Addition operator, see\n",
      " |          `Python documentation\n",
      " |          <https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types>`_\n",
      " |          for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  agg = aggregate(self, func=None, axis=0, *args, **kwargs)\n",
      " |  \n",
      " |  aggregate(self, func=None, axis=0, *args, **kwargs)\n",
      " |      Aggregate using one or more operations over the specified axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function, str, list or dict\n",
      " |          Function to use for aggregating the data. If a function, must either\n",
      " |          work when passed a Series or when passed to Series.apply.\n",
      " |      \n",
      " |          Accepted combinations are:\n",
      " |      \n",
      " |          - function\n",
      " |          - string function name\n",
      " |          - list of functions and/or function names, e.g. ``[np.sum, 'mean']``\n",
      " |          - dict of axis labels -> functions, function names or list of such.\n",
      " |      axis : {0 or 'index'}\n",
      " |              Parameter needed for compatibility with DataFrame.\n",
      " |      *args\n",
      " |          Positional arguments to pass to `func`.\n",
      " |      **kwargs\n",
      " |          Keyword arguments to pass to `func`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar, Series or DataFrame\n",
      " |      \n",
      " |          The return can be:\n",
      " |      \n",
      " |          * scalar : when Series.agg is called with single function\n",
      " |          * Series : when DataFrame.agg is called with a single function\n",
      " |          * DataFrame : when DataFrame.agg is called with several functions\n",
      " |      \n",
      " |          Return scalar, Series or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.apply : Invoke function on a Series.\n",
      " |      Series.transform : Transform function producing a Series with like indexes.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      `agg` is an alias for `aggregate`. Use the alias.\n",
      " |      \n",
      " |      Functions that mutate the passed object can produce unexpected\n",
      " |      behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
      " |      for more details.\n",
      " |      \n",
      " |      A passed user-defined-function will be passed a Series for evaluation.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.agg('min')\n",
      " |      1\n",
      " |      \n",
      " |      >>> s.agg(['min', 'max'])\n",
      " |      min   1\n",
      " |      max   4\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  align(self, other, join='outer', axis=None, level=None, copy=True, fill_value=None, method=None, limit=None, fill_axis=0, broadcast_axis=None)\n",
      " |      Align two objects on their axes with the specified join method.\n",
      " |      \n",
      " |      Join method is specified for each axis Index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame or Series\n",
      " |      join : {'outer', 'inner', 'left', 'right'}, default 'outer'\n",
      " |      axis : allowed axis of the other object, default None\n",
      " |          Align on index (0), columns (1), or both (None).\n",
      " |      level : int or level name, default None\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      copy : bool, default True\n",
      " |          Always returns new objects. If copy=False and no reindexing is\n",
      " |          required then original objects are returned.\n",
      " |      fill_value : scalar, default np.NaN\n",
      " |          Value to use for missing values. Defaults to NaN, but can be any\n",
      " |          \"compatible\" value.\n",
      " |      method : {'backfill', 'bfill', 'pad', 'ffill', None}, default None\n",
      " |          Method to use for filling holes in reindexed Series:\n",
      " |      \n",
      " |          - pad / ffill: propagate last valid observation forward to next valid.\n",
      " |          - backfill / bfill: use NEXT valid observation to fill gap.\n",
      " |      \n",
      " |      limit : int, default None\n",
      " |          If method is specified, this is the maximum number of consecutive\n",
      " |          NaN values to forward/backward fill. In other words, if there is\n",
      " |          a gap with more than this number of consecutive NaNs, it will only\n",
      " |          be partially filled. If method is not specified, this is the\n",
      " |          maximum number of entries along the entire axis where NaNs will be\n",
      " |          filled. Must be greater than 0 if not None.\n",
      " |      fill_axis : {0 or 'index'}, default 0\n",
      " |          Filling axis, method and limit.\n",
      " |      broadcast_axis : {0 or 'index'}, default None\n",
      " |          Broadcast values along this axis, if aligning two objects of\n",
      " |          different dimensions.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      (left, right) : (Series, type of other)\n",
      " |          Aligned objects.\n",
      " |  \n",
      " |  all(self, axis=0, bool_only=None, skipna=True, level=None, **kwargs)\n",
      " |      Return whether all elements are True, potentially over an axis.\n",
      " |      \n",
      " |      Returns True unless there at least one element within a series or\n",
      " |      along a Dataframe axis that is False or equivalent (e.g. zero or\n",
      " |      empty).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          Indicate which axis or axes should be reduced.\n",
      " |      \n",
      " |          * 0 / 'index' : reduce the index, return a Series whose index is the\n",
      " |            original column labels.\n",
      " |          * 1 / 'columns' : reduce the columns, return a Series whose index is the\n",
      " |            original index.\n",
      " |          * None : reduce all axes, return a scalar.\n",
      " |      \n",
      " |      bool_only : bool, default None\n",
      " |          Include only boolean columns. If None, will attempt to use everything,\n",
      " |          then use only boolean data. Not implemented for Series.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If the entire row/column is NA and skipna is\n",
      " |          True, then the result will be True, as for an empty row/column.\n",
      " |          If skipna is False, then NA are treated as True, because these are not\n",
      " |          equal to zero.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar.\n",
      " |      **kwargs : any, default None\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series\n",
      " |          If level is specified, then, Series is returned; otherwise, scalar\n",
      " |          is returned.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.all : Return True if all elements are True.\n",
      " |      DataFrame.any : Return True if one (or more) elements are True.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> pd.Series([True, True]).all()\n",
      " |      True\n",
      " |      >>> pd.Series([True, False]).all()\n",
      " |      False\n",
      " |      >>> pd.Series([], dtype=\"float64\").all()\n",
      " |      True\n",
      " |      >>> pd.Series([np.nan]).all()\n",
      " |      True\n",
      " |      >>> pd.Series([np.nan]).all(skipna=False)\n",
      " |      True\n",
      " |      \n",
      " |      **DataFrames**\n",
      " |      \n",
      " |      Create a dataframe from a dictionary.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'col1': [True, True], 'col2': [True, False]})\n",
      " |      >>> df\n",
      " |         col1   col2\n",
      " |      0  True   True\n",
      " |      1  True  False\n",
      " |      \n",
      " |      Default behaviour checks if column-wise values all return True.\n",
      " |      \n",
      " |      >>> df.all()\n",
      " |      col1     True\n",
      " |      col2    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Specify ``axis='columns'`` to check if row-wise values all return True.\n",
      " |      \n",
      " |      >>> df.all(axis='columns')\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Or ``axis=None`` for whether every value is True.\n",
      " |      \n",
      " |      >>> df.all(axis=None)\n",
      " |      False\n",
      " |  \n",
      " |  any(self, axis=0, bool_only=None, skipna=True, level=None, **kwargs)\n",
      " |      Return whether any element is True, potentially over an axis.\n",
      " |      \n",
      " |      Returns False unless there is at least one element within a series or\n",
      " |      along a Dataframe axis that is True or equivalent (e.g. non-zero or\n",
      " |      non-empty).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          Indicate which axis or axes should be reduced.\n",
      " |      \n",
      " |          * 0 / 'index' : reduce the index, return a Series whose index is the\n",
      " |            original column labels.\n",
      " |          * 1 / 'columns' : reduce the columns, return a Series whose index is the\n",
      " |            original index.\n",
      " |          * None : reduce all axes, return a scalar.\n",
      " |      \n",
      " |      bool_only : bool, default None\n",
      " |          Include only boolean columns. If None, will attempt to use everything,\n",
      " |          then use only boolean data. Not implemented for Series.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If the entire row/column is NA and skipna is\n",
      " |          True, then the result will be False, as for an empty row/column.\n",
      " |          If skipna is False, then NA are treated as True, because these are not\n",
      " |          equal to zero.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar.\n",
      " |      **kwargs : any, default None\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series\n",
      " |          If level is specified, then, Series is returned; otherwise, scalar\n",
      " |          is returned.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.any : Numpy version of this method.\n",
      " |      Series.any : Return whether any element is True.\n",
      " |      Series.all : Return whether all elements are True.\n",
      " |      DataFrame.any : Return whether any element is True over requested axis.\n",
      " |      DataFrame.all : Return whether all elements are True over requested axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      For Series input, the output is a scalar indicating whether any element\n",
      " |      is True.\n",
      " |      \n",
      " |      >>> pd.Series([False, False]).any()\n",
      " |      False\n",
      " |      >>> pd.Series([True, False]).any()\n",
      " |      True\n",
      " |      >>> pd.Series([], dtype=\"float64\").any()\n",
      " |      False\n",
      " |      >>> pd.Series([np.nan]).any()\n",
      " |      False\n",
      " |      >>> pd.Series([np.nan]).any(skipna=False)\n",
      " |      True\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      Whether each column contains at least one True element (the default).\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2], \"B\": [0, 2], \"C\": [0, 0]})\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |      0  1  0  0\n",
      " |      1  2  2  0\n",
      " |      \n",
      " |      >>> df.any()\n",
      " |      A     True\n",
      " |      B     True\n",
      " |      C    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Aggregating over the columns.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [True, False], \"B\": [1, 2]})\n",
      " |      >>> df\n",
      " |             A  B\n",
      " |      0   True  1\n",
      " |      1  False  2\n",
      " |      \n",
      " |      >>> df.any(axis='columns')\n",
      " |      0    True\n",
      " |      1    True\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [True, False], \"B\": [1, 0]})\n",
      " |      >>> df\n",
      " |             A  B\n",
      " |      0   True  1\n",
      " |      1  False  0\n",
      " |      \n",
      " |      >>> df.any(axis='columns')\n",
      " |      0    True\n",
      " |      1    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Aggregating over the entire DataFrame with ``axis=None``.\n",
      " |      \n",
      " |      >>> df.any(axis=None)\n",
      " |      True\n",
      " |      \n",
      " |      `any` for an empty DataFrame is an empty Series.\n",
      " |      \n",
      " |      >>> pd.DataFrame([]).any()\n",
      " |      Series([], dtype: bool)\n",
      " |  \n",
      " |  append(self, to_append, ignore_index: 'bool' = False, verify_integrity: 'bool' = False)\n",
      " |      Concatenate two or more Series.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      to_append : Series or list/tuple of Series\n",
      " |          Series to append with self.\n",
      " |      ignore_index : bool, default False\n",
      " |          If True, the resulting axis will be labeled 0, 1, …, n - 1.\n",
      " |      verify_integrity : bool, default False\n",
      " |          If True, raise Exception on creating index with duplicates.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Concatenated Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      concat : General function to concatenate DataFrame or Series objects.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Iteratively appending to a Series can be more computationally intensive\n",
      " |      than a single concatenate. A better solution is to append values to a\n",
      " |      list and then concatenate the list with the original Series all at\n",
      " |      once.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s1 = pd.Series([1, 2, 3])\n",
      " |      >>> s2 = pd.Series([4, 5, 6])\n",
      " |      >>> s3 = pd.Series([4, 5, 6], index=[3, 4, 5])\n",
      " |      >>> s1.append(s2)\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      0    4\n",
      " |      1    5\n",
      " |      2    6\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s1.append(s3)\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      4    5\n",
      " |      5    6\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      With `ignore_index` set to True:\n",
      " |      \n",
      " |      >>> s1.append(s2, ignore_index=True)\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      4    5\n",
      " |      5    6\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      With `verify_integrity` set to True:\n",
      " |      \n",
      " |      >>> s1.append(s2, verify_integrity=True)\n",
      " |      Traceback (most recent call last):\n",
      " |      ...\n",
      " |      ValueError: Indexes have overlapping values: [0, 1, 2]\n",
      " |  \n",
      " |  apply(self, func: 'AggFuncType', convert_dtype: 'bool' = True, args: 'tuple[Any, ...]' = (), **kwargs) -> 'FrameOrSeriesUnion'\n",
      " |      Invoke function on values of Series.\n",
      " |      \n",
      " |      Can be ufunc (a NumPy function that applies to the entire Series)\n",
      " |      or a Python function that only works on single values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |          Python function or NumPy ufunc to apply.\n",
      " |      convert_dtype : bool, default True\n",
      " |          Try to find better dtype for elementwise function results. If\n",
      " |          False, leave as dtype=object. Note that the dtype is always\n",
      " |          preserved for some extension array dtypes, such as Categorical.\n",
      " |      args : tuple\n",
      " |          Positional arguments passed to func after the series value.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments passed to func.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          If func returns a Series object the result will be a DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.map: For element-wise operations.\n",
      " |      Series.agg: Only perform aggregating type operations.\n",
      " |      Series.transform: Only perform transforming type operations.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Functions that mutate the passed object can produce unexpected\n",
      " |      behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
      " |      for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Create a series with typical summer temperatures for each city.\n",
      " |      \n",
      " |      >>> s = pd.Series([20, 21, 12],\n",
      " |      ...               index=['London', 'New York', 'Helsinki'])\n",
      " |      >>> s\n",
      " |      London      20\n",
      " |      New York    21\n",
      " |      Helsinki    12\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Square the values by defining a function and passing it as an\n",
      " |      argument to ``apply()``.\n",
      " |      \n",
      " |      >>> def square(x):\n",
      " |      ...     return x ** 2\n",
      " |      >>> s.apply(square)\n",
      " |      London      400\n",
      " |      New York    441\n",
      " |      Helsinki    144\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Square the values by passing an anonymous function as an\n",
      " |      argument to ``apply()``.\n",
      " |      \n",
      " |      >>> s.apply(lambda x: x ** 2)\n",
      " |      London      400\n",
      " |      New York    441\n",
      " |      Helsinki    144\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Define a custom function that needs additional positional\n",
      " |      arguments and pass these additional arguments using the\n",
      " |      ``args`` keyword.\n",
      " |      \n",
      " |      >>> def subtract_custom_value(x, custom_value):\n",
      " |      ...     return x - custom_value\n",
      " |      \n",
      " |      >>> s.apply(subtract_custom_value, args=(5,))\n",
      " |      London      15\n",
      " |      New York    16\n",
      " |      Helsinki     7\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Define a custom function that takes keyword arguments\n",
      " |      and pass these arguments to ``apply``.\n",
      " |      \n",
      " |      >>> def add_custom_values(x, **kwargs):\n",
      " |      ...     for month in kwargs:\n",
      " |      ...         x += kwargs[month]\n",
      " |      ...     return x\n",
      " |      \n",
      " |      >>> s.apply(add_custom_values, june=30, july=20, august=25)\n",
      " |      London      95\n",
      " |      New York    96\n",
      " |      Helsinki    87\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Use a function from the Numpy library.\n",
      " |      \n",
      " |      >>> s.apply(np.log)\n",
      " |      London      2.995732\n",
      " |      New York    3.044522\n",
      " |      Helsinki    2.484907\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  argsort(self, axis=0, kind='quicksort', order=None) -> 'Series'\n",
      " |      Return the integer indices that would sort the Series values.\n",
      " |      \n",
      " |      Override ndarray.argsort. Argsorts the value, omitting NA/null values,\n",
      " |      and places the result in the same locations as the non-NA values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or \"index\"}\n",
      " |          Has no effect but is accepted for compatibility with numpy.\n",
      " |      kind : {'mergesort', 'quicksort', 'heapsort', 'stable'}, default 'quicksort'\n",
      " |          Choice of sorting algorithm. See :func:`numpy.sort` for more\n",
      " |          information. 'mergesort' and 'stable' are the only stable algorithms.\n",
      " |      order : None\n",
      " |          Has no effect but is accepted for compatibility with numpy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series[np.intp]\n",
      " |          Positions of values within the sort order with -1 indicating\n",
      " |          nan values.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.argsort : Returns the indices that would sort this array.\n",
      " |  \n",
      " |  asfreq(self, freq, method=None, how: 'str | None' = None, normalize: 'bool' = False, fill_value=None) -> 'Series'\n",
      " |      Convert time series to specified frequency.\n",
      " |      \n",
      " |      Returns the original data conformed to a new index with the specified\n",
      " |      frequency.\n",
      " |      \n",
      " |      If the index of this Series is a :class:`~pandas.PeriodIndex`, the new index\n",
      " |      is the result of transforming the original index with\n",
      " |      :meth:`PeriodIndex.asfreq <pandas.PeriodIndex.asfreq>` (so the original index\n",
      " |      will map one-to-one to the new index).\n",
      " |      \n",
      " |      Otherwise, the new index will be equivalent to ``pd.date_range(start, end,\n",
      " |      freq=freq)`` where ``start`` and ``end`` are, respectively, the first and\n",
      " |      last entries in the original index (see :func:`pandas.date_range`). The\n",
      " |      values corresponding to any timesteps in the new index which were not present\n",
      " |      in the original index will be null (``NaN``), unless a method for filling\n",
      " |      such unknowns is provided (see the ``method`` parameter below).\n",
      " |      \n",
      " |      The :meth:`resample` method is more appropriate if an operation on each group of\n",
      " |      timesteps (such as an aggregate) is necessary to represent the data at the new\n",
      " |      frequency.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : DateOffset or str\n",
      " |          Frequency DateOffset or string.\n",
      " |      method : {'backfill'/'bfill', 'pad'/'ffill'}, default None\n",
      " |          Method to use for filling holes in reindexed Series (note this\n",
      " |          does not fill NaNs that already were present):\n",
      " |      \n",
      " |          * 'pad' / 'ffill': propagate last valid observation forward to next\n",
      " |            valid\n",
      " |          * 'backfill' / 'bfill': use NEXT valid observation to fill.\n",
      " |      how : {'start', 'end'}, default end\n",
      " |          For PeriodIndex only (see PeriodIndex.asfreq).\n",
      " |      normalize : bool, default False\n",
      " |          Whether to reset output index to midnight.\n",
      " |      fill_value : scalar, optional\n",
      " |          Value to use for missing values, applied during upsampling (note\n",
      " |          this does not fill NaNs that already were present).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Series object reindexed to the specified frequency.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      reindex : Conform DataFrame to new index with optional filling logic.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      To learn more about the frequency strings, please see `this link\n",
      " |      <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Start by creating a series with 4 one minute timestamps.\n",
      " |      \n",
      " |      >>> index = pd.date_range('1/1/2000', periods=4, freq='T')\n",
      " |      >>> series = pd.Series([0.0, None, 2.0, 3.0], index=index)\n",
      " |      >>> df = pd.DataFrame({'s': series})\n",
      " |      >>> df\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      Upsample the series into 30 second bins.\n",
      " |      \n",
      " |      >>> df.asfreq(freq='30S')\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    NaN\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    NaN\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    NaN\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      Upsample again, providing a ``fill value``.\n",
      " |      \n",
      " |      >>> df.asfreq(freq='30S', fill_value=9.0)\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    9.0\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    9.0\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    9.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      Upsample again, providing a ``method``.\n",
      " |      \n",
      " |      >>> df.asfreq(freq='30S', method='bfill')\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    NaN\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    2.0\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    3.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |  \n",
      " |  autocorr(self, lag=1) -> 'float'\n",
      " |      Compute the lag-N autocorrelation.\n",
      " |      \n",
      " |      This method computes the Pearson correlation between\n",
      " |      the Series and its shifted self.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      lag : int, default 1\n",
      " |          Number of lags to apply before performing autocorrelation.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      float\n",
      " |          The Pearson correlation between self and self.shift(lag).\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.corr : Compute the correlation between two Series.\n",
      " |      Series.shift : Shift index by desired number of periods.\n",
      " |      DataFrame.corr : Compute pairwise correlation of columns.\n",
      " |      DataFrame.corrwith : Compute pairwise correlation between rows or\n",
      " |          columns of two DataFrame objects.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If the Pearson correlation is not well defined return 'NaN'.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([0.25, 0.5, 0.2, -0.05])\n",
      " |      >>> s.autocorr()  # doctest: +ELLIPSIS\n",
      " |      0.10355...\n",
      " |      >>> s.autocorr(lag=2)  # doctest: +ELLIPSIS\n",
      " |      -0.99999...\n",
      " |      \n",
      " |      If the Pearson correlation is not well defined, then 'NaN' is returned.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 0, 0, 0])\n",
      " |      >>> s.autocorr()\n",
      " |      nan\n",
      " |  \n",
      " |  between(self, left, right, inclusive='both') -> 'Series'\n",
      " |      Return boolean Series equivalent to left <= series <= right.\n",
      " |      \n",
      " |      This function returns a boolean vector containing `True` wherever the\n",
      " |      corresponding Series element is between the boundary values `left` and\n",
      " |      `right`. NA values are treated as `False`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      left : scalar or list-like\n",
      " |          Left boundary.\n",
      " |      right : scalar or list-like\n",
      " |          Right boundary.\n",
      " |      inclusive : {\"both\", \"neither\", \"left\", \"right\"}\n",
      " |          Include boundaries. Whether to set each bound as closed or open.\n",
      " |      \n",
      " |          .. versionchanged:: 1.3.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Series representing whether each element is between left and\n",
      " |          right (inclusive).\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.gt : Greater than of series and other.\n",
      " |      Series.lt : Less than of series and other.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This function is equivalent to ``(left <= ser) & (ser <= right)``\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([2, 0, 4, 8, np.nan])\n",
      " |      \n",
      " |      Boundary values are included by default:\n",
      " |      \n",
      " |      >>> s.between(1, 4)\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      4    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      With `inclusive` set to ``\"neither\"`` boundary values are excluded:\n",
      " |      \n",
      " |      >>> s.between(1, 4, inclusive=\"neither\")\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      2    False\n",
      " |      3    False\n",
      " |      4    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      `left` and `right` can be any scalar value:\n",
      " |      \n",
      " |      >>> s = pd.Series(['Alice', 'Bob', 'Carol', 'Eve'])\n",
      " |      >>> s.between('Anna', 'Daniel')\n",
      " |      0    False\n",
      " |      1     True\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  bfill(self: 'Series', axis: 'None | Axis' = None, inplace: 'bool' = False, limit: 'None | int' = None, downcast=None) -> 'Series | None'\n",
      " |      Synonym for :meth:`DataFrame.fillna` with ``method='bfill'``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame or None\n",
      " |          Object with missing values filled or None if ``inplace=True``.\n",
      " |  \n",
      " |  clip(self: 'Series', lower=None, upper=None, axis: 'Axis | None' = None, inplace: 'bool' = False, *args, **kwargs) -> 'Series | None'\n",
      " |      Trim values at input threshold(s).\n",
      " |      \n",
      " |      Assigns values outside boundary to boundary values. Thresholds\n",
      " |      can be singular values or array like, and in the latter case\n",
      " |      the clipping is performed element-wise in the specified axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      lower : float or array-like, default None\n",
      " |          Minimum threshold value. All values below this\n",
      " |          threshold will be set to it. A missing\n",
      " |          threshold (e.g `NA`) will not clip the value.\n",
      " |      upper : float or array-like, default None\n",
      " |          Maximum threshold value. All values above this\n",
      " |          threshold will be set to it. A missing\n",
      " |          threshold (e.g `NA`) will not clip the value.\n",
      " |      axis : int or str axis name, optional\n",
      " |          Align object with lower and upper along the given axis.\n",
      " |      inplace : bool, default False\n",
      " |          Whether to perform the operation in place on the data.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted\n",
      " |          for compatibility with numpy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame or None\n",
      " |          Same type as calling object with the values outside the\n",
      " |          clip boundaries replaced or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.clip : Trim values at input threshold in series.\n",
      " |      DataFrame.clip : Trim values at input threshold in dataframe.\n",
      " |      numpy.clip : Clip (limit) the values in an array.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> data = {'col_0': [9, -3, 0, -1, 5], 'col_1': [-2, -7, 6, 8, -5]}\n",
      " |      >>> df = pd.DataFrame(data)\n",
      " |      >>> df\n",
      " |         col_0  col_1\n",
      " |      0      9     -2\n",
      " |      1     -3     -7\n",
      " |      2      0      6\n",
      " |      3     -1      8\n",
      " |      4      5     -5\n",
      " |      \n",
      " |      Clips per column using lower and upper thresholds:\n",
      " |      \n",
      " |      >>> df.clip(-4, 6)\n",
      " |         col_0  col_1\n",
      " |      0      6     -2\n",
      " |      1     -3     -4\n",
      " |      2      0      6\n",
      " |      3     -1      6\n",
      " |      4      5     -4\n",
      " |      \n",
      " |      Clips using specific lower and upper thresholds per column element:\n",
      " |      \n",
      " |      >>> t = pd.Series([2, -4, -1, 6, 3])\n",
      " |      >>> t\n",
      " |      0    2\n",
      " |      1   -4\n",
      " |      2   -1\n",
      " |      3    6\n",
      " |      4    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.clip(t, t + 4, axis=0)\n",
      " |         col_0  col_1\n",
      " |      0      6      2\n",
      " |      1     -3     -4\n",
      " |      2      0      3\n",
      " |      3      6      8\n",
      " |      4      5      3\n",
      " |      \n",
      " |      Clips using specific lower threshold per column element, with missing values:\n",
      " |      \n",
      " |      >>> t = pd.Series([2, -4, np.NaN, 6, 3])\n",
      " |      >>> t\n",
      " |      0    2.0\n",
      " |      1   -4.0\n",
      " |      2    NaN\n",
      " |      3    6.0\n",
      " |      4    3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> df.clip(t, axis=0)\n",
      " |      col_0  col_1\n",
      " |      0      9      2\n",
      " |      1     -3     -4\n",
      " |      2      0      6\n",
      " |      3      6      8\n",
      " |      4      5      3\n",
      " |  \n",
      " |  combine(self, other, func, fill_value=None) -> 'Series'\n",
      " |      Combine the Series with a Series or scalar according to `func`.\n",
      " |      \n",
      " |      Combine the Series and `other` using `func` to perform elementwise\n",
      " |      selection for combined Series.\n",
      " |      `fill_value` is assumed when value is missing at some index\n",
      " |      from one of the two objects being combined.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar\n",
      " |          The value(s) to be combined with the `Series`.\n",
      " |      func : function\n",
      " |          Function that takes two scalars as inputs and returns an element.\n",
      " |      fill_value : scalar, optional\n",
      " |          The value to assume when an index is missing from\n",
      " |          one Series or the other. The default specifies to use the\n",
      " |          appropriate NaN value for the underlying dtype of the Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of combining the Series with the other object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.combine_first : Combine Series values, choosing the calling\n",
      " |          Series' values first.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Consider 2 Datasets ``s1`` and ``s2`` containing\n",
      " |      highest clocked speeds of different birds.\n",
      " |      \n",
      " |      >>> s1 = pd.Series({'falcon': 330.0, 'eagle': 160.0})\n",
      " |      >>> s1\n",
      " |      falcon    330.0\n",
      " |      eagle     160.0\n",
      " |      dtype: float64\n",
      " |      >>> s2 = pd.Series({'falcon': 345.0, 'eagle': 200.0, 'duck': 30.0})\n",
      " |      >>> s2\n",
      " |      falcon    345.0\n",
      " |      eagle     200.0\n",
      " |      duck       30.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Now, to combine the two datasets and view the highest speeds\n",
      " |      of the birds across the two datasets\n",
      " |      \n",
      " |      >>> s1.combine(s2, max)\n",
      " |      duck        NaN\n",
      " |      eagle     200.0\n",
      " |      falcon    345.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      In the previous example, the resulting value for duck is missing,\n",
      " |      because the maximum of a NaN and a float is a NaN.\n",
      " |      So, in the example, we set ``fill_value=0``,\n",
      " |      so the maximum value returned will be the value from some dataset.\n",
      " |      \n",
      " |      >>> s1.combine(s2, max, fill_value=0)\n",
      " |      duck       30.0\n",
      " |      eagle     200.0\n",
      " |      falcon    345.0\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  combine_first(self, other) -> 'Series'\n",
      " |      Update null elements with value in the same location in 'other'.\n",
      " |      \n",
      " |      Combine two Series objects by filling null values in one Series with\n",
      " |      non-null values from the other Series. Result index will be the union\n",
      " |      of the two indexes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series\n",
      " |          The value(s) to be used for filling null values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of combining the provided Series with the other object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.combine : Perform element-wise operation on two Series\n",
      " |          using a given function.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s1 = pd.Series([1, np.nan])\n",
      " |      >>> s2 = pd.Series([3, 4, 5])\n",
      " |      >>> s1.combine_first(s2)\n",
      " |      0    1.0\n",
      " |      1    4.0\n",
      " |      2    5.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Null values still persist if the location of that null value\n",
      " |      does not exist in `other`\n",
      " |      \n",
      " |      >>> s1 = pd.Series({'falcon': np.nan, 'eagle': 160.0})\n",
      " |      >>> s2 = pd.Series({'eagle': 200.0, 'duck': 30.0})\n",
      " |      >>> s1.combine_first(s2)\n",
      " |      duck       30.0\n",
      " |      eagle     160.0\n",
      " |      falcon      NaN\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  compare(self, other: 'Series', align_axis: 'Axis' = 1, keep_shape: 'bool' = False, keep_equal: 'bool' = False) -> 'FrameOrSeriesUnion'\n",
      " |      Compare to another Series and show the differences.\n",
      " |      \n",
      " |      .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series\n",
      " |          Object to compare with.\n",
      " |      \n",
      " |      align_axis : {0 or 'index', 1 or 'columns'}, default 1\n",
      " |          Determine which axis to align the comparison on.\n",
      " |      \n",
      " |          * 0, or 'index' : Resulting differences are stacked vertically\n",
      " |              with rows drawn alternately from self and other.\n",
      " |          * 1, or 'columns' : Resulting differences are aligned horizontally\n",
      " |              with columns drawn alternately from self and other.\n",
      " |      \n",
      " |      keep_shape : bool, default False\n",
      " |          If true, all rows and columns are kept.\n",
      " |          Otherwise, only the ones with different values are kept.\n",
      " |      \n",
      " |      keep_equal : bool, default False\n",
      " |          If true, the result keeps values that are equal.\n",
      " |          Otherwise, equal values are shown as NaNs.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          If axis is 0 or 'index' the result will be a Series.\n",
      " |          The resulting index will be a MultiIndex with 'self' and 'other'\n",
      " |          stacked alternately at the inner level.\n",
      " |      \n",
      " |          If axis is 1 or 'columns' the result will be a DataFrame.\n",
      " |          It will have two columns namely 'self' and 'other'.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.compare : Compare with another DataFrame and show differences.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Matching NaNs will not appear as a difference.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s1 = pd.Series([\"a\", \"b\", \"c\", \"d\", \"e\"])\n",
      " |      >>> s2 = pd.Series([\"a\", \"a\", \"c\", \"b\", \"e\"])\n",
      " |      \n",
      " |      Align the differences on columns\n",
      " |      \n",
      " |      >>> s1.compare(s2)\n",
      " |        self other\n",
      " |      1    b     a\n",
      " |      3    d     b\n",
      " |      \n",
      " |      Stack the differences on indices\n",
      " |      \n",
      " |      >>> s1.compare(s2, align_axis=0)\n",
      " |      1  self     b\n",
      " |         other    a\n",
      " |      3  self     d\n",
      " |         other    b\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Keep all original rows\n",
      " |      \n",
      " |      >>> s1.compare(s2, keep_shape=True)\n",
      " |        self other\n",
      " |      0  NaN   NaN\n",
      " |      1    b     a\n",
      " |      2  NaN   NaN\n",
      " |      3    d     b\n",
      " |      4  NaN   NaN\n",
      " |      \n",
      " |      Keep all original rows and also all original values\n",
      " |      \n",
      " |      >>> s1.compare(s2, keep_shape=True, keep_equal=True)\n",
      " |        self other\n",
      " |      0    a     a\n",
      " |      1    b     a\n",
      " |      2    c     c\n",
      " |      3    d     b\n",
      " |      4    e     e\n",
      " |  \n",
      " |  corr(self, other, method='pearson', min_periods=None) -> 'float'\n",
      " |      Compute correlation with `other` Series, excluding missing values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series\n",
      " |          Series with which to compute the correlation.\n",
      " |      method : {'pearson', 'kendall', 'spearman'} or callable\n",
      " |          Method used to compute correlation:\n",
      " |      \n",
      " |          - pearson : Standard correlation coefficient\n",
      " |          - kendall : Kendall Tau correlation coefficient\n",
      " |          - spearman : Spearman rank correlation\n",
      " |          - callable: Callable with input two 1d ndarrays and returning a float.\n",
      " |      \n",
      " |          .. warning::\n",
      " |              Note that the returned matrix from corr will have 1 along the\n",
      " |              diagonals and will be symmetric regardless of the callable's\n",
      " |              behavior.\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations needed to have a valid result.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      float\n",
      " |          Correlation with other.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.corr : Compute pairwise correlation between columns.\n",
      " |      DataFrame.corrwith : Compute pairwise correlation with another\n",
      " |          DataFrame or Series.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> def histogram_intersection(a, b):\n",
      " |      ...     v = np.minimum(a, b).sum().round(decimals=1)\n",
      " |      ...     return v\n",
      " |      >>> s1 = pd.Series([.2, .0, .6, .2])\n",
      " |      >>> s2 = pd.Series([.3, .6, .0, .1])\n",
      " |      >>> s1.corr(s2, method=histogram_intersection)\n",
      " |      0.3\n",
      " |  \n",
      " |  count(self, level=None)\n",
      " |      Return number of non-NA/null observations in the Series.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a smaller Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      int or Series (if level specified)\n",
      " |          Number of non-null values in the Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.count : Count non-NA cells for each column or row.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([0.0, 1.0, np.nan])\n",
      " |      >>> s.count()\n",
      " |      2\n",
      " |  \n",
      " |  cov(self, other: 'Series', min_periods: 'int | None' = None, ddof: 'int | None' = 1) -> 'float'\n",
      " |      Compute covariance with Series, excluding missing values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series\n",
      " |          Series with which to compute the covariance.\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations needed to have a valid result.\n",
      " |      ddof : int, default 1\n",
      " |          Delta degrees of freedom.  The divisor used in calculations\n",
      " |          is ``N - ddof``, where ``N`` represents the number of elements.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      float\n",
      " |          Covariance between Series and other normalized by N-1\n",
      " |          (unbiased estimator).\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.cov : Compute pairwise covariance of columns.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s1 = pd.Series([0.90010907, 0.13484424, 0.62036035])\n",
      " |      >>> s2 = pd.Series([0.12528585, 0.26962463, 0.51111198])\n",
      " |      >>> s1.cov(s2)\n",
      " |      -0.01685762652715874\n",
      " |  \n",
      " |  cummax(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative maximum over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      maximum.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series\n",
      " |          Return cumulative maximum of scalar or Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.Expanding.max : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      Series.max : Return the maximum over\n",
      " |          Series axis.\n",
      " |      Series.cummax : Return cumulative maximum over Series axis.\n",
      " |      Series.cummin : Return cumulative minimum over Series axis.\n",
      " |      Series.cumsum : Return cumulative sum over Series axis.\n",
      " |      Series.cumprod : Return cumulative product over Series axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cummax()\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3    5.0\n",
      " |      4    5.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cummax(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                    columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the maximum\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cummax()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  3.0  1.0\n",
      " |      \n",
      " |      To iterate over columns and find the maximum in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cummax(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  2.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  1.0\n",
      " |  \n",
      " |  cummin(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative minimum over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      minimum.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series\n",
      " |          Return cumulative minimum of scalar or Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.Expanding.min : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      Series.min : Return the minimum over\n",
      " |          Series axis.\n",
      " |      Series.cummax : Return cumulative maximum over Series axis.\n",
      " |      Series.cummin : Return cumulative minimum over Series axis.\n",
      " |      Series.cumsum : Return cumulative sum over Series axis.\n",
      " |      Series.cumprod : Return cumulative product over Series axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cummin()\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    2.0\n",
      " |      3   -1.0\n",
      " |      4   -1.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cummin(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                    columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the minimum\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cummin()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  2.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      To iterate over columns and find the minimum in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cummin(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |  \n",
      " |  cumprod(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative product over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      product.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series\n",
      " |          Return cumulative product of scalar or Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.Expanding.prod : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      Series.prod : Return the product over\n",
      " |          Series axis.\n",
      " |      Series.cummax : Return cumulative maximum over Series axis.\n",
      " |      Series.cummin : Return cumulative minimum over Series axis.\n",
      " |      Series.cumsum : Return cumulative sum over Series axis.\n",
      " |      Series.cumprod : Return cumulative product over Series axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cumprod()\n",
      " |      0     2.0\n",
      " |      1     NaN\n",
      " |      2    10.0\n",
      " |      3   -10.0\n",
      " |      4    -0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cumprod(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                    columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the product\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cumprod()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  6.0  NaN\n",
      " |      2  6.0  0.0\n",
      " |      \n",
      " |      To iterate over columns and find the product in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cumprod(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  2.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |  \n",
      " |  cumsum(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative sum over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      sum.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series\n",
      " |          Return cumulative sum of scalar or Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.Expanding.sum : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      Series.sum : Return the sum over\n",
      " |          Series axis.\n",
      " |      Series.cummax : Return cumulative maximum over Series axis.\n",
      " |      Series.cummin : Return cumulative minimum over Series axis.\n",
      " |      Series.cumsum : Return cumulative sum over Series axis.\n",
      " |      Series.cumprod : Return cumulative product over Series axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cumsum()\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    7.0\n",
      " |      3    6.0\n",
      " |      4    6.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cumsum(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                    columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the sum\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cumsum()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  5.0  NaN\n",
      " |      2  6.0  1.0\n",
      " |      \n",
      " |      To iterate over columns and find the sum in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cumsum(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  3.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  1.0\n",
      " |  \n",
      " |  diff(self, periods: 'int' = 1) -> 'Series'\n",
      " |      First discrete difference of element.\n",
      " |      \n",
      " |      Calculates the difference of a Series element compared with another\n",
      " |      element in the Series (default is element in previous row).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for calculating difference, accepts negative\n",
      " |          values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          First differences of the Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.pct_change: Percent change over given number of periods.\n",
      " |      Series.shift: Shift index by desired number of periods with an\n",
      " |          optional time freq.\n",
      " |      DataFrame.diff: First discrete difference of object.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For boolean dtypes, this uses :meth:`operator.xor` rather than\n",
      " |      :meth:`operator.sub`.\n",
      " |      The result is calculated according to current dtype in Series,\n",
      " |      however dtype of the result is always float64.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Difference with previous row\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 1, 2, 3, 5, 8])\n",
      " |      >>> s.diff()\n",
      " |      0    NaN\n",
      " |      1    0.0\n",
      " |      2    1.0\n",
      " |      3    1.0\n",
      " |      4    2.0\n",
      " |      5    3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Difference with 3rd previous row\n",
      " |      \n",
      " |      >>> s.diff(periods=3)\n",
      " |      0    NaN\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    2.0\n",
      " |      4    4.0\n",
      " |      5    6.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Difference with following row\n",
      " |      \n",
      " |      >>> s.diff(periods=-1)\n",
      " |      0    0.0\n",
      " |      1   -1.0\n",
      " |      2   -1.0\n",
      " |      3   -2.0\n",
      " |      4   -3.0\n",
      " |      5    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Overflow in input dtype\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 0], dtype=np.uint8)\n",
      " |      >>> s.diff()\n",
      " |      0      NaN\n",
      " |      1    255.0\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  div = truediv(self, other, level=None, fill_value=None, axis=0)\n",
      " |  \n",
      " |  divide = truediv(self, other, level=None, fill_value=None, axis=0)\n",
      " |  \n",
      " |  divmod(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Return Integer division and modulo of series and other, element-wise (binary operator `divmod`).\n",
      " |      \n",
      " |      Equivalent to ``divmod(series, other)``, but with support to substitute a fill_value for\n",
      " |      missing data in either one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result of filling (at that location) will be missing.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      2-Tuple of Series\n",
      " |          The result of the operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.rdivmod : Reverse of the Integer division and modulo operator, see\n",
      " |          `Python documentation\n",
      " |          <https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types>`_\n",
      " |          for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.divmod(b, fill_value=0)\n",
      " |      (a    1.0\n",
      " |       b    NaN\n",
      " |       c    NaN\n",
      " |       d    0.0\n",
      " |       e    NaN\n",
      " |       dtype: float64,\n",
      " |       a    0.0\n",
      " |       b    NaN\n",
      " |       c    NaN\n",
      " |       d    0.0\n",
      " |       e    NaN\n",
      " |       dtype: float64)\n",
      " |  \n",
      " |  dot(self, other)\n",
      " |      Compute the dot product between the Series and the columns of other.\n",
      " |      \n",
      " |      This method computes the dot product between the Series and another\n",
      " |      one, or the Series and each columns of a DataFrame, or the Series and\n",
      " |      each columns of an array.\n",
      " |      \n",
      " |      It can also be called using `self @ other` in Python >= 3.5.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame or array-like\n",
      " |          The other object to compute the dot product with its columns.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar, Series or numpy.ndarray\n",
      " |          Return the dot product of the Series and other if other is a\n",
      " |          Series, the Series of the dot product of Series and each rows of\n",
      " |          other if other is a DataFrame or a numpy.ndarray between the Series\n",
      " |          and each columns of the numpy array.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.dot: Compute the matrix product with the DataFrame.\n",
      " |      Series.mul: Multiplication of series and other, element-wise.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The Series and other has to share the same index if other is a Series\n",
      " |      or a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([0, 1, 2, 3])\n",
      " |      >>> other = pd.Series([-1, 2, -3, 4])\n",
      " |      >>> s.dot(other)\n",
      " |      8\n",
      " |      >>> s @ other\n",
      " |      8\n",
      " |      >>> df = pd.DataFrame([[0, 1], [-2, 3], [4, -5], [6, 7]])\n",
      " |      >>> s.dot(df)\n",
      " |      0    24\n",
      " |      1    14\n",
      " |      dtype: int64\n",
      " |      >>> arr = np.array([[0, 1], [-2, 3], [4, -5], [6, 7]])\n",
      " |      >>> s.dot(arr)\n",
      " |      array([24, 14])\n",
      " |  \n",
      " |  drop(self, labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise') -> 'Series'\n",
      " |      Return Series with specified index labels removed.\n",
      " |      \n",
      " |      Remove elements of a Series based on specifying the index labels.\n",
      " |      When using a multi-index, labels on different levels can be removed\n",
      " |      by specifying the level.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      labels : single label or list-like\n",
      " |          Index labels to drop.\n",
      " |      axis : 0, default 0\n",
      " |          Redundant for application on Series.\n",
      " |      index : single label or list-like\n",
      " |          Redundant for application on Series, but 'index' can be used instead\n",
      " |          of 'labels'.\n",
      " |      columns : single label or list-like\n",
      " |          No change is made to the Series; use 'index' or 'labels' instead.\n",
      " |      level : int or level name, optional\n",
      " |          For MultiIndex, level for which the labels will be removed.\n",
      " |      inplace : bool, default False\n",
      " |          If True, do operation inplace and return None.\n",
      " |      errors : {'ignore', 'raise'}, default 'raise'\n",
      " |          If 'ignore', suppress error and only existing labels are dropped.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or None\n",
      " |          Series with specified index labels removed or None if ``inplace=True``.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError\n",
      " |          If none of the labels are found in the index.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.reindex : Return only specified index labels of Series.\n",
      " |      Series.dropna : Return series without null values.\n",
      " |      Series.drop_duplicates : Return Series with duplicate values removed.\n",
      " |      DataFrame.drop : Drop specified labels from rows or columns.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(data=np.arange(3), index=['A', 'B', 'C'])\n",
      " |      >>> s\n",
      " |      A  0\n",
      " |      B  1\n",
      " |      C  2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Drop labels B en C\n",
      " |      \n",
      " |      >>> s.drop(labels=['B', 'C'])\n",
      " |      A  0\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Drop 2nd level label in MultiIndex Series\n",
      " |      \n",
      " |      >>> midx = pd.MultiIndex(levels=[['lama', 'cow', 'falcon'],\n",
      " |      ...                              ['speed', 'weight', 'length']],\n",
      " |      ...                      codes=[[0, 0, 0, 1, 1, 1, 2, 2, 2],\n",
      " |      ...                             [0, 1, 2, 0, 1, 2, 0, 1, 2]])\n",
      " |      >>> s = pd.Series([45, 200, 1.2, 30, 250, 1.5, 320, 1, 0.3],\n",
      " |      ...               index=midx)\n",
      " |      >>> s\n",
      " |      lama    speed      45.0\n",
      " |              weight    200.0\n",
      " |              length      1.2\n",
      " |      cow     speed      30.0\n",
      " |              weight    250.0\n",
      " |              length      1.5\n",
      " |      falcon  speed     320.0\n",
      " |              weight      1.0\n",
      " |              length      0.3\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.drop(labels='weight', level=1)\n",
      " |      lama    speed      45.0\n",
      " |              length      1.2\n",
      " |      cow     speed      30.0\n",
      " |              length      1.5\n",
      " |      falcon  speed     320.0\n",
      " |              length      0.3\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  drop_duplicates(self, keep='first', inplace=False) -> 'Series | None'\n",
      " |      Return Series with duplicate values removed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      keep : {'first', 'last', ``False``}, default 'first'\n",
      " |          Method to handle dropping duplicates:\n",
      " |      \n",
      " |          - 'first' : Drop duplicates except for the first occurrence.\n",
      " |          - 'last' : Drop duplicates except for the last occurrence.\n",
      " |          - ``False`` : Drop all duplicates.\n",
      " |      \n",
      " |      inplace : bool, default ``False``\n",
      " |          If ``True``, performs operation inplace and returns None.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or None\n",
      " |          Series with duplicates dropped or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.drop_duplicates : Equivalent method on Index.\n",
      " |      DataFrame.drop_duplicates : Equivalent method on DataFrame.\n",
      " |      Series.duplicated : Related method on Series, indicating duplicate\n",
      " |          Series values.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Generate a Series with duplicated entries.\n",
      " |      \n",
      " |      >>> s = pd.Series(['lama', 'cow', 'lama', 'beetle', 'lama', 'hippo'],\n",
      " |      ...               name='animal')\n",
      " |      >>> s\n",
      " |      0      lama\n",
      " |      1       cow\n",
      " |      2      lama\n",
      " |      3    beetle\n",
      " |      4      lama\n",
      " |      5     hippo\n",
      " |      Name: animal, dtype: object\n",
      " |      \n",
      " |      With the 'keep' parameter, the selection behaviour of duplicated values\n",
      " |      can be changed. The value 'first' keeps the first occurrence for each\n",
      " |      set of duplicated entries. The default value of keep is 'first'.\n",
      " |      \n",
      " |      >>> s.drop_duplicates()\n",
      " |      0      lama\n",
      " |      1       cow\n",
      " |      3    beetle\n",
      " |      5     hippo\n",
      " |      Name: animal, dtype: object\n",
      " |      \n",
      " |      The value 'last' for parameter 'keep' keeps the last occurrence for\n",
      " |      each set of duplicated entries.\n",
      " |      \n",
      " |      >>> s.drop_duplicates(keep='last')\n",
      " |      1       cow\n",
      " |      3    beetle\n",
      " |      4      lama\n",
      " |      5     hippo\n",
      " |      Name: animal, dtype: object\n",
      " |      \n",
      " |      The value ``False`` for parameter 'keep' discards all sets of\n",
      " |      duplicated entries. Setting the value of 'inplace' to ``True`` performs\n",
      " |      the operation inplace and returns ``None``.\n",
      " |      \n",
      " |      >>> s.drop_duplicates(keep=False, inplace=True)\n",
      " |      >>> s\n",
      " |      1       cow\n",
      " |      3    beetle\n",
      " |      5     hippo\n",
      " |      Name: animal, dtype: object\n",
      " |  \n",
      " |  dropna(self, axis=0, inplace=False, how=None)\n",
      " |      Return a new Series with missing values removed.\n",
      " |      \n",
      " |      See the :ref:`User Guide <missing_data>` for more on which values are\n",
      " |      considered missing, and how to work with missing data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index'}, default 0\n",
      " |          There is only one axis to drop values from.\n",
      " |      inplace : bool, default False\n",
      " |          If True, do operation inplace and return None.\n",
      " |      how : str, optional\n",
      " |          Not in use. Kept for compatibility.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or None\n",
      " |          Series with NA entries dropped from it or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.isna: Indicate missing values.\n",
      " |      Series.notna : Indicate existing (non-missing) values.\n",
      " |      Series.fillna : Replace missing values.\n",
      " |      DataFrame.dropna : Drop rows or columns which contain NA values.\n",
      " |      Index.dropna : Drop missing indices.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> ser = pd.Series([1., 2., np.nan])\n",
      " |      >>> ser\n",
      " |      0    1.0\n",
      " |      1    2.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Drop NA values from a Series.\n",
      " |      \n",
      " |      >>> ser.dropna()\n",
      " |      0    1.0\n",
      " |      1    2.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Keep the Series with valid entries in the same variable.\n",
      " |      \n",
      " |      >>> ser.dropna(inplace=True)\n",
      " |      >>> ser\n",
      " |      0    1.0\n",
      " |      1    2.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Empty strings are not considered NA values. ``None`` is considered an\n",
      " |      NA value.\n",
      " |      \n",
      " |      >>> ser = pd.Series([np.NaN, 2, pd.NaT, '', None, 'I stay'])\n",
      " |      >>> ser\n",
      " |      0       NaN\n",
      " |      1         2\n",
      " |      2       NaT\n",
      " |      3\n",
      " |      4      None\n",
      " |      5    I stay\n",
      " |      dtype: object\n",
      " |      >>> ser.dropna()\n",
      " |      1         2\n",
      " |      3\n",
      " |      5    I stay\n",
      " |      dtype: object\n",
      " |  \n",
      " |  duplicated(self, keep='first') -> 'Series'\n",
      " |      Indicate duplicate Series values.\n",
      " |      \n",
      " |      Duplicated values are indicated as ``True`` values in the resulting\n",
      " |      Series. Either all duplicates, all except the first or all except the\n",
      " |      last occurrence of duplicates can be indicated.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      keep : {'first', 'last', False}, default 'first'\n",
      " |          Method to handle dropping duplicates:\n",
      " |      \n",
      " |          - 'first' : Mark duplicates as ``True`` except for the first\n",
      " |            occurrence.\n",
      " |          - 'last' : Mark duplicates as ``True`` except for the last\n",
      " |            occurrence.\n",
      " |          - ``False`` : Mark all duplicates as ``True``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series[bool]\n",
      " |          Series indicating whether each value has occurred in the\n",
      " |          preceding values.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.duplicated : Equivalent method on pandas.Index.\n",
      " |      DataFrame.duplicated : Equivalent method on pandas.DataFrame.\n",
      " |      Series.drop_duplicates : Remove duplicate values from Series.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      By default, for each set of duplicated values, the first occurrence is\n",
      " |      set on False and all others on True:\n",
      " |      \n",
      " |      >>> animals = pd.Series(['lama', 'cow', 'lama', 'beetle', 'lama'])\n",
      " |      >>> animals.duplicated()\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      4     True\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      which is equivalent to\n",
      " |      \n",
      " |      >>> animals.duplicated(keep='first')\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      4     True\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      By using 'last', the last occurrence of each set of duplicated values\n",
      " |      is set on False and all others on True:\n",
      " |      \n",
      " |      >>> animals.duplicated(keep='last')\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      4    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      By setting keep on ``False``, all duplicates are True:\n",
      " |      \n",
      " |      >>> animals.duplicated(keep=False)\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      4     True\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  eq(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Return Equal to of series and other, element-wise (binary operator `eq`).\n",
      " |      \n",
      " |      Equivalent to ``series == other``, but with support to substitute a fill_value for\n",
      " |      missing data in either one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result of filling (at that location) will be missing.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.eq(b, fill_value=0)\n",
      " |      a     True\n",
      " |      b    False\n",
      " |      c    False\n",
      " |      d    False\n",
      " |      e    False\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  explode(self, ignore_index: 'bool' = False) -> 'Series'\n",
      " |      Transform each element of a list-like to a row.\n",
      " |      \n",
      " |      .. versionadded:: 0.25.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ignore_index : bool, default False\n",
      " |          If True, the resulting index will be labeled 0, 1, …, n - 1.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Exploded lists to rows; index will be duplicated for these rows.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.str.split : Split string values on specified separator.\n",
      " |      Series.unstack : Unstack, a.k.a. pivot, Series with MultiIndex\n",
      " |          to produce DataFrame.\n",
      " |      DataFrame.melt : Unpivot a DataFrame from wide format to long format.\n",
      " |      DataFrame.explode : Explode a DataFrame from list-like\n",
      " |          columns to long format.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This routine will explode list-likes including lists, tuples, sets,\n",
      " |      Series, and np.ndarray. The result dtype of the subset rows will\n",
      " |      be object. Scalars will be returned unchanged, and empty list-likes will\n",
      " |      result in a np.nan for that row. In addition, the ordering of elements in\n",
      " |      the output will be non-deterministic when exploding sets.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([[1, 2, 3], 'foo', [], [3, 4]])\n",
      " |      >>> s\n",
      " |      0    [1, 2, 3]\n",
      " |      1          foo\n",
      " |      2           []\n",
      " |      3       [3, 4]\n",
      " |      dtype: object\n",
      " |      \n",
      " |      >>> s.explode()\n",
      " |      0      1\n",
      " |      0      2\n",
      " |      0      3\n",
      " |      1    foo\n",
      " |      2    NaN\n",
      " |      3      3\n",
      " |      3      4\n",
      " |      dtype: object\n",
      " |  \n",
      " |  ffill(self: 'Series', axis: 'None | Axis' = None, inplace: 'bool' = False, limit: 'None | int' = None, downcast=None) -> 'Series | None'\n",
      " |      Synonym for :meth:`DataFrame.fillna` with ``method='ffill'``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame or None\n",
      " |          Object with missing values filled or None if ``inplace=True``.\n",
      " |  \n",
      " |  fillna(self, value: 'object | ArrayLike | None' = None, method: 'FillnaOptions | None' = None, axis=None, inplace=False, limit=None, downcast=None) -> 'Series | None'\n",
      " |      Fill NA/NaN values using the specified method.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      value : scalar, dict, Series, or DataFrame\n",
      " |          Value to use to fill holes (e.g. 0), alternately a\n",
      " |          dict/Series/DataFrame of values specifying which value to use for\n",
      " |          each index (for a Series) or column (for a DataFrame).  Values not\n",
      " |          in the dict/Series/DataFrame will not be filled. This value cannot\n",
      " |          be a list.\n",
      " |      method : {'backfill', 'bfill', 'pad', 'ffill', None}, default None\n",
      " |          Method to use for filling holes in reindexed Series\n",
      " |          pad / ffill: propagate last valid observation forward to next valid\n",
      " |          backfill / bfill: use next valid observation to fill gap.\n",
      " |      axis : {0 or 'index'}\n",
      " |          Axis along which to fill missing values.\n",
      " |      inplace : bool, default False\n",
      " |          If True, fill in-place. Note: this will modify any\n",
      " |          other views on this object (e.g., a no-copy slice for a column in a\n",
      " |          DataFrame).\n",
      " |      limit : int, default None\n",
      " |          If method is specified, this is the maximum number of consecutive\n",
      " |          NaN values to forward/backward fill. In other words, if there is\n",
      " |          a gap with more than this number of consecutive NaNs, it will only\n",
      " |          be partially filled. If method is not specified, this is the\n",
      " |          maximum number of entries along the entire axis where NaNs will be\n",
      " |          filled. Must be greater than 0 if not None.\n",
      " |      downcast : dict, default is None\n",
      " |          A dict of item->dtype of what to downcast if possible,\n",
      " |          or the string 'infer' which will try to downcast to an appropriate\n",
      " |          equal type (e.g. float64 to int64 if possible).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or None\n",
      " |          Object with missing values filled or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      interpolate : Fill NaN values using interpolation.\n",
      " |      reindex : Conform object to new index.\n",
      " |      asfreq : Convert TimeSeries to specified frequency.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[np.nan, 2, np.nan, 0],\n",
      " |      ...                    [3, 4, np.nan, 1],\n",
      " |      ...                    [np.nan, np.nan, np.nan, 5],\n",
      " |      ...                    [np.nan, 3, np.nan, 4]],\n",
      " |      ...                   columns=list(\"ABCD\"))\n",
      " |      >>> df\n",
      " |           A    B   C  D\n",
      " |      0  NaN  2.0 NaN  0\n",
      " |      1  3.0  4.0 NaN  1\n",
      " |      2  NaN  NaN NaN  5\n",
      " |      3  NaN  3.0 NaN  4\n",
      " |      \n",
      " |      Replace all NaN elements with 0s.\n",
      " |      \n",
      " |      >>> df.fillna(0)\n",
      " |          A   B   C   D\n",
      " |      0   0.0 2.0 0.0 0\n",
      " |      1   3.0 4.0 0.0 1\n",
      " |      2   0.0 0.0 0.0 5\n",
      " |      3   0.0 3.0 0.0 4\n",
      " |      \n",
      " |      We can also propagate non-null values forward or backward.\n",
      " |      \n",
      " |      >>> df.fillna(method=\"ffill\")\n",
      " |          A   B   C   D\n",
      " |      0   NaN 2.0 NaN 0\n",
      " |      1   3.0 4.0 NaN 1\n",
      " |      2   3.0 4.0 NaN 5\n",
      " |      3   3.0 3.0 NaN 4\n",
      " |      \n",
      " |      Replace all NaN elements in column 'A', 'B', 'C', and 'D', with 0, 1,\n",
      " |      2, and 3 respectively.\n",
      " |      \n",
      " |      >>> values = {\"A\": 0, \"B\": 1, \"C\": 2, \"D\": 3}\n",
      " |      >>> df.fillna(value=values)\n",
      " |          A   B   C   D\n",
      " |      0   0.0 2.0 2.0 0\n",
      " |      1   3.0 4.0 2.0 1\n",
      " |      2   0.0 1.0 2.0 5\n",
      " |      3   0.0 3.0 2.0 4\n",
      " |      \n",
      " |      Only replace the first NaN element.\n",
      " |      \n",
      " |      >>> df.fillna(value=values, limit=1)\n",
      " |          A   B   C   D\n",
      " |      0   0.0 2.0 2.0 0\n",
      " |      1   3.0 4.0 NaN 1\n",
      " |      2   NaN 1.0 NaN 5\n",
      " |      3   NaN 3.0 NaN 4\n",
      " |      \n",
      " |      When filling using a DataFrame, replacement happens along\n",
      " |      the same column names and same indices\n",
      " |      \n",
      " |      >>> df2 = pd.DataFrame(np.zeros((4, 4)), columns=list(\"ABCE\"))\n",
      " |      >>> df.fillna(df2)\n",
      " |          A   B   C   D\n",
      " |      0   0.0 2.0 0.0 0\n",
      " |      1   3.0 4.0 0.0 1\n",
      " |      2   0.0 0.0 0.0 5\n",
      " |      3   0.0 3.0 0.0 4\n",
      " |  \n",
      " |  floordiv(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Return Integer division of series and other, element-wise (binary operator `floordiv`).\n",
      " |      \n",
      " |      Equivalent to ``series // other``, but with support to substitute a fill_value for\n",
      " |      missing data in either one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result of filling (at that location) will be missing.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.rfloordiv : Reverse of the Integer division operator, see\n",
      " |          `Python documentation\n",
      " |          <https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types>`_\n",
      " |          for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.floordiv(b, fill_value=0)\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      c    NaN\n",
      " |      d    0.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  ge(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Return Greater than or equal to of series and other, element-wise (binary operator `ge`).\n",
      " |      \n",
      " |      Equivalent to ``series >= other``, but with support to substitute a fill_value for\n",
      " |      missing data in either one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result of filling (at that location) will be missing.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan, 1], index=['a', 'b', 'c', 'd', 'e'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      e    1.0\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([0, 1, 2, np.nan, 1], index=['a', 'b', 'c', 'd', 'f'])\n",
      " |      >>> b\n",
      " |      a    0.0\n",
      " |      b    1.0\n",
      " |      c    2.0\n",
      " |      d    NaN\n",
      " |      f    1.0\n",
      " |      dtype: float64\n",
      " |      >>> a.ge(b, fill_value=0)\n",
      " |      a     True\n",
      " |      b     True\n",
      " |      c    False\n",
      " |      d    False\n",
      " |      e     True\n",
      " |      f    False\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  groupby(self, by=None, axis=0, level=None, as_index: 'bool' = True, sort: 'bool' = True, group_keys: 'bool' = True, squeeze: 'bool | lib.NoDefault' = <no_default>, observed: 'bool' = False, dropna: 'bool' = True) -> 'SeriesGroupBy'\n",
      " |      Group Series using a mapper or by a Series of columns.\n",
      " |      \n",
      " |      A groupby operation involves some combination of splitting the\n",
      " |      object, applying a function, and combining the results. This can be\n",
      " |      used to group large amounts of data and compute operations on these\n",
      " |      groups.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      by : mapping, function, label, or list of labels\n",
      " |          Used to determine the groups for the groupby.\n",
      " |          If ``by`` is a function, it's called on each value of the object's\n",
      " |          index. If a dict or Series is passed, the Series or dict VALUES\n",
      " |          will be used to determine the groups (the Series' values are first\n",
      " |          aligned; see ``.align()`` method). If an ndarray is passed, the\n",
      " |          values are used as-is to determine the groups. A label or list of\n",
      " |          labels may be passed to group by the columns in ``self``. Notice\n",
      " |          that a tuple is interpreted as a (single) key.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Split along rows (0) or columns (1).\n",
      " |      level : int, level name, or sequence of such, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), group by a particular\n",
      " |          level or levels.\n",
      " |      as_index : bool, default True\n",
      " |          For aggregated output, return object with group labels as the\n",
      " |          index. Only relevant for DataFrame input. as_index=False is\n",
      " |          effectively \"SQL-style\" grouped output.\n",
      " |      sort : bool, default True\n",
      " |          Sort group keys. Get better performance by turning this off.\n",
      " |          Note this does not influence the order of observations within each\n",
      " |          group. Groupby preserves the order of rows within each group.\n",
      " |      group_keys : bool, default True\n",
      " |          When calling apply, add group keys to index to identify pieces.\n",
      " |      squeeze : bool, default False\n",
      " |          Reduce the dimensionality of the return type if possible,\n",
      " |          otherwise return a consistent type.\n",
      " |      \n",
      " |          .. deprecated:: 1.1.0\n",
      " |      \n",
      " |      observed : bool, default False\n",
      " |          This only applies if any of the groupers are Categoricals.\n",
      " |          If True: only show observed values for categorical groupers.\n",
      " |          If False: show all values for categorical groupers.\n",
      " |      dropna : bool, default True\n",
      " |          If True, and if group keys contain NA values, NA values together\n",
      " |          with row/column will be dropped.\n",
      " |          If False, NA values will also be treated as the key in groups\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      SeriesGroupBy\n",
      " |          Returns a groupby object that contains information about the groups.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      resample : Convenience method for frequency conversion and resampling\n",
      " |          of time series.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the `user guide\n",
      " |      <https://pandas.pydata.org/pandas-docs/stable/groupby.html>`__ for more.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> ser = pd.Series([390., 350., 30., 20.],\n",
      " |      ...                 index=['Falcon', 'Falcon', 'Parrot', 'Parrot'], name=\"Max Speed\")\n",
      " |      >>> ser\n",
      " |      Falcon    390.0\n",
      " |      Falcon    350.0\n",
      " |      Parrot     30.0\n",
      " |      Parrot     20.0\n",
      " |      Name: Max Speed, dtype: float64\n",
      " |      >>> ser.groupby([\"a\", \"b\", \"a\", \"b\"]).mean()\n",
      " |      a    210.0\n",
      " |      b    185.0\n",
      " |      Name: Max Speed, dtype: float64\n",
      " |      >>> ser.groupby(level=0).mean()\n",
      " |      Falcon    370.0\n",
      " |      Parrot     25.0\n",
      " |      Name: Max Speed, dtype: float64\n",
      " |      >>> ser.groupby(ser > 100).mean()\n",
      " |      Max Speed\n",
      " |      False     25.0\n",
      " |      True     370.0\n",
      " |      Name: Max Speed, dtype: float64\n",
      " |      \n",
      " |      **Grouping by Indexes**\n",
      " |      \n",
      " |      We can groupby different levels of a hierarchical index\n",
      " |      using the `level` parameter:\n",
      " |      \n",
      " |      >>> arrays = [['Falcon', 'Falcon', 'Parrot', 'Parrot'],\n",
      " |      ...           ['Captive', 'Wild', 'Captive', 'Wild']]\n",
      " |      >>> index = pd.MultiIndex.from_arrays(arrays, names=('Animal', 'Type'))\n",
      " |      >>> ser = pd.Series([390., 350., 30., 20.], index=index, name=\"Max Speed\")\n",
      " |      >>> ser\n",
      " |      Animal  Type\n",
      " |      Falcon  Captive    390.0\n",
      " |              Wild       350.0\n",
      " |      Parrot  Captive     30.0\n",
      " |              Wild        20.0\n",
      " |      Name: Max Speed, dtype: float64\n",
      " |      >>> ser.groupby(level=0).mean()\n",
      " |      Animal\n",
      " |      Falcon    370.0\n",
      " |      Parrot     25.0\n",
      " |      Name: Max Speed, dtype: float64\n",
      " |      >>> ser.groupby(level=\"Type\").mean()\n",
      " |      Type\n",
      " |      Captive    210.0\n",
      " |      Wild       185.0\n",
      " |      Name: Max Speed, dtype: float64\n",
      " |      \n",
      " |      We can also choose to include `NA` in group keys or not by defining\n",
      " |      `dropna` parameter, the default setting is `True`:\n",
      " |      \n",
      " |      >>> ser = pd.Series([1, 2, 3, 3], index=[\"a\", 'a', 'b', np.nan])\n",
      " |      >>> ser.groupby(level=0).sum()\n",
      " |      a    3\n",
      " |      b    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> ser.groupby(level=0, dropna=False).sum()\n",
      " |      a    3\n",
      " |      b    3\n",
      " |      NaN  3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> arrays = ['Falcon', 'Falcon', 'Parrot', 'Parrot']\n",
      " |      >>> ser = pd.Series([390., 350., 30., 20.], index=arrays, name=\"Max Speed\")\n",
      " |      >>> ser.groupby([\"a\", \"b\", \"a\", np.nan]).mean()\n",
      " |      a    210.0\n",
      " |      b    350.0\n",
      " |      Name: Max Speed, dtype: float64\n",
      " |      \n",
      " |      >>> ser.groupby([\"a\", \"b\", \"a\", np.nan], dropna=False).mean()\n",
      " |      a    210.0\n",
      " |      b    350.0\n",
      " |      NaN   20.0\n",
      " |      Name: Max Speed, dtype: float64\n",
      " |  \n",
      " |  gt(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Return Greater than of series and other, element-wise (binary operator `gt`).\n",
      " |      \n",
      " |      Equivalent to ``series > other``, but with support to substitute a fill_value for\n",
      " |      missing data in either one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result of filling (at that location) will be missing.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan, 1], index=['a', 'b', 'c', 'd', 'e'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      e    1.0\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([0, 1, 2, np.nan, 1], index=['a', 'b', 'c', 'd', 'f'])\n",
      " |      >>> b\n",
      " |      a    0.0\n",
      " |      b    1.0\n",
      " |      c    2.0\n",
      " |      d    NaN\n",
      " |      f    1.0\n",
      " |      dtype: float64\n",
      " |      >>> a.gt(b, fill_value=0)\n",
      " |      a     True\n",
      " |      b    False\n",
      " |      c    False\n",
      " |      d    False\n",
      " |      e     True\n",
      " |      f    False\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  hist = hist_series(self, by=None, ax=None, grid: 'bool' = True, xlabelsize: 'int | None' = None, xrot: 'float | None' = None, ylabelsize: 'int | None' = None, yrot: 'float | None' = None, figsize: 'tuple[int, int] | None' = None, bins: 'int | Sequence[int]' = 10, backend: 'str | None' = None, legend: 'bool' = False, **kwargs)\n",
      " |      Draw histogram of the input series using matplotlib.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      by : object, optional\n",
      " |          If passed, then used to form histograms for separate groups.\n",
      " |      ax : matplotlib axis object\n",
      " |          If not passed, uses gca().\n",
      " |      grid : bool, default True\n",
      " |          Whether to show axis grid lines.\n",
      " |      xlabelsize : int, default None\n",
      " |          If specified changes the x-axis label size.\n",
      " |      xrot : float, default None\n",
      " |          Rotation of x axis labels.\n",
      " |      ylabelsize : int, default None\n",
      " |          If specified changes the y-axis label size.\n",
      " |      yrot : float, default None\n",
      " |          Rotation of y axis labels.\n",
      " |      figsize : tuple, default None\n",
      " |          Figure size in inches by default.\n",
      " |      bins : int or sequence, default 10\n",
      " |          Number of histogram bins to be used. If an integer is given, bins + 1\n",
      " |          bin edges are calculated and returned. If bins is a sequence, gives\n",
      " |          bin edges, including left edge of first bin and right edge of last\n",
      " |          bin. In this case, bins is returned unmodified.\n",
      " |      backend : str, default None\n",
      " |          Backend to use instead of the backend specified in the option\n",
      " |          ``plotting.backend``. For instance, 'matplotlib'. Alternatively, to\n",
      " |          specify the ``plotting.backend`` for the whole session, set\n",
      " |          ``pd.options.plotting.backend``.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      legend : bool, default False\n",
      " |          Whether to show the legend.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      **kwargs\n",
      " |          To be passed to the actual plotting function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      matplotlib.AxesSubplot\n",
      " |          A histogram plot.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      matplotlib.axes.Axes.hist : Plot a histogram using matplotlib.\n",
      " |  \n",
      " |  idxmax(self, axis=0, skipna=True, *args, **kwargs)\n",
      " |      Return the row label of the maximum value.\n",
      " |      \n",
      " |      If multiple values equal the maximum, the first row label with that\n",
      " |      value is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : int, default 0\n",
      " |          For compatibility with DataFrame.idxmax. Redundant for application\n",
      " |          on Series.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If the entire Series is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs\n",
      " |          Additional arguments and keywords have no effect but might be\n",
      " |          accepted for compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index\n",
      " |          Label of the maximum value.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          If the Series is empty.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.argmax : Return indices of the maximum values\n",
      " |          along the given axis.\n",
      " |      DataFrame.idxmax : Return index of first occurrence of maximum\n",
      " |          over requested axis.\n",
      " |      Series.idxmin : Return index *label* of the first occurrence\n",
      " |          of minimum of values.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the Series version of ``ndarray.argmax``. This method\n",
      " |      returns the label of the maximum, while ``ndarray.argmax`` returns\n",
      " |      the position. To get the position, use ``series.values.argmax()``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(data=[1, None, 4, 3, 4],\n",
      " |      ...               index=['A', 'B', 'C', 'D', 'E'])\n",
      " |      >>> s\n",
      " |      A    1.0\n",
      " |      B    NaN\n",
      " |      C    4.0\n",
      " |      D    3.0\n",
      " |      E    4.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.idxmax()\n",
      " |      'C'\n",
      " |      \n",
      " |      If `skipna` is False and there is an NA value in the data,\n",
      " |      the function returns ``nan``.\n",
      " |      \n",
      " |      >>> s.idxmax(skipna=False)\n",
      " |      nan\n",
      " |  \n",
      " |  idxmin(self, axis=0, skipna=True, *args, **kwargs)\n",
      " |      Return the row label of the minimum value.\n",
      " |      \n",
      " |      If multiple values equal the minimum, the first row label with that\n",
      " |      value is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : int, default 0\n",
      " |          For compatibility with DataFrame.idxmin. Redundant for application\n",
      " |          on Series.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If the entire Series is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs\n",
      " |          Additional arguments and keywords have no effect but might be\n",
      " |          accepted for compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index\n",
      " |          Label of the minimum value.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          If the Series is empty.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.argmin : Return indices of the minimum values\n",
      " |          along the given axis.\n",
      " |      DataFrame.idxmin : Return index of first occurrence of minimum\n",
      " |          over requested axis.\n",
      " |      Series.idxmax : Return index *label* of the first occurrence\n",
      " |          of maximum of values.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the Series version of ``ndarray.argmin``. This method\n",
      " |      returns the label of the minimum, while ``ndarray.argmin`` returns\n",
      " |      the position. To get the position, use ``series.values.argmin()``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(data=[1, None, 4, 1],\n",
      " |      ...               index=['A', 'B', 'C', 'D'])\n",
      " |      >>> s\n",
      " |      A    1.0\n",
      " |      B    NaN\n",
      " |      C    4.0\n",
      " |      D    1.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.idxmin()\n",
      " |      'A'\n",
      " |      \n",
      " |      If `skipna` is False and there is an NA value in the data,\n",
      " |      the function returns ``nan``.\n",
      " |      \n",
      " |      >>> s.idxmin(skipna=False)\n",
      " |      nan\n",
      " |  \n",
      " |  interpolate(self: 'Series', method: 'str' = 'linear', axis: 'Axis' = 0, limit: 'int | None' = None, inplace: 'bool' = False, limit_direction: 'str | None' = None, limit_area: 'str | None' = None, downcast: 'str | None' = None, **kwargs) -> 'Series | None'\n",
      " |      Fill NaN values using an interpolation method.\n",
      " |      \n",
      " |      Please note that only ``method='linear'`` is supported for\n",
      " |      DataFrame/Series with a MultiIndex.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : str, default 'linear'\n",
      " |          Interpolation technique to use. One of:\n",
      " |      \n",
      " |          * 'linear': Ignore the index and treat the values as equally\n",
      " |            spaced. This is the only method supported on MultiIndexes.\n",
      " |          * 'time': Works on daily and higher resolution data to interpolate\n",
      " |            given length of interval.\n",
      " |          * 'index', 'values': use the actual numerical values of the index.\n",
      " |          * 'pad': Fill in NaNs using existing values.\n",
      " |          * 'nearest', 'zero', 'slinear', 'quadratic', 'cubic', 'spline',\n",
      " |            'barycentric', 'polynomial': Passed to\n",
      " |            `scipy.interpolate.interp1d`. These methods use the numerical\n",
      " |            values of the index.  Both 'polynomial' and 'spline' require that\n",
      " |            you also specify an `order` (int), e.g.\n",
      " |            ``df.interpolate(method='polynomial', order=5)``.\n",
      " |          * 'krogh', 'piecewise_polynomial', 'spline', 'pchip', 'akima',\n",
      " |            'cubicspline': Wrappers around the SciPy interpolation methods of\n",
      " |            similar names. See `Notes`.\n",
      " |          * 'from_derivatives': Refers to\n",
      " |            `scipy.interpolate.BPoly.from_derivatives` which\n",
      " |            replaces 'piecewise_polynomial' interpolation method in\n",
      " |            scipy 0.18.\n",
      " |      \n",
      " |      axis : {{0 or 'index', 1 or 'columns', None}}, default None\n",
      " |          Axis to interpolate along.\n",
      " |      limit : int, optional\n",
      " |          Maximum number of consecutive NaNs to fill. Must be greater than\n",
      " |          0.\n",
      " |      inplace : bool, default False\n",
      " |          Update the data in place if possible.\n",
      " |      limit_direction : {{'forward', 'backward', 'both'}}, Optional\n",
      " |          Consecutive NaNs will be filled in this direction.\n",
      " |      \n",
      " |          If limit is specified:\n",
      " |              * If 'method' is 'pad' or 'ffill', 'limit_direction' must be 'forward'.\n",
      " |              * If 'method' is 'backfill' or 'bfill', 'limit_direction' must be\n",
      " |                'backwards'.\n",
      " |      \n",
      " |          If 'limit' is not specified:\n",
      " |              * If 'method' is 'backfill' or 'bfill', the default is 'backward'\n",
      " |              * else the default is 'forward'\n",
      " |      \n",
      " |          .. versionchanged:: 1.1.0\n",
      " |              raises ValueError if `limit_direction` is 'forward' or 'both' and\n",
      " |                  method is 'backfill' or 'bfill'.\n",
      " |              raises ValueError if `limit_direction` is 'backward' or 'both' and\n",
      " |                  method is 'pad' or 'ffill'.\n",
      " |      \n",
      " |      limit_area : {{`None`, 'inside', 'outside'}}, default None\n",
      " |          If limit is specified, consecutive NaNs will be filled with this\n",
      " |          restriction.\n",
      " |      \n",
      " |          * ``None``: No fill restriction.\n",
      " |          * 'inside': Only fill NaNs surrounded by valid values\n",
      " |            (interpolate).\n",
      " |          * 'outside': Only fill NaNs outside valid values (extrapolate).\n",
      " |      \n",
      " |      downcast : optional, 'infer' or None, defaults to None\n",
      " |          Downcast dtypes if possible.\n",
      " |      ``**kwargs`` : optional\n",
      " |          Keyword arguments to pass on to the interpolating function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame or None\n",
      " |          Returns the same object type as the caller, interpolated at\n",
      " |          some or all ``NaN`` values or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      fillna : Fill missing values using different methods.\n",
      " |      scipy.interpolate.Akima1DInterpolator : Piecewise cubic polynomials\n",
      " |          (Akima interpolator).\n",
      " |      scipy.interpolate.BPoly.from_derivatives : Piecewise polynomial in the\n",
      " |          Bernstein basis.\n",
      " |      scipy.interpolate.interp1d : Interpolate a 1-D function.\n",
      " |      scipy.interpolate.KroghInterpolator : Interpolate polynomial (Krogh\n",
      " |          interpolator).\n",
      " |      scipy.interpolate.PchipInterpolator : PCHIP 1-d monotonic cubic\n",
      " |          interpolation.\n",
      " |      scipy.interpolate.CubicSpline : Cubic spline data interpolator.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The 'krogh', 'piecewise_polynomial', 'spline', 'pchip' and 'akima'\n",
      " |      methods are wrappers around the respective SciPy implementations of\n",
      " |      similar names. These use the actual numerical values of the index.\n",
      " |      For more information on their behavior, see the\n",
      " |      `SciPy documentation\n",
      " |      <https://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation>`__\n",
      " |      and `SciPy tutorial\n",
      " |      <https://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html>`__.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Filling in ``NaN`` in a :class:`~pandas.Series` via linear\n",
      " |      interpolation.\n",
      " |      \n",
      " |      >>> s = pd.Series([0, 1, np.nan, 3])\n",
      " |      >>> s\n",
      " |      0    0.0\n",
      " |      1    1.0\n",
      " |      2    NaN\n",
      " |      3    3.0\n",
      " |      dtype: float64\n",
      " |      >>> s.interpolate()\n",
      " |      0    0.0\n",
      " |      1    1.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Filling in ``NaN`` in a Series by padding, but filling at most two\n",
      " |      consecutive ``NaN`` at a time.\n",
      " |      \n",
      " |      >>> s = pd.Series([np.nan, \"single_one\", np.nan,\n",
      " |      ...                \"fill_two_more\", np.nan, np.nan, np.nan,\n",
      " |      ...                4.71, np.nan])\n",
      " |      >>> s\n",
      " |      0              NaN\n",
      " |      1       single_one\n",
      " |      2              NaN\n",
      " |      3    fill_two_more\n",
      " |      4              NaN\n",
      " |      5              NaN\n",
      " |      6              NaN\n",
      " |      7             4.71\n",
      " |      8              NaN\n",
      " |      dtype: object\n",
      " |      >>> s.interpolate(method='pad', limit=2)\n",
      " |      0              NaN\n",
      " |      1       single_one\n",
      " |      2       single_one\n",
      " |      3    fill_two_more\n",
      " |      4    fill_two_more\n",
      " |      5    fill_two_more\n",
      " |      6              NaN\n",
      " |      7             4.71\n",
      " |      8             4.71\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Filling in ``NaN`` in a Series via polynomial interpolation or splines:\n",
      " |      Both 'polynomial' and 'spline' methods require that you also specify\n",
      " |      an ``order`` (int).\n",
      " |      \n",
      " |      >>> s = pd.Series([0, 2, np.nan, 8])\n",
      " |      >>> s.interpolate(method='polynomial', order=2)\n",
      " |      0    0.000000\n",
      " |      1    2.000000\n",
      " |      2    4.666667\n",
      " |      3    8.000000\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Fill the DataFrame forward (that is, going down) along each column\n",
      " |      using linear interpolation.\n",
      " |      \n",
      " |      Note how the last entry in column 'a' is interpolated differently,\n",
      " |      because there is no entry after it to use for interpolation.\n",
      " |      Note how the first entry in column 'b' remains ``NaN``, because there\n",
      " |      is no entry before it to use for interpolation.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([(0.0, np.nan, -1.0, 1.0),\n",
      " |      ...                    (np.nan, 2.0, np.nan, np.nan),\n",
      " |      ...                    (2.0, 3.0, np.nan, 9.0),\n",
      " |      ...                    (np.nan, 4.0, -4.0, 16.0)],\n",
      " |      ...                   columns=list('abcd'))\n",
      " |      >>> df\n",
      " |           a    b    c     d\n",
      " |      0  0.0  NaN -1.0   1.0\n",
      " |      1  NaN  2.0  NaN   NaN\n",
      " |      2  2.0  3.0  NaN   9.0\n",
      " |      3  NaN  4.0 -4.0  16.0\n",
      " |      >>> df.interpolate(method='linear', limit_direction='forward', axis=0)\n",
      " |           a    b    c     d\n",
      " |      0  0.0  NaN -1.0   1.0\n",
      " |      1  1.0  2.0 -2.0   5.0\n",
      " |      2  2.0  3.0 -3.0   9.0\n",
      " |      3  2.0  4.0 -4.0  16.0\n",
      " |      \n",
      " |      Using polynomial interpolation.\n",
      " |      \n",
      " |      >>> df['d'].interpolate(method='polynomial', order=2)\n",
      " |      0     1.0\n",
      " |      1     4.0\n",
      " |      2     9.0\n",
      " |      3    16.0\n",
      " |      Name: d, dtype: float64\n",
      " |  \n",
      " |  isin(self, values) -> 'Series'\n",
      " |      Whether elements in Series are contained in `values`.\n",
      " |      \n",
      " |      Return a boolean Series showing whether each element in the Series\n",
      " |      matches an element in the passed sequence of `values` exactly.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      values : set or list-like\n",
      " |          The sequence of values to test. Passing in a single string will\n",
      " |          raise a ``TypeError``. Instead, turn a single string into a\n",
      " |          list of one element.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Series of booleans indicating if each element is in values.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |        * If `values` is a string\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.isin : Equivalent method on DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(['lama', 'cow', 'lama', 'beetle', 'lama',\n",
      " |      ...                'hippo'], name='animal')\n",
      " |      >>> s.isin(['cow', 'lama'])\n",
      " |      0     True\n",
      " |      1     True\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      4     True\n",
      " |      5    False\n",
      " |      Name: animal, dtype: bool\n",
      " |      \n",
      " |      Passing a single string as ``s.isin('lama')`` will raise an error. Use\n",
      " |      a list of one element instead:\n",
      " |      \n",
      " |      >>> s.isin(['lama'])\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      4     True\n",
      " |      5    False\n",
      " |      Name: animal, dtype: bool\n",
      " |      \n",
      " |      Strings and integers are distinct and are therefore not comparable:\n",
      " |      \n",
      " |      >>> pd.Series([1]).isin(['1'])\n",
      " |      0    False\n",
      " |      dtype: bool\n",
      " |      >>> pd.Series([1.1]).isin(['1.1'])\n",
      " |      0    False\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  isna(self) -> 'Series'\n",
      " |      Detect missing values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are NA.\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, gets mapped to True\n",
      " |      values.\n",
      " |      Everything else gets mapped to False values. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Mask of bool values for each element in Series that\n",
      " |          indicates whether an element is an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.isnull : Alias of isna.\n",
      " |      Series.notna : Boolean inverse of isna.\n",
      " |      Series.dropna : Omit axes labels with missing values.\n",
      " |      isna : Top-level isna.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(dict(age=[5, 6, np.NaN],\n",
      " |      ...                    born=[pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                          pd.Timestamp('1940-04-25')],\n",
      " |      ...                    name=['Alfred', 'Batman', ''],\n",
      " |      ...                    toy=[None, 'Batmobile', 'Joker']))\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.isna()\n",
      " |           age   born   name    toy\n",
      " |      0  False   True  False   True\n",
      " |      1  False  False  False  False\n",
      " |      2   True  False  False  False\n",
      " |      \n",
      " |      Show which entries in a Series are NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.isna()\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  isnull(self) -> 'Series'\n",
      " |      Detect missing values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are NA.\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, gets mapped to True\n",
      " |      values.\n",
      " |      Everything else gets mapped to False values. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Mask of bool values for each element in Series that\n",
      " |          indicates whether an element is an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.isnull : Alias of isna.\n",
      " |      Series.notna : Boolean inverse of isna.\n",
      " |      Series.dropna : Omit axes labels with missing values.\n",
      " |      isna : Top-level isna.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(dict(age=[5, 6, np.NaN],\n",
      " |      ...                    born=[pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                          pd.Timestamp('1940-04-25')],\n",
      " |      ...                    name=['Alfred', 'Batman', ''],\n",
      " |      ...                    toy=[None, 'Batmobile', 'Joker']))\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.isna()\n",
      " |           age   born   name    toy\n",
      " |      0  False   True  False   True\n",
      " |      1  False  False  False  False\n",
      " |      2   True  False  False  False\n",
      " |      \n",
      " |      Show which entries in a Series are NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.isna()\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  items(self) -> 'Iterable[tuple[Hashable, Any]]'\n",
      " |      Lazily iterate over (index, value) tuples.\n",
      " |      \n",
      " |      This method returns an iterable tuple (index, value). This is\n",
      " |      convenient if you want to create a lazy iterator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      iterable\n",
      " |          Iterable of tuples containing the (index, value) pairs from a\n",
      " |          Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.items : Iterate over (column name, Series) pairs.\n",
      " |      DataFrame.iterrows : Iterate over DataFrame rows as (index, Series) pairs.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(['A', 'B', 'C'])\n",
      " |      >>> for index, value in s.items():\n",
      " |      ...     print(f\"Index : {index}, Value : {value}\")\n",
      " |      Index : 0, Value : A\n",
      " |      Index : 1, Value : B\n",
      " |      Index : 2, Value : C\n",
      " |  \n",
      " |  iteritems(self) -> 'Iterable[tuple[Hashable, Any]]'\n",
      " |      Lazily iterate over (index, value) tuples.\n",
      " |      \n",
      " |      This method returns an iterable tuple (index, value). This is\n",
      " |      convenient if you want to create a lazy iterator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      iterable\n",
      " |          Iterable of tuples containing the (index, value) pairs from a\n",
      " |          Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.items : Iterate over (column name, Series) pairs.\n",
      " |      DataFrame.iterrows : Iterate over DataFrame rows as (index, Series) pairs.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(['A', 'B', 'C'])\n",
      " |      >>> for index, value in s.items():\n",
      " |      ...     print(f\"Index : {index}, Value : {value}\")\n",
      " |      Index : 0, Value : A\n",
      " |      Index : 1, Value : B\n",
      " |      Index : 2, Value : C\n",
      " |  \n",
      " |  keys(self) -> 'Index'\n",
      " |      Return alias for index.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index\n",
      " |          Index of the Series.\n",
      " |  \n",
      " |  kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return unbiased kurtosis over requested axis.\n",
      " |      \n",
      " |      Kurtosis obtained using Fisher's definition of\n",
      " |      kurtosis (kurtosis of normal == 0.0). Normalized by N-1.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series (if level specified)\n",
      " |  \n",
      " |  kurtosis = kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |  \n",
      " |  le(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Return Less than or equal to of series and other, element-wise (binary operator `le`).\n",
      " |      \n",
      " |      Equivalent to ``series <= other``, but with support to substitute a fill_value for\n",
      " |      missing data in either one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result of filling (at that location) will be missing.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan, 1], index=['a', 'b', 'c', 'd', 'e'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      e    1.0\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([0, 1, 2, np.nan, 1], index=['a', 'b', 'c', 'd', 'f'])\n",
      " |      >>> b\n",
      " |      a    0.0\n",
      " |      b    1.0\n",
      " |      c    2.0\n",
      " |      d    NaN\n",
      " |      f    1.0\n",
      " |      dtype: float64\n",
      " |      >>> a.le(b, fill_value=0)\n",
      " |      a    False\n",
      " |      b     True\n",
      " |      c     True\n",
      " |      d    False\n",
      " |      e    False\n",
      " |      f     True\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  lt(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Return Less than of series and other, element-wise (binary operator `lt`).\n",
      " |      \n",
      " |      Equivalent to ``series < other``, but with support to substitute a fill_value for\n",
      " |      missing data in either one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result of filling (at that location) will be missing.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan, 1], index=['a', 'b', 'c', 'd', 'e'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      e    1.0\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([0, 1, 2, np.nan, 1], index=['a', 'b', 'c', 'd', 'f'])\n",
      " |      >>> b\n",
      " |      a    0.0\n",
      " |      b    1.0\n",
      " |      c    2.0\n",
      " |      d    NaN\n",
      " |      f    1.0\n",
      " |      dtype: float64\n",
      " |      >>> a.lt(b, fill_value=0)\n",
      " |      a    False\n",
      " |      b    False\n",
      " |      c     True\n",
      " |      d    False\n",
      " |      e    False\n",
      " |      f     True\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  mad(self, axis=None, skipna=None, level=None)\n",
      " |      Return the mean absolute deviation of the values over the requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default None\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series (if level specified)\n",
      " |  \n",
      " |  map(self, arg, na_action=None) -> 'Series'\n",
      " |      Map values of Series according to input correspondence.\n",
      " |      \n",
      " |      Used for substituting each value in a Series with another value,\n",
      " |      that may be derived from a function, a ``dict`` or\n",
      " |      a :class:`Series`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg : function, collections.abc.Mapping subclass or Series\n",
      " |          Mapping correspondence.\n",
      " |      na_action : {None, 'ignore'}, default None\n",
      " |          If 'ignore', propagate NaN values, without passing them to the\n",
      " |          mapping correspondence.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Same index as caller.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.apply : For applying more complex functions on a Series.\n",
      " |      DataFrame.apply : Apply a function row-/column-wise.\n",
      " |      DataFrame.applymap : Apply a function elementwise on a whole DataFrame.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      When ``arg`` is a dictionary, values in Series that are not in the\n",
      " |      dictionary (as keys) are converted to ``NaN``. However, if the\n",
      " |      dictionary is a ``dict`` subclass that defines ``__missing__`` (i.e.\n",
      " |      provides a method for default values), then this default is used\n",
      " |      rather than ``NaN``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(['cat', 'dog', np.nan, 'rabbit'])\n",
      " |      >>> s\n",
      " |      0      cat\n",
      " |      1      dog\n",
      " |      2      NaN\n",
      " |      3   rabbit\n",
      " |      dtype: object\n",
      " |      \n",
      " |      ``map`` accepts a ``dict`` or a ``Series``. Values that are not found\n",
      " |      in the ``dict`` are converted to ``NaN``, unless the dict has a default\n",
      " |      value (e.g. ``defaultdict``):\n",
      " |      \n",
      " |      >>> s.map({'cat': 'kitten', 'dog': 'puppy'})\n",
      " |      0   kitten\n",
      " |      1    puppy\n",
      " |      2      NaN\n",
      " |      3      NaN\n",
      " |      dtype: object\n",
      " |      \n",
      " |      It also accepts a function:\n",
      " |      \n",
      " |      >>> s.map('I am a {}'.format)\n",
      " |      0       I am a cat\n",
      " |      1       I am a dog\n",
      " |      2       I am a nan\n",
      " |      3    I am a rabbit\n",
      " |      dtype: object\n",
      " |      \n",
      " |      To avoid applying the function to missing values (and keep them as\n",
      " |      ``NaN``) ``na_action='ignore'`` can be used:\n",
      " |      \n",
      " |      >>> s.map('I am a {}'.format, na_action='ignore')\n",
      " |      0     I am a cat\n",
      " |      1     I am a dog\n",
      " |      2            NaN\n",
      " |      3  I am a rabbit\n",
      " |      dtype: object\n",
      " |  \n",
      " |  mask(self, cond, other=nan, inplace=False, axis=None, level=None, errors='raise', try_cast=<no_default>)\n",
      " |      Replace values where the condition is True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      cond : bool Series/DataFrame, array-like, or callable\n",
      " |          Where `cond` is False, keep the original value. Where\n",
      " |          True, replace with corresponding value from `other`.\n",
      " |          If `cond` is callable, it is computed on the Series/DataFrame and\n",
      " |          should return boolean Series/DataFrame or array. The callable must\n",
      " |          not change input Series/DataFrame (though pandas doesn't check it).\n",
      " |      other : scalar, Series/DataFrame, or callable\n",
      " |          Entries where `cond` is True are replaced with\n",
      " |          corresponding value from `other`.\n",
      " |          If other is callable, it is computed on the Series/DataFrame and\n",
      " |          should return scalar or Series/DataFrame. The callable must not\n",
      " |          change input Series/DataFrame (though pandas doesn't check it).\n",
      " |      inplace : bool, default False\n",
      " |          Whether to perform the operation in place on the data.\n",
      " |      axis : int, default None\n",
      " |          Alignment axis if needed.\n",
      " |      level : int, default None\n",
      " |          Alignment level if needed.\n",
      " |      errors : str, {'raise', 'ignore'}, default 'raise'\n",
      " |          Note that currently this parameter won't affect\n",
      " |          the results and will always coerce to a suitable dtype.\n",
      " |      \n",
      " |          - 'raise' : allow exceptions to be raised.\n",
      " |          - 'ignore' : suppress exceptions. On error return original object.\n",
      " |      \n",
      " |      try_cast : bool, default None\n",
      " |          Try to cast the result back to the input type (if possible).\n",
      " |      \n",
      " |          .. deprecated:: 1.3.0\n",
      " |              Manually cast back if necessary.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Same type as caller or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :func:`DataFrame.where` : Return an object of same shape as\n",
      " |          self.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The mask method is an application of the if-then idiom. For each\n",
      " |      element in the calling DataFrame, if ``cond`` is ``False`` the\n",
      " |      element is used; otherwise the corresponding element from the DataFrame\n",
      " |      ``other`` is used.\n",
      " |      \n",
      " |      The signature for :func:`DataFrame.where` differs from\n",
      " |      :func:`numpy.where`. Roughly ``df1.where(m, df2)`` is equivalent to\n",
      " |      ``np.where(m, df1, df2)``.\n",
      " |      \n",
      " |      For further details and examples see the ``mask`` documentation in\n",
      " |      :ref:`indexing <indexing.where_mask>`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(range(5))\n",
      " |      >>> s.where(s > 0)\n",
      " |      0    NaN\n",
      " |      1    1.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      4    4.0\n",
      " |      dtype: float64\n",
      " |      >>> s.mask(s > 0)\n",
      " |      0    0.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.where(s > 1, 10)\n",
      " |      0    10\n",
      " |      1    10\n",
      " |      2    2\n",
      " |      3    3\n",
      " |      4    4\n",
      " |      dtype: int64\n",
      " |      >>> s.mask(s > 1, 10)\n",
      " |      0     0\n",
      " |      1     1\n",
      " |      2    10\n",
      " |      3    10\n",
      " |      4    10\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  0  1\n",
      " |      1  2  3\n",
      " |      2  4  5\n",
      " |      3  6  7\n",
      " |      4  8  9\n",
      " |      >>> m = df % 3 == 0\n",
      " |      >>> df.where(m, -df)\n",
      " |         A  B\n",
      " |      0  0 -1\n",
      " |      1 -2  3\n",
      " |      2 -4 -5\n",
      " |      3  6 -7\n",
      " |      4 -8  9\n",
      " |      >>> df.where(m, -df) == np.where(m, df, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      >>> df.where(m, -df) == df.mask(~m, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |  \n",
      " |  max(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the maximum of the values over the requested axis.\n",
      " |      \n",
      " |      If you want the *index* of the maximum, use ``idxmax``. This is the equivalent of the ``numpy.ndarray`` method ``argmax``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series (if level specified)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sum : Return the sum.\n",
      " |      Series.min : Return the minimum.\n",
      " |      Series.max : Return the maximum.\n",
      " |      Series.idxmin : Return the index of the minimum.\n",
      " |      Series.idxmax : Return the index of the maximum.\n",
      " |      DataFrame.sum : Return the sum over the requested axis.\n",
      " |      DataFrame.min : Return the minimum over the requested axis.\n",
      " |      DataFrame.max : Return the maximum over the requested axis.\n",
      " |      DataFrame.idxmin : Return the index of the minimum over the requested axis.\n",
      " |      DataFrame.idxmax : Return the index of the maximum over the requested axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.MultiIndex.from_arrays([\n",
      " |      ...     ['warm', 'warm', 'cold', 'cold'],\n",
      " |      ...     ['dog', 'falcon', 'fish', 'spider']],\n",
      " |      ...     names=['blooded', 'animal'])\n",
      " |      >>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n",
      " |      >>> s\n",
      " |      blooded  animal\n",
      " |      warm     dog       4\n",
      " |               falcon    2\n",
      " |      cold     fish      0\n",
      " |               spider    8\n",
      " |      Name: legs, dtype: int64\n",
      " |      \n",
      " |      >>> s.max()\n",
      " |      8\n",
      " |  \n",
      " |  mean(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the mean of the values over the requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series (if level specified)\n",
      " |  \n",
      " |  median(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the median of the values over the requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series (if level specified)\n",
      " |  \n",
      " |  memory_usage(self, index: 'bool' = True, deep: 'bool' = False) -> 'int'\n",
      " |      Return the memory usage of the Series.\n",
      " |      \n",
      " |      The memory usage can optionally include the contribution of\n",
      " |      the index and of elements of `object` dtype.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : bool, default True\n",
      " |          Specifies whether to include the memory usage of the Series index.\n",
      " |      deep : bool, default False\n",
      " |          If True, introspect the data deeply by interrogating\n",
      " |          `object` dtypes for system-level memory consumption, and include\n",
      " |          it in the returned value.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      int\n",
      " |          Bytes of memory consumed.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.nbytes : Total bytes consumed by the elements of the\n",
      " |          array.\n",
      " |      DataFrame.memory_usage : Bytes consumed by a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(range(3))\n",
      " |      >>> s.memory_usage()\n",
      " |      152\n",
      " |      \n",
      " |      Not including the index gives the size of the rest of the data, which\n",
      " |      is necessarily smaller:\n",
      " |      \n",
      " |      >>> s.memory_usage(index=False)\n",
      " |      24\n",
      " |      \n",
      " |      The memory footprint of `object` values is ignored by default:\n",
      " |      \n",
      " |      >>> s = pd.Series([\"a\", \"b\"])\n",
      " |      >>> s.values\n",
      " |      array(['a', 'b'], dtype=object)\n",
      " |      >>> s.memory_usage()\n",
      " |      144\n",
      " |      >>> s.memory_usage(deep=True)\n",
      " |      244\n",
      " |  \n",
      " |  min(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the minimum of the values over the requested axis.\n",
      " |      \n",
      " |      If you want the *index* of the minimum, use ``idxmin``. This is the equivalent of the ``numpy.ndarray`` method ``argmin``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series (if level specified)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sum : Return the sum.\n",
      " |      Series.min : Return the minimum.\n",
      " |      Series.max : Return the maximum.\n",
      " |      Series.idxmin : Return the index of the minimum.\n",
      " |      Series.idxmax : Return the index of the maximum.\n",
      " |      DataFrame.sum : Return the sum over the requested axis.\n",
      " |      DataFrame.min : Return the minimum over the requested axis.\n",
      " |      DataFrame.max : Return the maximum over the requested axis.\n",
      " |      DataFrame.idxmin : Return the index of the minimum over the requested axis.\n",
      " |      DataFrame.idxmax : Return the index of the maximum over the requested axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.MultiIndex.from_arrays([\n",
      " |      ...     ['warm', 'warm', 'cold', 'cold'],\n",
      " |      ...     ['dog', 'falcon', 'fish', 'spider']],\n",
      " |      ...     names=['blooded', 'animal'])\n",
      " |      >>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n",
      " |      >>> s\n",
      " |      blooded  animal\n",
      " |      warm     dog       4\n",
      " |               falcon    2\n",
      " |      cold     fish      0\n",
      " |               spider    8\n",
      " |      Name: legs, dtype: int64\n",
      " |      \n",
      " |      >>> s.min()\n",
      " |      0\n",
      " |  \n",
      " |  mod(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Return Modulo of series and other, element-wise (binary operator `mod`).\n",
      " |      \n",
      " |      Equivalent to ``series % other``, but with support to substitute a fill_value for\n",
      " |      missing data in either one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result of filling (at that location) will be missing.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.rmod : Reverse of the Modulo operator, see\n",
      " |          `Python documentation\n",
      " |          <https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types>`_\n",
      " |          for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.mod(b, fill_value=0)\n",
      " |      a    0.0\n",
      " |      b    NaN\n",
      " |      c    NaN\n",
      " |      d    0.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  mode(self, dropna=True) -> 'Series'\n",
      " |      Return the mode(s) of the Series.\n",
      " |      \n",
      " |      The mode is the value that appears most often. There can be multiple modes.\n",
      " |      \n",
      " |      Always returns Series even if only one value is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dropna : bool, default True\n",
      " |          Don't consider counts of NaN/NaT.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Modes of the Series in sorted order.\n",
      " |  \n",
      " |  mul(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Return Multiplication of series and other, element-wise (binary operator `mul`).\n",
      " |      \n",
      " |      Equivalent to ``series * other``, but with support to substitute a fill_value for\n",
      " |      missing data in either one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result of filling (at that location) will be missing.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.rmul : Reverse of the Multiplication operator, see\n",
      " |          `Python documentation\n",
      " |          <https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types>`_\n",
      " |          for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.multiply(b, fill_value=0)\n",
      " |      a    1.0\n",
      " |      b    0.0\n",
      " |      c    0.0\n",
      " |      d    0.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  multiply = mul(self, other, level=None, fill_value=None, axis=0)\n",
      " |  \n",
      " |  ne(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Return Not equal to of series and other, element-wise (binary operator `ne`).\n",
      " |      \n",
      " |      Equivalent to ``series != other``, but with support to substitute a fill_value for\n",
      " |      missing data in either one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result of filling (at that location) will be missing.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.ne(b, fill_value=0)\n",
      " |      a    False\n",
      " |      b     True\n",
      " |      c     True\n",
      " |      d     True\n",
      " |      e     True\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  nlargest(self, n=5, keep='first') -> 'Series'\n",
      " |      Return the largest `n` elements.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, default 5\n",
      " |          Return this many descending sorted values.\n",
      " |      keep : {'first', 'last', 'all'}, default 'first'\n",
      " |          When there are duplicate values that cannot all fit in a\n",
      " |          Series of `n` elements:\n",
      " |      \n",
      " |          - ``first`` : return the first `n` occurrences in order\n",
      " |              of appearance.\n",
      " |          - ``last`` : return the last `n` occurrences in reverse\n",
      " |              order of appearance.\n",
      " |          - ``all`` : keep all occurrences. This can result in a Series of\n",
      " |              size larger than `n`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The `n` largest values in the Series, sorted in decreasing order.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.nsmallest: Get the `n` smallest elements.\n",
      " |      Series.sort_values: Sort Series by values.\n",
      " |      Series.head: Return the first `n` rows.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Faster than ``.sort_values(ascending=False).head(n)`` for small `n`\n",
      " |      relative to the size of the ``Series`` object.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> countries_population = {\"Italy\": 59000000, \"France\": 65000000,\n",
      " |      ...                         \"Malta\": 434000, \"Maldives\": 434000,\n",
      " |      ...                         \"Brunei\": 434000, \"Iceland\": 337000,\n",
      " |      ...                         \"Nauru\": 11300, \"Tuvalu\": 11300,\n",
      " |      ...                         \"Anguilla\": 11300, \"Montserrat\": 5200}\n",
      " |      >>> s = pd.Series(countries_population)\n",
      " |      >>> s\n",
      " |      Italy       59000000\n",
      " |      France      65000000\n",
      " |      Malta         434000\n",
      " |      Maldives      434000\n",
      " |      Brunei        434000\n",
      " |      Iceland       337000\n",
      " |      Nauru          11300\n",
      " |      Tuvalu         11300\n",
      " |      Anguilla       11300\n",
      " |      Montserrat      5200\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      The `n` largest elements where ``n=5`` by default.\n",
      " |      \n",
      " |      >>> s.nlargest()\n",
      " |      France      65000000\n",
      " |      Italy       59000000\n",
      " |      Malta         434000\n",
      " |      Maldives      434000\n",
      " |      Brunei        434000\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      The `n` largest elements where ``n=3``. Default `keep` value is 'first'\n",
      " |      so Malta will be kept.\n",
      " |      \n",
      " |      >>> s.nlargest(3)\n",
      " |      France    65000000\n",
      " |      Italy     59000000\n",
      " |      Malta       434000\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      The `n` largest elements where ``n=3`` and keeping the last duplicates.\n",
      " |      Brunei will be kept since it is the last with value 434000 based on\n",
      " |      the index order.\n",
      " |      \n",
      " |      >>> s.nlargest(3, keep='last')\n",
      " |      France      65000000\n",
      " |      Italy       59000000\n",
      " |      Brunei        434000\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      The `n` largest elements where ``n=3`` with all duplicates kept. Note\n",
      " |      that the returned Series has five elements due to the three duplicates.\n",
      " |      \n",
      " |      >>> s.nlargest(3, keep='all')\n",
      " |      France      65000000\n",
      " |      Italy       59000000\n",
      " |      Malta         434000\n",
      " |      Maldives      434000\n",
      " |      Brunei        434000\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  notna(self) -> 'Series'\n",
      " |      Detect existing (non-missing) values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are not NA.\n",
      " |      Non-missing values get mapped to True. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, get mapped to False\n",
      " |      values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Mask of bool values for each element in Series that\n",
      " |          indicates whether an element is not an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.notnull : Alias of notna.\n",
      " |      Series.isna : Boolean inverse of notna.\n",
      " |      Series.dropna : Omit axes labels with missing values.\n",
      " |      notna : Top-level notna.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are not NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(dict(age=[5, 6, np.NaN],\n",
      " |      ...                    born=[pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                          pd.Timestamp('1940-04-25')],\n",
      " |      ...                    name=['Alfred', 'Batman', ''],\n",
      " |      ...                    toy=[None, 'Batmobile', 'Joker']))\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.notna()\n",
      " |           age   born  name    toy\n",
      " |      0   True  False  True  False\n",
      " |      1   True   True  True   True\n",
      " |      2  False   True  True   True\n",
      " |      \n",
      " |      Show which entries in a Series are not NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.notna()\n",
      " |      0     True\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  notnull(self) -> 'Series'\n",
      " |      Detect existing (non-missing) values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are not NA.\n",
      " |      Non-missing values get mapped to True. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, get mapped to False\n",
      " |      values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Mask of bool values for each element in Series that\n",
      " |          indicates whether an element is not an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.notnull : Alias of notna.\n",
      " |      Series.isna : Boolean inverse of notna.\n",
      " |      Series.dropna : Omit axes labels with missing values.\n",
      " |      notna : Top-level notna.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are not NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(dict(age=[5, 6, np.NaN],\n",
      " |      ...                    born=[pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                          pd.Timestamp('1940-04-25')],\n",
      " |      ...                    name=['Alfred', 'Batman', ''],\n",
      " |      ...                    toy=[None, 'Batmobile', 'Joker']))\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.notna()\n",
      " |           age   born  name    toy\n",
      " |      0   True  False  True  False\n",
      " |      1   True   True  True   True\n",
      " |      2  False   True  True   True\n",
      " |      \n",
      " |      Show which entries in a Series are not NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.notna()\n",
      " |      0     True\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  nsmallest(self, n: 'int' = 5, keep: 'str' = 'first') -> 'Series'\n",
      " |      Return the smallest `n` elements.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, default 5\n",
      " |          Return this many ascending sorted values.\n",
      " |      keep : {'first', 'last', 'all'}, default 'first'\n",
      " |          When there are duplicate values that cannot all fit in a\n",
      " |          Series of `n` elements:\n",
      " |      \n",
      " |          - ``first`` : return the first `n` occurrences in order\n",
      " |              of appearance.\n",
      " |          - ``last`` : return the last `n` occurrences in reverse\n",
      " |              order of appearance.\n",
      " |          - ``all`` : keep all occurrences. This can result in a Series of\n",
      " |              size larger than `n`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The `n` smallest values in the Series, sorted in increasing order.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.nlargest: Get the `n` largest elements.\n",
      " |      Series.sort_values: Sort Series by values.\n",
      " |      Series.head: Return the first `n` rows.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Faster than ``.sort_values().head(n)`` for small `n` relative to\n",
      " |      the size of the ``Series`` object.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> countries_population = {\"Italy\": 59000000, \"France\": 65000000,\n",
      " |      ...                         \"Brunei\": 434000, \"Malta\": 434000,\n",
      " |      ...                         \"Maldives\": 434000, \"Iceland\": 337000,\n",
      " |      ...                         \"Nauru\": 11300, \"Tuvalu\": 11300,\n",
      " |      ...                         \"Anguilla\": 11300, \"Montserrat\": 5200}\n",
      " |      >>> s = pd.Series(countries_population)\n",
      " |      >>> s\n",
      " |      Italy       59000000\n",
      " |      France      65000000\n",
      " |      Brunei        434000\n",
      " |      Malta         434000\n",
      " |      Maldives      434000\n",
      " |      Iceland       337000\n",
      " |      Nauru          11300\n",
      " |      Tuvalu         11300\n",
      " |      Anguilla       11300\n",
      " |      Montserrat      5200\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      The `n` smallest elements where ``n=5`` by default.\n",
      " |      \n",
      " |      >>> s.nsmallest()\n",
      " |      Montserrat    5200\n",
      " |      Nauru        11300\n",
      " |      Tuvalu       11300\n",
      " |      Anguilla     11300\n",
      " |      Iceland     337000\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      The `n` smallest elements where ``n=3``. Default `keep` value is\n",
      " |      'first' so Nauru and Tuvalu will be kept.\n",
      " |      \n",
      " |      >>> s.nsmallest(3)\n",
      " |      Montserrat   5200\n",
      " |      Nauru       11300\n",
      " |      Tuvalu      11300\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      The `n` smallest elements where ``n=3`` and keeping the last\n",
      " |      duplicates. Anguilla and Tuvalu will be kept since they are the last\n",
      " |      with value 11300 based on the index order.\n",
      " |      \n",
      " |      >>> s.nsmallest(3, keep='last')\n",
      " |      Montserrat   5200\n",
      " |      Anguilla    11300\n",
      " |      Tuvalu      11300\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      The `n` smallest elements where ``n=3`` with all duplicates kept. Note\n",
      " |      that the returned Series has four elements due to the three duplicates.\n",
      " |      \n",
      " |      >>> s.nsmallest(3, keep='all')\n",
      " |      Montserrat   5200\n",
      " |      Nauru       11300\n",
      " |      Tuvalu      11300\n",
      " |      Anguilla    11300\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  pop(self, item: 'Hashable') -> 'Any'\n",
      " |      Return item and drops from series. Raise KeyError if not found.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      item : label\n",
      " |          Index of the element that needs to be removed.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Value that is popped from series.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> ser = pd.Series([1,2,3])\n",
      " |      \n",
      " |      >>> ser.pop(0)\n",
      " |      1\n",
      " |      \n",
      " |      >>> ser\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  pow(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Return Exponential power of series and other, element-wise (binary operator `pow`).\n",
      " |      \n",
      " |      Equivalent to ``series ** other``, but with support to substitute a fill_value for\n",
      " |      missing data in either one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result of filling (at that location) will be missing.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.rpow : Reverse of the Exponential power operator, see\n",
      " |          `Python documentation\n",
      " |          <https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types>`_\n",
      " |          for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.pow(b, fill_value=0)\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    0.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  prod(self, axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)\n",
      " |      Return the product of the values over the requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      min_count : int, default 0\n",
      " |          The required number of valid values to perform the operation. If fewer than\n",
      " |          ``min_count`` non-NA values are present the result will be NA.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series (if level specified)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sum : Return the sum.\n",
      " |      Series.min : Return the minimum.\n",
      " |      Series.max : Return the maximum.\n",
      " |      Series.idxmin : Return the index of the minimum.\n",
      " |      Series.idxmax : Return the index of the maximum.\n",
      " |      DataFrame.sum : Return the sum over the requested axis.\n",
      " |      DataFrame.min : Return the minimum over the requested axis.\n",
      " |      DataFrame.max : Return the maximum over the requested axis.\n",
      " |      DataFrame.idxmin : Return the index of the minimum over the requested axis.\n",
      " |      DataFrame.idxmax : Return the index of the maximum over the requested axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      By default, the product of an empty or all-NA Series is ``1``\n",
      " |      \n",
      " |      >>> pd.Series([], dtype=\"float64\").prod()\n",
      " |      1.0\n",
      " |      \n",
      " |      This can be controlled with the ``min_count`` parameter\n",
      " |      \n",
      " |      >>> pd.Series([], dtype=\"float64\").prod(min_count=1)\n",
      " |      nan\n",
      " |      \n",
      " |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
      " |      empty series identically.\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).prod()\n",
      " |      1.0\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).prod(min_count=1)\n",
      " |      nan\n",
      " |  \n",
      " |  product = prod(self, axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)\n",
      " |  \n",
      " |  quantile(self, q=0.5, interpolation='linear')\n",
      " |      Return value at the given quantile.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      q : float or array-like, default 0.5 (50% quantile)\n",
      " |          The quantile(s) to compute, which can lie in range: 0 <= q <= 1.\n",
      " |      interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n",
      " |          This optional parameter specifies the interpolation method to use,\n",
      " |          when the desired quantile lies between two data points `i` and `j`:\n",
      " |      \n",
      " |              * linear: `i + (j - i) * fraction`, where `fraction` is the\n",
      " |                fractional part of the index surrounded by `i` and `j`.\n",
      " |              * lower: `i`.\n",
      " |              * higher: `j`.\n",
      " |              * nearest: `i` or `j` whichever is nearest.\n",
      " |              * midpoint: (`i` + `j`) / 2.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      float or Series\n",
      " |          If ``q`` is an array, a Series will be returned where the\n",
      " |          index is ``q`` and the values are the quantiles, otherwise\n",
      " |          a float will be returned.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.Rolling.quantile : Calculate the rolling quantile.\n",
      " |      numpy.percentile : Returns the q-th percentile(s) of the array elements.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s.quantile(.5)\n",
      " |      2.5\n",
      " |      >>> s.quantile([.25, .5, .75])\n",
      " |      0.25    1.75\n",
      " |      0.50    2.50\n",
      " |      0.75    3.25\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  radd(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Return Addition of series and other, element-wise (binary operator `radd`).\n",
      " |      \n",
      " |      Equivalent to ``other + series``, but with support to substitute a fill_value for\n",
      " |      missing data in either one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result of filling (at that location) will be missing.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.add : Element-wise Addition, see\n",
      " |          `Python documentation\n",
      " |          <https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types>`_\n",
      " |          for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  ravel(self, order='C')\n",
      " |      Return the flattened underlying data as an ndarray.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray or ndarray-like\n",
      " |          Flattened data of the Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.ravel : Return a flattened array.\n",
      " |  \n",
      " |  rdiv = rtruediv(self, other, level=None, fill_value=None, axis=0)\n",
      " |  \n",
      " |  rdivmod(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Return Integer division and modulo of series and other, element-wise (binary operator `rdivmod`).\n",
      " |      \n",
      " |      Equivalent to ``other divmod series``, but with support to substitute a fill_value for\n",
      " |      missing data in either one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result of filling (at that location) will be missing.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      2-Tuple of Series\n",
      " |          The result of the operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.divmod : Element-wise Integer division and modulo, see\n",
      " |          `Python documentation\n",
      " |          <https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types>`_\n",
      " |          for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.divmod(b, fill_value=0)\n",
      " |      (a    1.0\n",
      " |       b    NaN\n",
      " |       c    NaN\n",
      " |       d    0.0\n",
      " |       e    NaN\n",
      " |       dtype: float64,\n",
      " |       a    0.0\n",
      " |       b    NaN\n",
      " |       c    NaN\n",
      " |       d    0.0\n",
      " |       e    NaN\n",
      " |       dtype: float64)\n",
      " |  \n",
      " |  reindex(self, index=None, **kwargs)\n",
      " |      Conform Series to new index with optional filling logic.\n",
      " |      \n",
      " |      Places NA/NaN in locations having no value in the previous index. A new object\n",
      " |      is produced unless the new index is equivalent to the current one and\n",
      " |      ``copy=False``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      \n",
      " |      index : array-like, optional\n",
      " |          New labels / index to conform to, should be specified using\n",
      " |          keywords. Preferably an Index object to avoid duplicating data.\n",
      " |      \n",
      " |      method : {None, 'backfill'/'bfill', 'pad'/'ffill', 'nearest'}\n",
      " |          Method to use for filling holes in reindexed DataFrame.\n",
      " |          Please note: this is only applicable to DataFrames/Series with a\n",
      " |          monotonically increasing/decreasing index.\n",
      " |      \n",
      " |          * None (default): don't fill gaps\n",
      " |          * pad / ffill: Propagate last valid observation forward to next\n",
      " |            valid.\n",
      " |          * backfill / bfill: Use next valid observation to fill gap.\n",
      " |          * nearest: Use nearest valid observations to fill gap.\n",
      " |      \n",
      " |      copy : bool, default True\n",
      " |          Return a new object, even if the passed indexes are the same.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : scalar, default np.NaN\n",
      " |          Value to use for missing values. Defaults to NaN, but can be any\n",
      " |          \"compatible\" value.\n",
      " |      limit : int, default None\n",
      " |          Maximum number of consecutive elements to forward or backward fill.\n",
      " |      tolerance : optional\n",
      " |          Maximum distance between original and new labels for inexact\n",
      " |          matches. The values of the index at the matching locations most\n",
      " |          satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      " |      \n",
      " |          Tolerance may be a scalar value, which applies the same tolerance\n",
      " |          to all values, or list-like, which applies variable tolerance per\n",
      " |          element. List-like includes list, tuple, array, Series, and must be\n",
      " |          the same size as the index and its dtype must exactly match the\n",
      " |          index's type.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series with changed index.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.set_index : Set row labels.\n",
      " |      DataFrame.reset_index : Remove row labels or move them to new columns.\n",
      " |      DataFrame.reindex_like : Change to same indices as other DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      ``DataFrame.reindex`` supports two calling conventions\n",
      " |      \n",
      " |      * ``(index=index_labels, columns=column_labels, ...)``\n",
      " |      * ``(labels, axis={'index', 'columns'}, ...)``\n",
      " |      \n",
      " |      We *highly* recommend using keyword arguments to clarify your\n",
      " |      intent.\n",
      " |      \n",
      " |      Create a dataframe with some fictional data.\n",
      " |      \n",
      " |      >>> index = ['Firefox', 'Chrome', 'Safari', 'IE10', 'Konqueror']\n",
      " |      >>> df = pd.DataFrame({'http_status': [200, 200, 404, 404, 301],\n",
      " |      ...                   'response_time': [0.04, 0.02, 0.07, 0.08, 1.0]},\n",
      " |      ...                   index=index)\n",
      " |      >>> df\n",
      " |                 http_status  response_time\n",
      " |      Firefox            200           0.04\n",
      " |      Chrome             200           0.02\n",
      " |      Safari             404           0.07\n",
      " |      IE10               404           0.08\n",
      " |      Konqueror          301           1.00\n",
      " |      \n",
      " |      Create a new index and reindex the dataframe. By default\n",
      " |      values in the new index that do not have corresponding\n",
      " |      records in the dataframe are assigned ``NaN``.\n",
      " |      \n",
      " |      >>> new_index = ['Safari', 'Iceweasel', 'Comodo Dragon', 'IE10',\n",
      " |      ...              'Chrome']\n",
      " |      >>> df.reindex(new_index)\n",
      " |                     http_status  response_time\n",
      " |      Safari               404.0           0.07\n",
      " |      Iceweasel              NaN            NaN\n",
      " |      Comodo Dragon          NaN            NaN\n",
      " |      IE10                 404.0           0.08\n",
      " |      Chrome               200.0           0.02\n",
      " |      \n",
      " |      We can fill in the missing values by passing a value to\n",
      " |      the keyword ``fill_value``. Because the index is not monotonically\n",
      " |      increasing or decreasing, we cannot use arguments to the keyword\n",
      " |      ``method`` to fill the ``NaN`` values.\n",
      " |      \n",
      " |      >>> df.reindex(new_index, fill_value=0)\n",
      " |                     http_status  response_time\n",
      " |      Safari                 404           0.07\n",
      " |      Iceweasel                0           0.00\n",
      " |      Comodo Dragon            0           0.00\n",
      " |      IE10                   404           0.08\n",
      " |      Chrome                 200           0.02\n",
      " |      \n",
      " |      >>> df.reindex(new_index, fill_value='missing')\n",
      " |                    http_status response_time\n",
      " |      Safari                404          0.07\n",
      " |      Iceweasel         missing       missing\n",
      " |      Comodo Dragon     missing       missing\n",
      " |      IE10                  404          0.08\n",
      " |      Chrome                200          0.02\n",
      " |      \n",
      " |      We can also reindex the columns.\n",
      " |      \n",
      " |      >>> df.reindex(columns=['http_status', 'user_agent'])\n",
      " |                 http_status  user_agent\n",
      " |      Firefox            200         NaN\n",
      " |      Chrome             200         NaN\n",
      " |      Safari             404         NaN\n",
      " |      IE10               404         NaN\n",
      " |      Konqueror          301         NaN\n",
      " |      \n",
      " |      Or we can use \"axis-style\" keyword arguments\n",
      " |      \n",
      " |      >>> df.reindex(['http_status', 'user_agent'], axis=\"columns\")\n",
      " |                 http_status  user_agent\n",
      " |      Firefox            200         NaN\n",
      " |      Chrome             200         NaN\n",
      " |      Safari             404         NaN\n",
      " |      IE10               404         NaN\n",
      " |      Konqueror          301         NaN\n",
      " |      \n",
      " |      To further illustrate the filling functionality in\n",
      " |      ``reindex``, we will create a dataframe with a\n",
      " |      monotonically increasing index (for example, a sequence\n",
      " |      of dates).\n",
      " |      \n",
      " |      >>> date_index = pd.date_range('1/1/2010', periods=6, freq='D')\n",
      " |      >>> df2 = pd.DataFrame({\"prices\": [100, 101, np.nan, 100, 89, 88]},\n",
      " |      ...                    index=date_index)\n",
      " |      >>> df2\n",
      " |                  prices\n",
      " |      2010-01-01   100.0\n",
      " |      2010-01-02   101.0\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04   100.0\n",
      " |      2010-01-05    89.0\n",
      " |      2010-01-06    88.0\n",
      " |      \n",
      " |      Suppose we decide to expand the dataframe to cover a wider\n",
      " |      date range.\n",
      " |      \n",
      " |      >>> date_index2 = pd.date_range('12/29/2009', periods=10, freq='D')\n",
      " |      >>> df2.reindex(date_index2)\n",
      " |                  prices\n",
      " |      2009-12-29     NaN\n",
      " |      2009-12-30     NaN\n",
      " |      2009-12-31     NaN\n",
      " |      2010-01-01   100.0\n",
      " |      2010-01-02   101.0\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04   100.0\n",
      " |      2010-01-05    89.0\n",
      " |      2010-01-06    88.0\n",
      " |      2010-01-07     NaN\n",
      " |      \n",
      " |      The index entries that did not have a value in the original data frame\n",
      " |      (for example, '2009-12-29') are by default filled with ``NaN``.\n",
      " |      If desired, we can fill in the missing values using one of several\n",
      " |      options.\n",
      " |      \n",
      " |      For example, to back-propagate the last valid value to fill the ``NaN``\n",
      " |      values, pass ``bfill`` as an argument to the ``method`` keyword.\n",
      " |      \n",
      " |      >>> df2.reindex(date_index2, method='bfill')\n",
      " |                  prices\n",
      " |      2009-12-29   100.0\n",
      " |      2009-12-30   100.0\n",
      " |      2009-12-31   100.0\n",
      " |      2010-01-01   100.0\n",
      " |      2010-01-02   101.0\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04   100.0\n",
      " |      2010-01-05    89.0\n",
      " |      2010-01-06    88.0\n",
      " |      2010-01-07     NaN\n",
      " |      \n",
      " |      Please note that the ``NaN`` value present in the original dataframe\n",
      " |      (at index value 2010-01-03) will not be filled by any of the\n",
      " |      value propagation schemes. This is because filling while reindexing\n",
      " |      does not look at dataframe values, but only compares the original and\n",
      " |      desired indexes. If you do want to fill in the ``NaN`` values present\n",
      " |      in the original dataframe, use the ``fillna()`` method.\n",
      " |      \n",
      " |      See the :ref:`user guide <basics.reindexing>` for more.\n",
      " |  \n",
      " |  rename(self, index=None, *, axis=None, copy=True, inplace=False, level=None, errors='ignore')\n",
      " |      Alter Series index labels or name.\n",
      " |      \n",
      " |      Function / dict values must be unique (1-to-1). Labels not contained in\n",
      " |      a dict / Series will be left as-is. Extra labels listed don't throw an\n",
      " |      error.\n",
      " |      \n",
      " |      Alternatively, change ``Series.name`` with a scalar value.\n",
      " |      \n",
      " |      See the :ref:`user guide <basics.rename>` for more.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or \"index\"}\n",
      " |          Unused. Accepted for compatibility with DataFrame method only.\n",
      " |      index : scalar, hashable sequence, dict-like or function, optional\n",
      " |          Functions or dict-like are transformations to apply to\n",
      " |          the index.\n",
      " |          Scalar or hashable sequence-like will alter the ``Series.name``\n",
      " |          attribute.\n",
      " |      \n",
      " |      **kwargs\n",
      " |          Additional keyword arguments passed to the function. Only the\n",
      " |          \"inplace\" keyword is used.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or None\n",
      " |          Series with index labels or name altered or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.rename : Corresponding DataFrame method.\n",
      " |      Series.rename_axis : Set the name of the axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |      >>> s.rename(\"my_name\")  # scalar, changes Series.name\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      Name: my_name, dtype: int64\n",
      " |      >>> s.rename(lambda x: x ** 2)  # function, changes labels\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      4    3\n",
      " |      dtype: int64\n",
      " |      >>> s.rename({1: 3, 2: 5})  # mapping, changes labels\n",
      " |      0    1\n",
      " |      3    2\n",
      " |      5    3\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  reorder_levels(self, order) -> 'Series'\n",
      " |      Rearrange index levels using input order.\n",
      " |      \n",
      " |      May not drop or duplicate levels.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      order : list of int representing new level order\n",
      " |          Reference level by number or key.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of caller (new object)\n",
      " |  \n",
      " |  repeat(self, repeats, axis=None) -> 'Series'\n",
      " |      Repeat elements of a Series.\n",
      " |      \n",
      " |      Returns a new Series where each element of the current Series\n",
      " |      is repeated consecutively a given number of times.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      repeats : int or array of ints\n",
      " |          The number of repetitions for each element. This should be a\n",
      " |          non-negative integer. Repeating 0 times will return an empty\n",
      " |          Series.\n",
      " |      axis : None\n",
      " |          Must be ``None``. Has no effect but is accepted for compatibility\n",
      " |          with numpy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Newly created Series with repeated elements.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.repeat : Equivalent function for Index.\n",
      " |      numpy.repeat : Similar method for :class:`numpy.ndarray`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(['a', 'b', 'c'])\n",
      " |      >>> s\n",
      " |      0    a\n",
      " |      1    b\n",
      " |      2    c\n",
      " |      dtype: object\n",
      " |      >>> s.repeat(2)\n",
      " |      0    a\n",
      " |      0    a\n",
      " |      1    b\n",
      " |      1    b\n",
      " |      2    c\n",
      " |      2    c\n",
      " |      dtype: object\n",
      " |      >>> s.repeat([1, 2, 3])\n",
      " |      0    a\n",
      " |      1    b\n",
      " |      1    b\n",
      " |      2    c\n",
      " |      2    c\n",
      " |      2    c\n",
      " |      dtype: object\n",
      " |  \n",
      " |  replace(self, to_replace=None, value=None, inplace=False, limit=None, regex=False, method='pad')\n",
      " |      Replace values given in `to_replace` with `value`.\n",
      " |      \n",
      " |      Values of the Series are replaced with other values dynamically.\n",
      " |      \n",
      " |      This differs from updating with ``.loc`` or ``.iloc``, which require\n",
      " |      you to specify a location to update with some value.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      to_replace : str, regex, list, dict, Series, int, float, or None\n",
      " |          How to find the values that will be replaced.\n",
      " |      \n",
      " |          * numeric, str or regex:\n",
      " |      \n",
      " |              - numeric: numeric values equal to `to_replace` will be\n",
      " |                  replaced with `value`\n",
      " |              - str: string exactly matching `to_replace` will be replaced\n",
      " |                  with `value`\n",
      " |              - regex: regexs matching `to_replace` will be replaced with\n",
      " |                  `value`\n",
      " |      \n",
      " |          * list of str, regex, or numeric:\n",
      " |      \n",
      " |              - First, if `to_replace` and `value` are both lists, they\n",
      " |                  **must** be the same length.\n",
      " |              - Second, if ``regex=True`` then all of the strings in **both**\n",
      " |                  lists will be interpreted as regexs otherwise they will match\n",
      " |                  directly. This doesn't matter much for `value` since there\n",
      " |                  are only a few possible substitution regexes you can use.\n",
      " |              - str, regex and numeric rules apply as above.\n",
      " |      \n",
      " |          * dict:\n",
      " |      \n",
      " |              - Dicts can be used to specify different replacement values\n",
      " |                  for different existing values. For example,\n",
      " |                  ``{'a': 'b', 'y': 'z'}`` replaces the value 'a' with 'b' and\n",
      " |                  'y' with 'z'. To use a dict in this way the `value`\n",
      " |                  parameter should be `None`.\n",
      " |              - For a DataFrame a dict can specify that different values\n",
      " |                  should be replaced in different columns. For example,\n",
      " |                  ``{'a': 1, 'b': 'z'}`` looks for the value 1 in column 'a'\n",
      " |                  and the value 'z' in column 'b' and replaces these values\n",
      " |                  with whatever is specified in `value`. The `value` parameter\n",
      " |                  should not be ``None`` in this case. You can treat this as a\n",
      " |                  special case of passing two lists except that you are\n",
      " |                  specifying the column to search in.\n",
      " |              - For a DataFrame nested dictionaries, e.g.,\n",
      " |                  ``{'a': {'b': np.nan}}``, are read as follows: look in column\n",
      " |                  'a' for the value 'b' and replace it with NaN. The `value`\n",
      " |                  parameter should be ``None`` to use a nested dict in this\n",
      " |                  way. You can nest regular expressions as well. Note that\n",
      " |                  column names (the top-level dictionary keys in a nested\n",
      " |                  dictionary) **cannot** be regular expressions.\n",
      " |      \n",
      " |          * None:\n",
      " |      \n",
      " |              - This means that the `regex` argument must be a string,\n",
      " |                  compiled regular expression, or list, dict, ndarray or\n",
      " |                  Series of such elements. If `value` is also ``None`` then\n",
      " |                  this **must** be a nested dictionary or Series.\n",
      " |      \n",
      " |          See the examples section for examples of each of these.\n",
      " |      value : scalar, dict, list, str, regex, default None\n",
      " |          Value to replace any values matching `to_replace` with.\n",
      " |          For a DataFrame a dict of values can be used to specify which\n",
      " |          value to use for each column (columns not in the dict will not be\n",
      " |          filled). Regular expressions, strings and lists or dicts of such\n",
      " |          objects are also allowed.\n",
      " |      inplace : bool, default False\n",
      " |          If True, performs operation inplace and returns None.\n",
      " |      limit : int, default None\n",
      " |          Maximum size gap to forward or backward fill.\n",
      " |      regex : bool or same types as `to_replace`, default False\n",
      " |          Whether to interpret `to_replace` and/or `value` as regular\n",
      " |          expressions. If this is ``True`` then `to_replace` *must* be a\n",
      " |          string. Alternatively, this could be a regular expression or a\n",
      " |          list, dict, or array of regular expressions in which case\n",
      " |          `to_replace` must be ``None``.\n",
      " |      method : {'pad', 'ffill', 'bfill', `None`}\n",
      " |          The method to use when for replacement, when `to_replace` is a\n",
      " |          scalar, list or tuple and `value` is ``None``.\n",
      " |      \n",
      " |          .. versionchanged:: 0.23.0\n",
      " |              Added to DataFrame.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Object after replacement.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      AssertionError\n",
      " |          * If `regex` is not a ``bool`` and `to_replace` is not\n",
      " |              ``None``.\n",
      " |      \n",
      " |      TypeError\n",
      " |          * If `to_replace` is not a scalar, array-like, ``dict``, or ``None``\n",
      " |          * If `to_replace` is a ``dict`` and `value` is not a ``list``,\n",
      " |              ``dict``, ``ndarray``, or ``Series``\n",
      " |          * If `to_replace` is ``None`` and `regex` is not compilable\n",
      " |              into a regular expression or is a list, dict, ndarray, or\n",
      " |              Series.\n",
      " |          * When replacing multiple ``bool`` or ``datetime64`` objects and\n",
      " |              the arguments to `to_replace` does not match the type of the\n",
      " |              value being replaced\n",
      " |      \n",
      " |      ValueError\n",
      " |          * If a ``list`` or an ``ndarray`` is passed to `to_replace` and\n",
      " |              `value` but they are not the same length.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.fillna : Fill NA values.\n",
      " |      Series.where : Replace values based on boolean condition.\n",
      " |      Series.str.replace : Simple string replacement.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      * Regex substitution is performed under the hood with ``re.sub``. The\n",
      " |          rules for substitution for ``re.sub`` are the same.\n",
      " |      * Regular expressions will only substitute on strings, meaning you\n",
      " |          cannot provide, for example, a regular expression matching floating\n",
      " |          point numbers and expect the columns in your frame that have a\n",
      " |          numeric dtype to be matched. However, if those floating point\n",
      " |          numbers *are* strings, then you can do this.\n",
      " |      * This method has *a lot* of options. You are encouraged to experiment\n",
      " |          and play with this method to gain intuition about how it works.\n",
      " |      * When dict is used as the `to_replace` value, it is like\n",
      " |          key(s) in the dict are the to_replace part and\n",
      " |          value(s) in the dict are the value parameter.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      **Scalar `to_replace` and `value`**\n",
      " |      \n",
      " |      >>> s = pd.Series([0, 1, 2, 3, 4])\n",
      " |      >>> s.replace(0, 5)\n",
      " |      0    5\n",
      " |      1    1\n",
      " |      2    2\n",
      " |      3    3\n",
      " |      4    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [0, 1, 2, 3, 4],\n",
      " |      ...                    'B': [5, 6, 7, 8, 9],\n",
      " |      ...                    'C': ['a', 'b', 'c', 'd', 'e']})\n",
      " |      >>> df.replace(0, 5)\n",
      " |          A  B  C\n",
      " |      0  5  5  a\n",
      " |      1  1  6  b\n",
      " |      2  2  7  c\n",
      " |      3  3  8  d\n",
      " |      4  4  9  e\n",
      " |      \n",
      " |      **List-like `to_replace`**\n",
      " |      \n",
      " |      >>> df.replace([0, 1, 2, 3], 4)\n",
      " |          A  B  C\n",
      " |      0  4  5  a\n",
      " |      1  4  6  b\n",
      " |      2  4  7  c\n",
      " |      3  4  8  d\n",
      " |      4  4  9  e\n",
      " |      \n",
      " |      >>> df.replace([0, 1, 2, 3], [4, 3, 2, 1])\n",
      " |          A  B  C\n",
      " |      0  4  5  a\n",
      " |      1  3  6  b\n",
      " |      2  2  7  c\n",
      " |      3  1  8  d\n",
      " |      4  4  9  e\n",
      " |      \n",
      " |      >>> s.replace([1, 2], method='bfill')\n",
      " |      0    0\n",
      " |      1    3\n",
      " |      2    3\n",
      " |      3    3\n",
      " |      4    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      **dict-like `to_replace`**\n",
      " |      \n",
      " |      >>> df.replace({0: 10, 1: 100})\n",
      " |              A  B  C\n",
      " |      0   10  5  a\n",
      " |      1  100  6  b\n",
      " |      2    2  7  c\n",
      " |      3    3  8  d\n",
      " |      4    4  9  e\n",
      " |      \n",
      " |      >>> df.replace({'A': 0, 'B': 5}, 100)\n",
      " |              A    B  C\n",
      " |      0  100  100  a\n",
      " |      1    1    6  b\n",
      " |      2    2    7  c\n",
      " |      3    3    8  d\n",
      " |      4    4    9  e\n",
      " |      \n",
      " |      >>> df.replace({'A': {0: 100, 4: 400}})\n",
      " |              A  B  C\n",
      " |      0  100  5  a\n",
      " |      1    1  6  b\n",
      " |      2    2  7  c\n",
      " |      3    3  8  d\n",
      " |      4  400  9  e\n",
      " |      \n",
      " |      **Regular expression `to_replace`**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': ['bat', 'foo', 'bait'],\n",
      " |      ...                    'B': ['abc', 'bar', 'xyz']})\n",
      " |      >>> df.replace(to_replace=r'^ba.$', value='new', regex=True)\n",
      " |              A    B\n",
      " |      0   new  abc\n",
      " |      1   foo  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace({'A': r'^ba.$'}, {'A': 'new'}, regex=True)\n",
      " |              A    B\n",
      " |      0   new  abc\n",
      " |      1   foo  bar\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace(regex=r'^ba.$', value='new')\n",
      " |              A    B\n",
      " |      0   new  abc\n",
      " |      1   foo  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace(regex={r'^ba.$': 'new', 'foo': 'xyz'})\n",
      " |              A    B\n",
      " |      0   new  abc\n",
      " |      1   xyz  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace(regex=[r'^ba.$', 'foo'], value='new')\n",
      " |              A    B\n",
      " |      0   new  abc\n",
      " |      1   new  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      Compare the behavior of ``s.replace({'a': None})`` and\n",
      " |      ``s.replace('a', None)`` to understand the peculiarities\n",
      " |      of the `to_replace` parameter:\n",
      " |      \n",
      " |      >>> s = pd.Series([10, 'a', 'a', 'b', 'a'])\n",
      " |      \n",
      " |      When one uses a dict as the `to_replace` value, it is like the\n",
      " |      value(s) in the dict are equal to the `value` parameter.\n",
      " |      ``s.replace({'a': None})`` is equivalent to\n",
      " |      ``s.replace(to_replace={'a': None}, value=None, method=None)``:\n",
      " |      \n",
      " |      >>> s.replace({'a': None})\n",
      " |      0      10\n",
      " |      1    None\n",
      " |      2    None\n",
      " |      3       b\n",
      " |      4    None\n",
      " |      dtype: object\n",
      " |      \n",
      " |      When ``value=None`` and `to_replace` is a scalar, list or\n",
      " |      tuple, `replace` uses the method parameter (default 'pad') to do the\n",
      " |      replacement. So this is why the 'a' values are being replaced by 10\n",
      " |      in rows 1 and 2 and 'b' in row 4 in this case.\n",
      " |      The command ``s.replace('a', None)`` is actually equivalent to\n",
      " |      ``s.replace(to_replace='a', value=None, method='pad')``:\n",
      " |      \n",
      " |      >>> s.replace('a', None)\n",
      " |      0    10\n",
      " |      1    10\n",
      " |      2    10\n",
      " |      3     b\n",
      " |      4     b\n",
      " |      dtype: object\n",
      " |  \n",
      " |  resample(self, rule, axis=0, closed: 'str | None' = None, label: 'str | None' = None, convention: 'str' = 'start', kind: 'str | None' = None, loffset=None, base: 'int | None' = None, on=None, level=None, origin: 'str | TimestampConvertibleTypes' = 'start_day', offset: 'TimedeltaConvertibleTypes | None' = None) -> 'Resampler'\n",
      " |      Resample time-series data.\n",
      " |      \n",
      " |      Convenience method for frequency conversion and resampling of time series.\n",
      " |      The object must have a datetime-like index (`DatetimeIndex`, `PeriodIndex`,\n",
      " |      or `TimedeltaIndex`), or the caller must pass the label of a datetime-like\n",
      " |      series/index to the ``on``/``level`` keyword parameter.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      rule : DateOffset, Timedelta or str\n",
      " |          The offset string or object representing target conversion.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Which axis to use for up- or down-sampling. For `Series` this\n",
      " |          will default to 0, i.e. along the rows. Must be\n",
      " |          `DatetimeIndex`, `TimedeltaIndex` or `PeriodIndex`.\n",
      " |      closed : {'right', 'left'}, default None\n",
      " |          Which side of bin interval is closed. The default is 'left'\n",
      " |          for all frequency offsets except for 'M', 'A', 'Q', 'BM',\n",
      " |          'BA', 'BQ', and 'W' which all have a default of 'right'.\n",
      " |      label : {'right', 'left'}, default None\n",
      " |          Which bin edge label to label bucket with. The default is 'left'\n",
      " |          for all frequency offsets except for 'M', 'A', 'Q', 'BM',\n",
      " |          'BA', 'BQ', and 'W' which all have a default of 'right'.\n",
      " |      convention : {'start', 'end', 's', 'e'}, default 'start'\n",
      " |          For `PeriodIndex` only, controls whether to use the start or\n",
      " |          end of `rule`.\n",
      " |      kind : {'timestamp', 'period'}, optional, default None\n",
      " |          Pass 'timestamp' to convert the resulting index to a\n",
      " |          `DateTimeIndex` or 'period' to convert it to a `PeriodIndex`.\n",
      " |          By default the input representation is retained.\n",
      " |      loffset : timedelta, default None\n",
      " |          Adjust the resampled time labels.\n",
      " |      \n",
      " |          .. deprecated:: 1.1.0\n",
      " |              You should add the loffset to the `df.index` after the resample.\n",
      " |              See below.\n",
      " |      \n",
      " |      base : int, default 0\n",
      " |          For frequencies that evenly subdivide 1 day, the \"origin\" of the\n",
      " |          aggregated intervals. For example, for '5min' frequency, base could\n",
      " |          range from 0 through 4. Defaults to 0.\n",
      " |      \n",
      " |          .. deprecated:: 1.1.0\n",
      " |              The new arguments that you should use are 'offset' or 'origin'.\n",
      " |      \n",
      " |      on : str, optional\n",
      " |          For a DataFrame, column to use instead of index for resampling.\n",
      " |          Column must be datetime-like.\n",
      " |      level : str or int, optional\n",
      " |          For a MultiIndex, level (name or number) to use for\n",
      " |          resampling. `level` must be datetime-like.\n",
      " |      origin : {'epoch', 'start', 'start_day', 'end', 'end_day'}, Timestamp\n",
      " |          or str, default 'start_day'\n",
      " |          The timestamp on which to adjust the grouping. The timezone of origin\n",
      " |          must match the timezone of the index.\n",
      " |          If a timestamp is not used, these values are also supported:\n",
      " |      \n",
      " |          - 'epoch': `origin` is 1970-01-01\n",
      " |          - 'start': `origin` is the first value of the timeseries\n",
      " |          - 'start_day': `origin` is the first day at midnight of the timeseries\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |          - 'end': `origin` is the last value of the timeseries\n",
      " |          - 'end_day': `origin` is the ceiling midnight of the last day\n",
      " |      \n",
      " |          .. versionadded:: 1.3.0\n",
      " |      \n",
      " |      offset : Timedelta or str, default is None\n",
      " |          An offset timedelta added to the origin.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.core.Resampler\n",
      " |          :class:`~pandas.core.Resampler` object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.resample : Resample a Series.\n",
      " |      DataFrame.resample : Resample a DataFrame.\n",
      " |      groupby : Group Series by mapping, function, label, or list of labels.\n",
      " |      asfreq : Reindex a Series with the given frequency without grouping.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the `user guide\n",
      " |      <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#resampling>`__\n",
      " |      for more.\n",
      " |      \n",
      " |      To learn more about the offset strings, please see `this link\n",
      " |      <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects>`__.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Start by creating a series with 9 one minute timestamps.\n",
      " |      \n",
      " |      >>> index = pd.date_range('1/1/2000', periods=9, freq='T')\n",
      " |      >>> series = pd.Series(range(9), index=index)\n",
      " |      >>> series\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      2000-01-01 00:03:00    3\n",
      " |      2000-01-01 00:04:00    4\n",
      " |      2000-01-01 00:05:00    5\n",
      " |      2000-01-01 00:06:00    6\n",
      " |      2000-01-01 00:07:00    7\n",
      " |      2000-01-01 00:08:00    8\n",
      " |      Freq: T, dtype: int64\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins and sum the values\n",
      " |      of the timestamps falling into a bin.\n",
      " |      \n",
      " |      >>> series.resample('3T').sum()\n",
      " |      2000-01-01 00:00:00     3\n",
      " |      2000-01-01 00:03:00    12\n",
      " |      2000-01-01 00:06:00    21\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins as above, but label each\n",
      " |      bin using the right edge instead of the left. Please note that the\n",
      " |      value in the bucket used as the label is not included in the bucket,\n",
      " |      which it labels. For example, in the original series the\n",
      " |      bucket ``2000-01-01 00:03:00`` contains the value 3, but the summed\n",
      " |      value in the resampled bucket with the label ``2000-01-01 00:03:00``\n",
      " |      does not include 3 (if it did, the summed value would be 6, not 3).\n",
      " |      To include this value close the right side of the bin interval as\n",
      " |      illustrated in the example below this one.\n",
      " |      \n",
      " |      >>> series.resample('3T', label='right').sum()\n",
      " |      2000-01-01 00:03:00     3\n",
      " |      2000-01-01 00:06:00    12\n",
      " |      2000-01-01 00:09:00    21\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins as above, but close the right\n",
      " |      side of the bin interval.\n",
      " |      \n",
      " |      >>> series.resample('3T', label='right', closed='right').sum()\n",
      " |      2000-01-01 00:00:00     0\n",
      " |      2000-01-01 00:03:00     6\n",
      " |      2000-01-01 00:06:00    15\n",
      " |      2000-01-01 00:09:00    15\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      Upsample the series into 30 second bins.\n",
      " |      \n",
      " |      >>> series.resample('30S').asfreq()[0:5]   # Select first 5 rows\n",
      " |      2000-01-01 00:00:00   0.0\n",
      " |      2000-01-01 00:00:30   NaN\n",
      " |      2000-01-01 00:01:00   1.0\n",
      " |      2000-01-01 00:01:30   NaN\n",
      " |      2000-01-01 00:02:00   2.0\n",
      " |      Freq: 30S, dtype: float64\n",
      " |      \n",
      " |      Upsample the series into 30 second bins and fill the ``NaN``\n",
      " |      values using the ``pad`` method.\n",
      " |      \n",
      " |      >>> series.resample('30S').pad()[0:5]\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:00:30    0\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:01:30    1\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      Freq: 30S, dtype: int64\n",
      " |      \n",
      " |      Upsample the series into 30 second bins and fill the\n",
      " |      ``NaN`` values using the ``bfill`` method.\n",
      " |      \n",
      " |      >>> series.resample('30S').bfill()[0:5]\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:00:30    1\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:01:30    2\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      Freq: 30S, dtype: int64\n",
      " |      \n",
      " |      Pass a custom function via ``apply``\n",
      " |      \n",
      " |      >>> def custom_resampler(arraylike):\n",
      " |      ...     return np.sum(arraylike) + 5\n",
      " |      ...\n",
      " |      >>> series.resample('3T').apply(custom_resampler)\n",
      " |      2000-01-01 00:00:00     8\n",
      " |      2000-01-01 00:03:00    17\n",
      " |      2000-01-01 00:06:00    26\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      For a Series with a PeriodIndex, the keyword `convention` can be\n",
      " |      used to control whether to use the start or end of `rule`.\n",
      " |      \n",
      " |      Resample a year by quarter using 'start' `convention`. Values are\n",
      " |      assigned to the first quarter of the period.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2], index=pd.period_range('2012-01-01',\n",
      " |      ...                                             freq='A',\n",
      " |      ...                                             periods=2))\n",
      " |      >>> s\n",
      " |      2012    1\n",
      " |      2013    2\n",
      " |      Freq: A-DEC, dtype: int64\n",
      " |      >>> s.resample('Q', convention='start').asfreq()\n",
      " |      2012Q1    1.0\n",
      " |      2012Q2    NaN\n",
      " |      2012Q3    NaN\n",
      " |      2012Q4    NaN\n",
      " |      2013Q1    2.0\n",
      " |      2013Q2    NaN\n",
      " |      2013Q3    NaN\n",
      " |      2013Q4    NaN\n",
      " |      Freq: Q-DEC, dtype: float64\n",
      " |      \n",
      " |      Resample quarters by month using 'end' `convention`. Values are\n",
      " |      assigned to the last month of the period.\n",
      " |      \n",
      " |      >>> q = pd.Series([1, 2, 3, 4], index=pd.period_range('2018-01-01',\n",
      " |      ...                                                   freq='Q',\n",
      " |      ...                                                   periods=4))\n",
      " |      >>> q\n",
      " |      2018Q1    1\n",
      " |      2018Q2    2\n",
      " |      2018Q3    3\n",
      " |      2018Q4    4\n",
      " |      Freq: Q-DEC, dtype: int64\n",
      " |      >>> q.resample('M', convention='end').asfreq()\n",
      " |      2018-03    1.0\n",
      " |      2018-04    NaN\n",
      " |      2018-05    NaN\n",
      " |      2018-06    2.0\n",
      " |      2018-07    NaN\n",
      " |      2018-08    NaN\n",
      " |      2018-09    3.0\n",
      " |      2018-10    NaN\n",
      " |      2018-11    NaN\n",
      " |      2018-12    4.0\n",
      " |      Freq: M, dtype: float64\n",
      " |      \n",
      " |      For DataFrame objects, the keyword `on` can be used to specify the\n",
      " |      column instead of the index for resampling.\n",
      " |      \n",
      " |      >>> d = {'price': [10, 11, 9, 13, 14, 18, 17, 19],\n",
      " |      ...      'volume': [50, 60, 40, 100, 50, 100, 40, 50]}\n",
      " |      >>> df = pd.DataFrame(d)\n",
      " |      >>> df['week_starting'] = pd.date_range('01/01/2018',\n",
      " |      ...                                     periods=8,\n",
      " |      ...                                     freq='W')\n",
      " |      >>> df\n",
      " |         price  volume week_starting\n",
      " |      0     10      50    2018-01-07\n",
      " |      1     11      60    2018-01-14\n",
      " |      2      9      40    2018-01-21\n",
      " |      3     13     100    2018-01-28\n",
      " |      4     14      50    2018-02-04\n",
      " |      5     18     100    2018-02-11\n",
      " |      6     17      40    2018-02-18\n",
      " |      7     19      50    2018-02-25\n",
      " |      >>> df.resample('M', on='week_starting').mean()\n",
      " |                     price  volume\n",
      " |      week_starting\n",
      " |      2018-01-31     10.75    62.5\n",
      " |      2018-02-28     17.00    60.0\n",
      " |      \n",
      " |      For a DataFrame with MultiIndex, the keyword `level` can be used to\n",
      " |      specify on which level the resampling needs to take place.\n",
      " |      \n",
      " |      >>> days = pd.date_range('1/1/2000', periods=4, freq='D')\n",
      " |      >>> d2 = {'price': [10, 11, 9, 13, 14, 18, 17, 19],\n",
      " |      ...       'volume': [50, 60, 40, 100, 50, 100, 40, 50]}\n",
      " |      >>> df2 = pd.DataFrame(\n",
      " |      ...     d2,\n",
      " |      ...     index=pd.MultiIndex.from_product(\n",
      " |      ...         [days, ['morning', 'afternoon']]\n",
      " |      ...     )\n",
      " |      ... )\n",
      " |      >>> df2\n",
      " |                            price  volume\n",
      " |      2000-01-01 morning       10      50\n",
      " |                 afternoon     11      60\n",
      " |      2000-01-02 morning        9      40\n",
      " |                 afternoon     13     100\n",
      " |      2000-01-03 morning       14      50\n",
      " |                 afternoon     18     100\n",
      " |      2000-01-04 morning       17      40\n",
      " |                 afternoon     19      50\n",
      " |      >>> df2.resample('D', level=0).sum()\n",
      " |                  price  volume\n",
      " |      2000-01-01     21     110\n",
      " |      2000-01-02     22     140\n",
      " |      2000-01-03     32     150\n",
      " |      2000-01-04     36      90\n",
      " |      \n",
      " |      If you want to adjust the start of the bins based on a fixed timestamp:\n",
      " |      \n",
      " |      >>> start, end = '2000-10-01 23:30:00', '2000-10-02 00:30:00'\n",
      " |      >>> rng = pd.date_range(start, end, freq='7min')\n",
      " |      >>> ts = pd.Series(np.arange(len(rng)) * 3, index=rng)\n",
      " |      >>> ts\n",
      " |      2000-10-01 23:30:00     0\n",
      " |      2000-10-01 23:37:00     3\n",
      " |      2000-10-01 23:44:00     6\n",
      " |      2000-10-01 23:51:00     9\n",
      " |      2000-10-01 23:58:00    12\n",
      " |      2000-10-02 00:05:00    15\n",
      " |      2000-10-02 00:12:00    18\n",
      " |      2000-10-02 00:19:00    21\n",
      " |      2000-10-02 00:26:00    24\n",
      " |      Freq: 7T, dtype: int64\n",
      " |      \n",
      " |      >>> ts.resample('17min').sum()\n",
      " |      2000-10-01 23:14:00     0\n",
      " |      2000-10-01 23:31:00     9\n",
      " |      2000-10-01 23:48:00    21\n",
      " |      2000-10-02 00:05:00    54\n",
      " |      2000-10-02 00:22:00    24\n",
      " |      Freq: 17T, dtype: int64\n",
      " |      \n",
      " |      >>> ts.resample('17min', origin='epoch').sum()\n",
      " |      2000-10-01 23:18:00     0\n",
      " |      2000-10-01 23:35:00    18\n",
      " |      2000-10-01 23:52:00    27\n",
      " |      2000-10-02 00:09:00    39\n",
      " |      2000-10-02 00:26:00    24\n",
      " |      Freq: 17T, dtype: int64\n",
      " |      \n",
      " |      >>> ts.resample('17min', origin='2000-01-01').sum()\n",
      " |      2000-10-01 23:24:00     3\n",
      " |      2000-10-01 23:41:00    15\n",
      " |      2000-10-01 23:58:00    45\n",
      " |      2000-10-02 00:15:00    45\n",
      " |      Freq: 17T, dtype: int64\n",
      " |      \n",
      " |      If you want to adjust the start of the bins with an `offset` Timedelta, the two\n",
      " |      following lines are equivalent:\n",
      " |      \n",
      " |      >>> ts.resample('17min', origin='start').sum()\n",
      " |      2000-10-01 23:30:00     9\n",
      " |      2000-10-01 23:47:00    21\n",
      " |      2000-10-02 00:04:00    54\n",
      " |      2000-10-02 00:21:00    24\n",
      " |      Freq: 17T, dtype: int64\n",
      " |      \n",
      " |      >>> ts.resample('17min', offset='23h30min').sum()\n",
      " |      2000-10-01 23:30:00     9\n",
      " |      2000-10-01 23:47:00    21\n",
      " |      2000-10-02 00:04:00    54\n",
      " |      2000-10-02 00:21:00    24\n",
      " |      Freq: 17T, dtype: int64\n",
      " |      \n",
      " |      If you want to take the largest Timestamp as the end of the bins:\n",
      " |      \n",
      " |      >>> ts.resample('17min', origin='end').sum()\n",
      " |      2000-10-01 23:35:00     0\n",
      " |      2000-10-01 23:52:00    18\n",
      " |      2000-10-02 00:09:00    27\n",
      " |      2000-10-02 00:26:00    63\n",
      " |      Freq: 17T, dtype: int64\n",
      " |      \n",
      " |      In contrast with the `start_day`, you can use `end_day` to take the ceiling\n",
      " |      midnight of the largest Timestamp as the end of the bins and drop the bins\n",
      " |      not containing data:\n",
      " |      \n",
      " |      >>> ts.resample('17min', origin='end_day').sum()\n",
      " |      2000-10-01 23:38:00     3\n",
      " |      2000-10-01 23:55:00    15\n",
      " |      2000-10-02 00:12:00    45\n",
      " |      2000-10-02 00:29:00    45\n",
      " |      Freq: 17T, dtype: int64\n",
      " |      \n",
      " |      To replace the use of the deprecated `base` argument, you can now use `offset`,\n",
      " |      in this example it is equivalent to have `base=2`:\n",
      " |      \n",
      " |      >>> ts.resample('17min', offset='2min').sum()\n",
      " |      2000-10-01 23:16:00     0\n",
      " |      2000-10-01 23:33:00     9\n",
      " |      2000-10-01 23:50:00    36\n",
      " |      2000-10-02 00:07:00    39\n",
      " |      2000-10-02 00:24:00    24\n",
      " |      Freq: 17T, dtype: int64\n",
      " |      \n",
      " |      To replace the use of the deprecated `loffset` argument:\n",
      " |      \n",
      " |      >>> from pandas.tseries.frequencies import to_offset\n",
      " |      >>> loffset = '19min'\n",
      " |      >>> ts_out = ts.resample('17min').sum()\n",
      " |      >>> ts_out.index = ts_out.index + to_offset(loffset)\n",
      " |      >>> ts_out\n",
      " |      2000-10-01 23:33:00     0\n",
      " |      2000-10-01 23:50:00     9\n",
      " |      2000-10-02 00:07:00    21\n",
      " |      2000-10-02 00:24:00    54\n",
      " |      2000-10-02 00:41:00    24\n",
      " |      Freq: 17T, dtype: int64\n",
      " |  \n",
      " |  reset_index(self, level=None, drop=False, name=None, inplace=False)\n",
      " |      Generate a new DataFrame or Series with the index reset.\n",
      " |      \n",
      " |      This is useful when the index needs to be treated as a column, or\n",
      " |      when the index is meaningless and needs to be reset to the default\n",
      " |      before another operation.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, str, tuple, or list, default optional\n",
      " |          For a Series with a MultiIndex, only remove the specified levels\n",
      " |          from the index. Removes all levels by default.\n",
      " |      drop : bool, default False\n",
      " |          Just reset the index, without inserting it as a column in\n",
      " |          the new DataFrame.\n",
      " |      name : object, optional\n",
      " |          The name to use for the column containing the original Series\n",
      " |          values. Uses ``self.name`` by default. This argument is ignored\n",
      " |          when `drop` is True.\n",
      " |      inplace : bool, default False\n",
      " |          Modify the Series in place (do not create a new object).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame or None\n",
      " |          When `drop` is False (the default), a DataFrame is returned.\n",
      " |          The newly created columns will come first in the DataFrame,\n",
      " |          followed by the original Series values.\n",
      " |          When `drop` is True, a `Series` is returned.\n",
      " |          In either case, if ``inplace=True``, no value is returned.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.reset_index: Analogous function for DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4], name='foo',\n",
      " |      ...               index=pd.Index(['a', 'b', 'c', 'd'], name='idx'))\n",
      " |      \n",
      " |      Generate a DataFrame with default index.\n",
      " |      \n",
      " |      >>> s.reset_index()\n",
      " |        idx  foo\n",
      " |      0   a    1\n",
      " |      1   b    2\n",
      " |      2   c    3\n",
      " |      3   d    4\n",
      " |      \n",
      " |      To specify the name of the new column use `name`.\n",
      " |      \n",
      " |      >>> s.reset_index(name='values')\n",
      " |        idx  values\n",
      " |      0   a       1\n",
      " |      1   b       2\n",
      " |      2   c       3\n",
      " |      3   d       4\n",
      " |      \n",
      " |      To generate a new Series with the default set `drop` to True.\n",
      " |      \n",
      " |      >>> s.reset_index(drop=True)\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      Name: foo, dtype: int64\n",
      " |      \n",
      " |      To update the Series in place, without generating a new one\n",
      " |      set `inplace` to True. Note that it also requires ``drop=True``.\n",
      " |      \n",
      " |      >>> s.reset_index(inplace=True, drop=True)\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      Name: foo, dtype: int64\n",
      " |      \n",
      " |      The `level` parameter is interesting for Series with a multi-level\n",
      " |      index.\n",
      " |      \n",
      " |      >>> arrays = [np.array(['bar', 'bar', 'baz', 'baz']),\n",
      " |      ...           np.array(['one', 'two', 'one', 'two'])]\n",
      " |      >>> s2 = pd.Series(\n",
      " |      ...     range(4), name='foo',\n",
      " |      ...     index=pd.MultiIndex.from_arrays(arrays,\n",
      " |      ...                                     names=['a', 'b']))\n",
      " |      \n",
      " |      To remove a specific level from the Index, use `level`.\n",
      " |      \n",
      " |      >>> s2.reset_index(level='a')\n",
      " |             a  foo\n",
      " |      b\n",
      " |      one  bar    0\n",
      " |      two  bar    1\n",
      " |      one  baz    2\n",
      " |      two  baz    3\n",
      " |      \n",
      " |      If `level` is not set, all levels are removed from the Index.\n",
      " |      \n",
      " |      >>> s2.reset_index()\n",
      " |           a    b  foo\n",
      " |      0  bar  one    0\n",
      " |      1  bar  two    1\n",
      " |      2  baz  one    2\n",
      " |      3  baz  two    3\n",
      " |  \n",
      " |  rfloordiv(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Return Integer division of series and other, element-wise (binary operator `rfloordiv`).\n",
      " |      \n",
      " |      Equivalent to ``other // series``, but with support to substitute a fill_value for\n",
      " |      missing data in either one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result of filling (at that location) will be missing.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.floordiv : Element-wise Integer division, see\n",
      " |          `Python documentation\n",
      " |          <https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types>`_\n",
      " |          for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.floordiv(b, fill_value=0)\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      c    NaN\n",
      " |      d    0.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  rmod(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Return Modulo of series and other, element-wise (binary operator `rmod`).\n",
      " |      \n",
      " |      Equivalent to ``other % series``, but with support to substitute a fill_value for\n",
      " |      missing data in either one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result of filling (at that location) will be missing.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.mod : Element-wise Modulo, see\n",
      " |          `Python documentation\n",
      " |          <https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types>`_\n",
      " |          for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.mod(b, fill_value=0)\n",
      " |      a    0.0\n",
      " |      b    NaN\n",
      " |      c    NaN\n",
      " |      d    0.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  rmul(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Return Multiplication of series and other, element-wise (binary operator `rmul`).\n",
      " |      \n",
      " |      Equivalent to ``other * series``, but with support to substitute a fill_value for\n",
      " |      missing data in either one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result of filling (at that location) will be missing.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.mul : Element-wise Multiplication, see\n",
      " |          `Python documentation\n",
      " |          <https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types>`_\n",
      " |          for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.multiply(b, fill_value=0)\n",
      " |      a    1.0\n",
      " |      b    0.0\n",
      " |      c    0.0\n",
      " |      d    0.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  round(self, decimals=0, *args, **kwargs) -> 'Series'\n",
      " |      Round each value in a Series to the given number of decimals.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      decimals : int, default 0\n",
      " |          Number of decimal places to round to. If decimals is negative,\n",
      " |          it specifies the number of positions to the left of the decimal point.\n",
      " |      *args, **kwargs\n",
      " |          Additional arguments and keywords have no effect but might be\n",
      " |          accepted for compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Rounded values of the Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.around : Round values of an np.array.\n",
      " |      DataFrame.round : Round values of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([0.1, 1.3, 2.7])\n",
      " |      >>> s.round()\n",
      " |      0    0.0\n",
      " |      1    1.0\n",
      " |      2    3.0\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  rpow(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Return Exponential power of series and other, element-wise (binary operator `rpow`).\n",
      " |      \n",
      " |      Equivalent to ``other ** series``, but with support to substitute a fill_value for\n",
      " |      missing data in either one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result of filling (at that location) will be missing.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.pow : Element-wise Exponential power, see\n",
      " |          `Python documentation\n",
      " |          <https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types>`_\n",
      " |          for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.pow(b, fill_value=0)\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    0.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  rsub(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Return Subtraction of series and other, element-wise (binary operator `rsub`).\n",
      " |      \n",
      " |      Equivalent to ``other - series``, but with support to substitute a fill_value for\n",
      " |      missing data in either one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result of filling (at that location) will be missing.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sub : Element-wise Subtraction, see\n",
      " |          `Python documentation\n",
      " |          <https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types>`_\n",
      " |          for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.subtract(b, fill_value=0)\n",
      " |      a    0.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d   -1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  rtruediv(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Return Floating division of series and other, element-wise (binary operator `rtruediv`).\n",
      " |      \n",
      " |      Equivalent to ``other / series``, but with support to substitute a fill_value for\n",
      " |      missing data in either one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result of filling (at that location) will be missing.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.truediv : Element-wise Floating division, see\n",
      " |          `Python documentation\n",
      " |          <https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types>`_\n",
      " |          for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.divide(b, fill_value=0)\n",
      " |      a    1.0\n",
      " |      b    inf\n",
      " |      c    inf\n",
      " |      d    0.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  searchsorted(self, value, side='left', sorter=None) -> 'np.ndarray'\n",
      " |      Find indices where elements should be inserted to maintain order.\n",
      " |      \n",
      " |      Find the indices into a sorted Series `self` such that, if the\n",
      " |      corresponding elements in `value` were inserted before the indices,\n",
      " |      the order of `self` would be preserved.\n",
      " |      \n",
      " |      .. note::\n",
      " |      \n",
      " |          The Series *must* be monotonically sorted, otherwise\n",
      " |          wrong locations will likely be returned. Pandas does *not*\n",
      " |          check this for you.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      value : array-like\n",
      " |          Values to insert into `self`.\n",
      " |      side : {'left', 'right'}, optional\n",
      " |          If 'left', the index of the first suitable location found is given.\n",
      " |          If 'right', return the last such index.  If there is no suitable\n",
      " |          index, return either 0 or N (where N is the length of `self`).\n",
      " |      sorter : 1-D array-like, optional\n",
      " |          Optional array of integer indices that sort `self` into ascending\n",
      " |          order. They are typically the result of ``np.argsort``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      int or array of int\n",
      " |          A scalar or array of insertion points with the\n",
      " |          same shape as `value`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      sort_values : Sort by the values along either axis.\n",
      " |      numpy.searchsorted : Similar method from NumPy.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Binary search is used to find the required insertion points.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> ser = pd.Series([1, 2, 3])\n",
      " |      >>> ser\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> ser.searchsorted(4)\n",
      " |      3\n",
      " |      \n",
      " |      >>> ser.searchsorted([0, 4])\n",
      " |      array([0, 3])\n",
      " |      \n",
      " |      >>> ser.searchsorted([1, 3], side='left')\n",
      " |      array([0, 2])\n",
      " |      \n",
      " |      >>> ser.searchsorted([1, 3], side='right')\n",
      " |      array([1, 3])\n",
      " |      \n",
      " |      >>> ser = pd.Series(pd.to_datetime(['3/11/2000', '3/12/2000', '3/13/2000']))\n",
      " |      >>> ser\n",
      " |      0   2000-03-11\n",
      " |      1   2000-03-12\n",
      " |      2   2000-03-13\n",
      " |      dtype: datetime64[ns]\n",
      " |      \n",
      " |      >>> ser.searchsorted('3/14/2000')\n",
      " |      3\n",
      " |      \n",
      " |      >>> ser = pd.Categorical(\n",
      " |      ...     ['apple', 'bread', 'bread', 'cheese', 'milk'], ordered=True\n",
      " |      ... )\n",
      " |      >>> ser\n",
      " |      ['apple', 'bread', 'bread', 'cheese', 'milk']\n",
      " |      Categories (4, object): ['apple' < 'bread' < 'cheese' < 'milk']\n",
      " |      \n",
      " |      >>> ser.searchsorted('bread')\n",
      " |      1\n",
      " |      \n",
      " |      >>> ser.searchsorted(['bread'], side='right')\n",
      " |      array([3])\n",
      " |      \n",
      " |      If the values are not monotonically sorted, wrong locations\n",
      " |      may be returned:\n",
      " |      \n",
      " |      >>> ser = pd.Series([2, 1, 3])\n",
      " |      >>> ser\n",
      " |      0    2\n",
      " |      1    1\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> ser.searchsorted(1)  # doctest: +SKIP\n",
      " |      0  # wrong result, correct would be 1\n",
      " |  \n",
      " |  sem(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      " |      Return unbiased standard error of the mean over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar.\n",
      " |      ddof : int, default 1\n",
      " |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\n",
      " |          where N represents the number of elements.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series (if level specified)\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      To have the same behaviour as `numpy.std`, use `ddof=0` (instead of the\n",
      " |      default `ddof=1`)\n",
      " |  \n",
      " |  set_axis(self, labels, axis: 'Axis' = 0, inplace: 'bool' = False)\n",
      " |      Assign desired index to given axis.\n",
      " |      \n",
      " |      Indexes for row labels can be changed by assigning\n",
      " |      a list-like or Index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      labels : list-like, Index\n",
      " |          The values for the new index.\n",
      " |      \n",
      " |      axis : {0 or 'index'}, default 0\n",
      " |          The axis to update. The value 0 identifies the rows.\n",
      " |      \n",
      " |      inplace : bool, default False\n",
      " |          Whether to return a new Series instance.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      renamed : Series or None\n",
      " |          An object of type Series or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.rename_axis : Alter the name of the index.\n",
      " |      \n",
      " |              Examples\n",
      " |              --------\n",
      " |              >>> s = pd.Series([1, 2, 3])\n",
      " |              >>> s\n",
      " |              0    1\n",
      " |              1    2\n",
      " |              2    3\n",
      " |              dtype: int64\n",
      " |      \n",
      " |              >>> s.set_axis(['a', 'b', 'c'], axis=0)\n",
      " |              a    1\n",
      " |              b    2\n",
      " |              c    3\n",
      " |              dtype: int64\n",
      " |  \n",
      " |  shift(self, periods=1, freq=None, axis=0, fill_value=None) -> 'Series'\n",
      " |      Shift index by desired number of periods with an optional time `freq`.\n",
      " |      \n",
      " |      When `freq` is not passed, shift the index without realigning the data.\n",
      " |      If `freq` is passed (in this case, the index must be date or datetime,\n",
      " |      or it will raise a `NotImplementedError`), the index will be\n",
      " |      increased using the periods and the `freq`. `freq` can be inferred\n",
      " |      when specified as \"infer\" as long as either freq or inferred_freq\n",
      " |      attribute is set in the index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to shift. Can be positive or negative.\n",
      " |      freq : DateOffset, tseries.offsets, timedelta, or str, optional\n",
      " |          Offset to use from the tseries module or time rule (e.g. 'EOM').\n",
      " |          If `freq` is specified then the index values are shifted but the\n",
      " |          data is not realigned. That is, use `freq` if you would like to\n",
      " |          extend the index when shifting and preserve the original data.\n",
      " |          If `freq` is specified as \"infer\" then it will be inferred from\n",
      " |          the freq or inferred_freq attributes of the index. If neither of\n",
      " |          those attributes exist, a ValueError is thrown.\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default None\n",
      " |          Shift direction.\n",
      " |      fill_value : object, optional\n",
      " |          The scalar value to use for newly introduced missing values.\n",
      " |          the default depends on the dtype of `self`.\n",
      " |          For numeric data, ``np.nan`` is used.\n",
      " |          For datetime, timedelta, or period data, etc. :attr:`NaT` is used.\n",
      " |          For extension dtypes, ``self.dtype.na_value`` is used.\n",
      " |      \n",
      " |          .. versionchanged:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Copy of input object, shifted.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.shift : Shift values of Index.\n",
      " |      DatetimeIndex.shift : Shift values of DatetimeIndex.\n",
      " |      PeriodIndex.shift : Shift values of PeriodIndex.\n",
      " |      tshift : Shift the time index, using the index's frequency if\n",
      " |          available.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"Col1\": [10, 20, 15, 30, 45],\n",
      " |      ...                    \"Col2\": [13, 23, 18, 33, 48],\n",
      " |      ...                    \"Col3\": [17, 27, 22, 37, 52]},\n",
      " |      ...                   index=pd.date_range(\"2020-01-01\", \"2020-01-05\"))\n",
      " |      >>> df\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-01    10    13    17\n",
      " |      2020-01-02    20    23    27\n",
      " |      2020-01-03    15    18    22\n",
      " |      2020-01-04    30    33    37\n",
      " |      2020-01-05    45    48    52\n",
      " |      \n",
      " |      >>> df.shift(periods=3)\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-01   NaN   NaN   NaN\n",
      " |      2020-01-02   NaN   NaN   NaN\n",
      " |      2020-01-03   NaN   NaN   NaN\n",
      " |      2020-01-04  10.0  13.0  17.0\n",
      " |      2020-01-05  20.0  23.0  27.0\n",
      " |      \n",
      " |      >>> df.shift(periods=1, axis=\"columns\")\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-01   NaN    10    13\n",
      " |      2020-01-02   NaN    20    23\n",
      " |      2020-01-03   NaN    15    18\n",
      " |      2020-01-04   NaN    30    33\n",
      " |      2020-01-05   NaN    45    48\n",
      " |      \n",
      " |      >>> df.shift(periods=3, fill_value=0)\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-01     0     0     0\n",
      " |      2020-01-02     0     0     0\n",
      " |      2020-01-03     0     0     0\n",
      " |      2020-01-04    10    13    17\n",
      " |      2020-01-05    20    23    27\n",
      " |      \n",
      " |      >>> df.shift(periods=3, freq=\"D\")\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-04    10    13    17\n",
      " |      2020-01-05    20    23    27\n",
      " |      2020-01-06    15    18    22\n",
      " |      2020-01-07    30    33    37\n",
      " |      2020-01-08    45    48    52\n",
      " |      \n",
      " |      >>> df.shift(periods=3, freq=\"infer\")\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-04    10    13    17\n",
      " |      2020-01-05    20    23    27\n",
      " |      2020-01-06    15    18    22\n",
      " |      2020-01-07    30    33    37\n",
      " |      2020-01-08    45    48    52\n",
      " |  \n",
      " |  skew(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return unbiased skew over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series (if level specified)\n",
      " |  \n",
      " |  sort_index(self, axis=0, level=None, ascending: 'bool | int | Sequence[bool | int]' = True, inplace: 'bool' = False, kind: 'str' = 'quicksort', na_position: 'str' = 'last', sort_remaining: 'bool' = True, ignore_index: 'bool' = False, key: 'IndexKeyFunc' = None)\n",
      " |      Sort Series by index labels.\n",
      " |      \n",
      " |      Returns a new Series sorted by label if `inplace` argument is\n",
      " |      ``False``, otherwise updates the original series and returns None.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : int, default 0\n",
      " |          Axis to direct sorting. This can only be 0 for Series.\n",
      " |      level : int, optional\n",
      " |          If not None, sort on values in specified index level(s).\n",
      " |      ascending : bool or list-like of bools, default True\n",
      " |          Sort ascending vs. descending. When the index is a MultiIndex the\n",
      " |          sort direction can be controlled for each level individually.\n",
      " |      inplace : bool, default False\n",
      " |          If True, perform operation in-place.\n",
      " |      kind : {'quicksort', 'mergesort', 'heapsort', 'stable'}, default 'quicksort'\n",
      " |          Choice of sorting algorithm. See also :func:`numpy.sort` for more\n",
      " |          information. 'mergesort' and 'stable' are the only stable algorithms. For\n",
      " |          DataFrames, this option is only applied when sorting on a single\n",
      " |          column or label.\n",
      " |      na_position : {'first', 'last'}, default 'last'\n",
      " |          If 'first' puts NaNs at the beginning, 'last' puts NaNs at the end.\n",
      " |          Not implemented for MultiIndex.\n",
      " |      sort_remaining : bool, default True\n",
      " |          If True and sorting by level and index is multilevel, sort by other\n",
      " |          levels too (in order) after sorting by specified level.\n",
      " |      ignore_index : bool, default False\n",
      " |          If True, the resulting axis will be labeled 0, 1, …, n - 1.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      key : callable, optional\n",
      " |          If not None, apply the key function to the index values\n",
      " |          before sorting. This is similar to the `key` argument in the\n",
      " |          builtin :meth:`sorted` function, with the notable difference that\n",
      " |          this `key` function should be *vectorized*. It should expect an\n",
      " |          ``Index`` and return an ``Index`` of the same shape.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or None\n",
      " |          The original Series sorted by the labels or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.sort_index: Sort DataFrame by the index.\n",
      " |      DataFrame.sort_values: Sort DataFrame by the value.\n",
      " |      Series.sort_values : Sort Series by the value.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(['a', 'b', 'c', 'd'], index=[3, 2, 1, 4])\n",
      " |      >>> s.sort_index()\n",
      " |      1    c\n",
      " |      2    b\n",
      " |      3    a\n",
      " |      4    d\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Sort Descending\n",
      " |      \n",
      " |      >>> s.sort_index(ascending=False)\n",
      " |      4    d\n",
      " |      3    a\n",
      " |      2    b\n",
      " |      1    c\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Sort Inplace\n",
      " |      \n",
      " |      >>> s.sort_index(inplace=True)\n",
      " |      >>> s\n",
      " |      1    c\n",
      " |      2    b\n",
      " |      3    a\n",
      " |      4    d\n",
      " |      dtype: object\n",
      " |      \n",
      " |      By default NaNs are put at the end, but use `na_position` to place\n",
      " |      them at the beginning\n",
      " |      \n",
      " |      >>> s = pd.Series(['a', 'b', 'c', 'd'], index=[3, 2, 1, np.nan])\n",
      " |      >>> s.sort_index(na_position='first')\n",
      " |      NaN     d\n",
      " |       1.0    c\n",
      " |       2.0    b\n",
      " |       3.0    a\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Specify index level to sort\n",
      " |      \n",
      " |      >>> arrays = [np.array(['qux', 'qux', 'foo', 'foo',\n",
      " |      ...                     'baz', 'baz', 'bar', 'bar']),\n",
      " |      ...           np.array(['two', 'one', 'two', 'one',\n",
      " |      ...                     'two', 'one', 'two', 'one'])]\n",
      " |      >>> s = pd.Series([1, 2, 3, 4, 5, 6, 7, 8], index=arrays)\n",
      " |      >>> s.sort_index(level=1)\n",
      " |      bar  one    8\n",
      " |      baz  one    6\n",
      " |      foo  one    4\n",
      " |      qux  one    2\n",
      " |      bar  two    7\n",
      " |      baz  two    5\n",
      " |      foo  two    3\n",
      " |      qux  two    1\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Does not sort by remaining levels when sorting by levels\n",
      " |      \n",
      " |      >>> s.sort_index(level=1, sort_remaining=False)\n",
      " |      qux  one    2\n",
      " |      foo  one    4\n",
      " |      baz  one    6\n",
      " |      bar  one    8\n",
      " |      qux  two    1\n",
      " |      foo  two    3\n",
      " |      baz  two    5\n",
      " |      bar  two    7\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Apply a key function before sorting\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3, 4], index=['A', 'b', 'C', 'd'])\n",
      " |      >>> s.sort_index(key=lambda x : x.str.lower())\n",
      " |      A    1\n",
      " |      b    2\n",
      " |      C    3\n",
      " |      d    4\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  sort_values(self, axis=0, ascending: 'bool | int | Sequence[bool | int]' = True, inplace: 'bool' = False, kind: 'str' = 'quicksort', na_position: 'str' = 'last', ignore_index: 'bool' = False, key: 'ValueKeyFunc' = None)\n",
      " |      Sort by the values.\n",
      " |      \n",
      " |      Sort a Series in ascending or descending order by some\n",
      " |      criterion.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index'}, default 0\n",
      " |          Axis to direct sorting. The value 'index' is accepted for\n",
      " |          compatibility with DataFrame.sort_values.\n",
      " |      ascending : bool or list of bools, default True\n",
      " |          If True, sort values in ascending order, otherwise descending.\n",
      " |      inplace : bool, default False\n",
      " |          If True, perform operation in-place.\n",
      " |      kind : {'quicksort', 'mergesort', 'heapsort', 'stable'}, default 'quicksort'\n",
      " |          Choice of sorting algorithm. See also :func:`numpy.sort` for more\n",
      " |          information. 'mergesort' and 'stable' are the only stable  algorithms.\n",
      " |      na_position : {'first' or 'last'}, default 'last'\n",
      " |          Argument 'first' puts NaNs at the beginning, 'last' puts NaNs at\n",
      " |          the end.\n",
      " |      ignore_index : bool, default False\n",
      " |          If True, the resulting axis will be labeled 0, 1, …, n - 1.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      key : callable, optional\n",
      " |          If not None, apply the key function to the series values\n",
      " |          before sorting. This is similar to the `key` argument in the\n",
      " |          builtin :meth:`sorted` function, with the notable difference that\n",
      " |          this `key` function should be *vectorized*. It should expect a\n",
      " |          ``Series`` and return an array-like.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or None\n",
      " |          Series ordered by values or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sort_index : Sort by the Series indices.\n",
      " |      DataFrame.sort_values : Sort DataFrame by the values along either axis.\n",
      " |      DataFrame.sort_index : Sort DataFrame by indices.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([np.nan, 1, 3, 10, 5])\n",
      " |      >>> s\n",
      " |      0     NaN\n",
      " |      1     1.0\n",
      " |      2     3.0\n",
      " |      3     10.0\n",
      " |      4     5.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Sort values ascending order (default behaviour)\n",
      " |      \n",
      " |      >>> s.sort_values(ascending=True)\n",
      " |      1     1.0\n",
      " |      2     3.0\n",
      " |      4     5.0\n",
      " |      3    10.0\n",
      " |      0     NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Sort values descending order\n",
      " |      \n",
      " |      >>> s.sort_values(ascending=False)\n",
      " |      3    10.0\n",
      " |      4     5.0\n",
      " |      2     3.0\n",
      " |      1     1.0\n",
      " |      0     NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Sort values inplace\n",
      " |      \n",
      " |      >>> s.sort_values(ascending=False, inplace=True)\n",
      " |      >>> s\n",
      " |      3    10.0\n",
      " |      4     5.0\n",
      " |      2     3.0\n",
      " |      1     1.0\n",
      " |      0     NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Sort values putting NAs first\n",
      " |      \n",
      " |      >>> s.sort_values(na_position='first')\n",
      " |      0     NaN\n",
      " |      1     1.0\n",
      " |      2     3.0\n",
      " |      4     5.0\n",
      " |      3    10.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Sort a series of strings\n",
      " |      \n",
      " |      >>> s = pd.Series(['z', 'b', 'd', 'a', 'c'])\n",
      " |      >>> s\n",
      " |      0    z\n",
      " |      1    b\n",
      " |      2    d\n",
      " |      3    a\n",
      " |      4    c\n",
      " |      dtype: object\n",
      " |      \n",
      " |      >>> s.sort_values()\n",
      " |      3    a\n",
      " |      1    b\n",
      " |      4    c\n",
      " |      2    d\n",
      " |      0    z\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Sort using a key function. Your `key` function will be\n",
      " |      given the ``Series`` of values and should return an array-like.\n",
      " |      \n",
      " |      >>> s = pd.Series(['a', 'B', 'c', 'D', 'e'])\n",
      " |      >>> s.sort_values()\n",
      " |      1    B\n",
      " |      3    D\n",
      " |      0    a\n",
      " |      2    c\n",
      " |      4    e\n",
      " |      dtype: object\n",
      " |      >>> s.sort_values(key=lambda x: x.str.lower())\n",
      " |      0    a\n",
      " |      1    B\n",
      " |      2    c\n",
      " |      3    D\n",
      " |      4    e\n",
      " |      dtype: object\n",
      " |      \n",
      " |      NumPy ufuncs work well here. For example, we can\n",
      " |      sort by the ``sin`` of the value\n",
      " |      \n",
      " |      >>> s = pd.Series([-4, -2, 0, 2, 4])\n",
      " |      >>> s.sort_values(key=np.sin)\n",
      " |      1   -2\n",
      " |      4    4\n",
      " |      2    0\n",
      " |      0   -4\n",
      " |      3    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      More complicated user-defined functions can be used,\n",
      " |      as long as they expect a Series and return an array-like\n",
      " |      \n",
      " |      >>> s.sort_values(key=lambda x: (np.tan(x.cumsum())))\n",
      " |      0   -4\n",
      " |      3    2\n",
      " |      4    4\n",
      " |      1   -2\n",
      " |      2    0\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  std(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      " |      Return sample standard deviation over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar.\n",
      " |      ddof : int, default 1\n",
      " |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\n",
      " |          where N represents the number of elements.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series (if level specified)\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      To have the same behaviour as `numpy.std`, use `ddof=0` (instead of the\n",
      " |      default `ddof=1`)\n",
      " |  \n",
      " |  sub(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Return Subtraction of series and other, element-wise (binary operator `sub`).\n",
      " |      \n",
      " |      Equivalent to ``series - other``, but with support to substitute a fill_value for\n",
      " |      missing data in either one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result of filling (at that location) will be missing.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.rsub : Reverse of the Subtraction operator, see\n",
      " |          `Python documentation\n",
      " |          <https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types>`_\n",
      " |          for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.subtract(b, fill_value=0)\n",
      " |      a    0.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d   -1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  subtract = sub(self, other, level=None, fill_value=None, axis=0)\n",
      " |  \n",
      " |  sum(self, axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)\n",
      " |      Return the sum of the values over the requested axis.\n",
      " |      \n",
      " |      This is equivalent to the method ``numpy.sum``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      min_count : int, default 0\n",
      " |          The required number of valid values to perform the operation. If fewer than\n",
      " |          ``min_count`` non-NA values are present the result will be NA.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series (if level specified)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sum : Return the sum.\n",
      " |      Series.min : Return the minimum.\n",
      " |      Series.max : Return the maximum.\n",
      " |      Series.idxmin : Return the index of the minimum.\n",
      " |      Series.idxmax : Return the index of the maximum.\n",
      " |      DataFrame.sum : Return the sum over the requested axis.\n",
      " |      DataFrame.min : Return the minimum over the requested axis.\n",
      " |      DataFrame.max : Return the maximum over the requested axis.\n",
      " |      DataFrame.idxmin : Return the index of the minimum over the requested axis.\n",
      " |      DataFrame.idxmax : Return the index of the maximum over the requested axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.MultiIndex.from_arrays([\n",
      " |      ...     ['warm', 'warm', 'cold', 'cold'],\n",
      " |      ...     ['dog', 'falcon', 'fish', 'spider']],\n",
      " |      ...     names=['blooded', 'animal'])\n",
      " |      >>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n",
      " |      >>> s\n",
      " |      blooded  animal\n",
      " |      warm     dog       4\n",
      " |               falcon    2\n",
      " |      cold     fish      0\n",
      " |               spider    8\n",
      " |      Name: legs, dtype: int64\n",
      " |      \n",
      " |      >>> s.sum()\n",
      " |      14\n",
      " |      \n",
      " |      By default, the sum of an empty or all-NA Series is ``0``.\n",
      " |      \n",
      " |      >>> pd.Series([], dtype=\"float64\").sum()  # min_count=0 is the default\n",
      " |      0.0\n",
      " |      \n",
      " |      This can be controlled with the ``min_count`` parameter. For example, if\n",
      " |      you'd like the sum of an empty series to be NaN, pass ``min_count=1``.\n",
      " |      \n",
      " |      >>> pd.Series([], dtype=\"float64\").sum(min_count=1)\n",
      " |      nan\n",
      " |      \n",
      " |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
      " |      empty series identically.\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).sum()\n",
      " |      0.0\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).sum(min_count=1)\n",
      " |      nan\n",
      " |  \n",
      " |  swaplevel(self, i=-2, j=-1, copy=True) -> 'Series'\n",
      " |      Swap levels i and j in a :class:`MultiIndex`.\n",
      " |      \n",
      " |      Default is to swap the two innermost levels of the index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      i, j : int or str\n",
      " |          Levels of the indices to be swapped. Can pass level name as string.\n",
      " |      copy : bool, default True\n",
      " |                  Whether to copy underlying data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Series with levels swapped in MultiIndex.\n",
      " |      \n",
      " |      Examples\n",
      " |              --------\n",
      " |              >>> s = pd.Series(\n",
      " |              ...     [\"A\", \"B\", \"A\", \"C\"],\n",
      " |              ...     index=[\n",
      " |              ...         [\"Final exam\", \"Final exam\", \"Coursework\", \"Coursework\"],\n",
      " |              ...         [\"History\", \"Geography\", \"History\", \"Geography\"],\n",
      " |              ...         [\"January\", \"February\", \"March\", \"April\"],\n",
      " |              ...     ],\n",
      " |              ... )\n",
      " |              >>> s\n",
      " |              Final exam  History     January      A\n",
      " |                          Geography   February     B\n",
      " |              Coursework  History     March        A\n",
      " |                          Geography   April        C\n",
      " |              dtype: object\n",
      " |      \n",
      " |              In the following example, we will swap the levels of the indices.\n",
      " |              Here, we will swap the levels column-wise, but levels can be swapped row-wise\n",
      " |              in a similar manner. Note that column-wise is the default behaviour.\n",
      " |              By not supplying any arguments for i and j, we swap the last and second to\n",
      " |              last indices.\n",
      " |      \n",
      " |              >>> s.swaplevel()\n",
      " |              Final exam  January     History         A\n",
      " |                          February    Geography       B\n",
      " |              Coursework  March       History         A\n",
      " |                          April       Geography       C\n",
      " |              dtype: object\n",
      " |      \n",
      " |              By supplying one argument, we can choose which index to swap the last\n",
      " |              index with. We can for example swap the first index with the last one as\n",
      " |              follows.\n",
      " |      \n",
      " |              >>> s.swaplevel(0)\n",
      " |              January     History     Final exam      A\n",
      " |              February    Geography   Final exam      B\n",
      " |              March       History     Coursework      A\n",
      " |              April       Geography   Coursework      C\n",
      " |              dtype: object\n",
      " |      \n",
      " |              We can also define explicitly which indices we want to swap by supplying values\n",
      " |              for both i and j. Here, we for example swap the first and second indices.\n",
      " |      \n",
      " |              >>> s.swaplevel(0, 1)\n",
      " |              History     Final exam  January         A\n",
      " |              Geography   Final exam  February        B\n",
      " |              History     Coursework  March           A\n",
      " |              Geography   Coursework  April           C\n",
      " |              dtype: object\n",
      " |  \n",
      " |  take(self, indices, axis=0, is_copy=None, **kwargs) -> 'Series'\n",
      " |      Return the elements in the given *positional* indices along an axis.\n",
      " |      \n",
      " |      This means that we are not indexing according to actual values in\n",
      " |      the index attribute of the object. We are indexing according to the\n",
      " |      actual position of the element in the object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      indices : array-like\n",
      " |          An array of ints indicating which positions to take.\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          The axis on which to select elements. ``0`` means that we are\n",
      " |          selecting rows, ``1`` means that we are selecting columns.\n",
      " |      is_copy : bool\n",
      " |          Before pandas 1.0, ``is_copy=False`` can be specified to ensure\n",
      " |          that the return value is an actual copy. Starting with pandas 1.0,\n",
      " |          ``take`` always returns a copy, and the keyword is therefore\n",
      " |          deprecated.\n",
      " |      \n",
      " |          .. deprecated:: 1.0.0\n",
      " |      **kwargs\n",
      " |          For compatibility with :meth:`numpy.take`. Has no effect on the\n",
      " |          output.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      taken : same type as caller\n",
      " |          An array-like containing the elements taken from the object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Select a subset of a DataFrame by labels.\n",
      " |      DataFrame.iloc : Select a subset of a DataFrame by positions.\n",
      " |      numpy.take : Take elements from an array along an axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('falcon', 'bird', 389.0),\n",
      " |      ...                    ('parrot', 'bird', 24.0),\n",
      " |      ...                    ('lion', 'mammal', 80.5),\n",
      " |      ...                    ('monkey', 'mammal', np.nan)],\n",
      " |      ...                   columns=['name', 'class', 'max_speed'],\n",
      " |      ...                   index=[0, 2, 3, 1])\n",
      " |      >>> df\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      2  parrot    bird       24.0\n",
      " |      3    lion  mammal       80.5\n",
      " |      1  monkey  mammal        NaN\n",
      " |      \n",
      " |      Take elements at positions 0 and 3 along the axis 0 (default).\n",
      " |      \n",
      " |      Note how the actual indices selected (0 and 1) do not correspond to\n",
      " |      our selected indices 0 and 3. That's because we are selecting the 0th\n",
      " |      and 3rd rows, not rows whose indices equal 0 and 3.\n",
      " |      \n",
      " |      >>> df.take([0, 3])\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      1  monkey  mammal        NaN\n",
      " |      \n",
      " |      Take elements at indices 1 and 2 along the axis 1 (column selection).\n",
      " |      \n",
      " |      >>> df.take([1, 2], axis=1)\n",
      " |          class  max_speed\n",
      " |      0    bird      389.0\n",
      " |      2    bird       24.0\n",
      " |      3  mammal       80.5\n",
      " |      1  mammal        NaN\n",
      " |      \n",
      " |      We may take elements using negative integers for positive indices,\n",
      " |      starting from the end of the object, just like with Python lists.\n",
      " |      \n",
      " |      >>> df.take([-1, -2])\n",
      " |           name   class  max_speed\n",
      " |      1  monkey  mammal        NaN\n",
      " |      3    lion  mammal       80.5\n",
      " |  \n",
      " |  to_dict(self, into=<class 'dict'>)\n",
      " |      Convert Series to {label -> value} dict or dict-like object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      into : class, default dict\n",
      " |          The collections.abc.Mapping subclass to use as the return\n",
      " |          object. Can be the actual class or an empty\n",
      " |          instance of the mapping type you want.  If you want a\n",
      " |          collections.defaultdict, you must pass it initialized.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      collections.abc.Mapping\n",
      " |          Key-value representation of Series.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s.to_dict()\n",
      " |      {0: 1, 1: 2, 2: 3, 3: 4}\n",
      " |      >>> from collections import OrderedDict, defaultdict\n",
      " |      >>> s.to_dict(OrderedDict)\n",
      " |      OrderedDict([(0, 1), (1, 2), (2, 3), (3, 4)])\n",
      " |      >>> dd = defaultdict(list)\n",
      " |      >>> s.to_dict(dd)\n",
      " |      defaultdict(<class 'list'>, {0: 1, 1: 2, 2: 3, 3: 4})\n",
      " |  \n",
      " |  to_frame(self, name=None) -> 'DataFrame'\n",
      " |      Convert Series to DataFrame.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : object, default None\n",
      " |          The passed name should substitute for the series name (if it has\n",
      " |          one).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          DataFrame representation of Series.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([\"a\", \"b\", \"c\"],\n",
      " |      ...               name=\"vals\")\n",
      " |      >>> s.to_frame()\n",
      " |        vals\n",
      " |      0    a\n",
      " |      1    b\n",
      " |      2    c\n",
      " |  \n",
      " |  to_markdown(self, buf: 'IO[str] | None' = None, mode: 'str' = 'wt', index: 'bool' = True, storage_options: 'StorageOptions' = None, **kwargs) -> 'str | None'\n",
      " |      Print Series in Markdown-friendly format.\n",
      " |      \n",
      " |      .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      buf : str, Path or StringIO-like, optional, default None\n",
      " |          Buffer to write to. If None, the output is returned as a string.\n",
      " |      mode : str, optional\n",
      " |          Mode in which file is opened, \"wt\" by default.\n",
      " |      index : bool, optional, default True\n",
      " |          Add index (row) labels.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib`` as header options. For other URLs (e.g.\n",
      " |          starting with \"s3://\", and \"gcs://\") the key-value pairs are forwarded to\n",
      " |          ``fsspec``. Please see ``fsspec`` and ``urllib`` for more details.\n",
      " |      \n",
      " |          .. versionadded:: 1.2.0\n",
      " |      \n",
      " |      **kwargs\n",
      " |          These parameters will be passed to `tabulate                 <https://pypi.org/project/tabulate>`_.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |          Series in Markdown-friendly format.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Requires the `tabulate <https://pypi.org/project/tabulate>`_ package.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([\"elk\", \"pig\", \"dog\", \"quetzal\"], name=\"animal\")\n",
      " |      >>> print(s.to_markdown())\n",
      " |      |    | animal   |\n",
      " |      |---:|:---------|\n",
      " |      |  0 | elk      |\n",
      " |      |  1 | pig      |\n",
      " |      |  2 | dog      |\n",
      " |      |  3 | quetzal  |\n",
      " |      \n",
      " |      Output markdown with a tabulate option.\n",
      " |      \n",
      " |      >>> print(s.to_markdown(tablefmt=\"grid\"))\n",
      " |      +----+----------+\n",
      " |      |    | animal   |\n",
      " |      +====+==========+\n",
      " |      |  0 | elk      |\n",
      " |      +----+----------+\n",
      " |      |  1 | pig      |\n",
      " |      +----+----------+\n",
      " |      |  2 | dog      |\n",
      " |      +----+----------+\n",
      " |      |  3 | quetzal  |\n",
      " |      +----+----------+\n",
      " |  \n",
      " |  to_period(self, freq=None, copy=True) -> 'Series'\n",
      " |      Convert Series from DatetimeIndex to PeriodIndex.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : str, default None\n",
      " |          Frequency associated with the PeriodIndex.\n",
      " |      copy : bool, default True\n",
      " |          Whether or not to return a copy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Series with index converted to PeriodIndex.\n",
      " |  \n",
      " |  to_string(self, buf=None, na_rep='NaN', float_format=None, header=True, index=True, length=False, dtype=False, name=False, max_rows=None, min_rows=None)\n",
      " |      Render a string representation of the Series.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      buf : StringIO-like, optional\n",
      " |          Buffer to write to.\n",
      " |      na_rep : str, optional\n",
      " |          String representation of NaN to use, default 'NaN'.\n",
      " |      float_format : one-parameter function, optional\n",
      " |          Formatter function to apply to columns' elements if they are\n",
      " |          floats, default None.\n",
      " |      header : bool, default True\n",
      " |          Add the Series header (index name).\n",
      " |      index : bool, optional\n",
      " |          Add index (row) labels, default True.\n",
      " |      length : bool, default False\n",
      " |          Add the Series length.\n",
      " |      dtype : bool, default False\n",
      " |          Add the Series dtype.\n",
      " |      name : bool, default False\n",
      " |          Add the Series name if not None.\n",
      " |      max_rows : int, optional\n",
      " |          Maximum number of rows to show before truncating. If None, show\n",
      " |          all.\n",
      " |      min_rows : int, optional\n",
      " |          The number of rows to display in a truncated repr (when number\n",
      " |          of rows is above `max_rows`).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str or None\n",
      " |          String representation of Series if ``buf=None``, otherwise None.\n",
      " |  \n",
      " |  to_timestamp(self, freq=None, how='start', copy=True) -> 'Series'\n",
      " |      Cast to DatetimeIndex of Timestamps, at *beginning* of period.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : str, default frequency of PeriodIndex\n",
      " |          Desired frequency.\n",
      " |      how : {'s', 'e', 'start', 'end'}\n",
      " |          Convention for converting period to timestamp; start of period\n",
      " |          vs. end.\n",
      " |      copy : bool, default True\n",
      " |          Whether or not to return a copy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series with DatetimeIndex\n",
      " |  \n",
      " |  transform(self, func: 'AggFuncType', axis: 'Axis' = 0, *args, **kwargs) -> 'FrameOrSeriesUnion'\n",
      " |      Call ``func`` on self producing a Series with transformed values.\n",
      " |      \n",
      " |      Produced Series will have same axis length as self.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function, str, list-like or dict-like\n",
      " |          Function to use for transforming the data. If a function, must either\n",
      " |          work when passed a Series or when passed to Series.apply. If func\n",
      " |          is both list-like and dict-like, dict-like behavior takes precedence.\n",
      " |      \n",
      " |          Accepted combinations are:\n",
      " |      \n",
      " |          - function\n",
      " |          - string function name\n",
      " |          - list-like of functions and/or function names, e.g. ``[np.exp, 'sqrt']``\n",
      " |          - dict-like of axis labels -> functions, function names or list-like of such.\n",
      " |      axis : {0 or 'index'}\n",
      " |              Parameter needed for compatibility with DataFrame.\n",
      " |      *args\n",
      " |          Positional arguments to pass to `func`.\n",
      " |      **kwargs\n",
      " |          Keyword arguments to pass to `func`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          A Series that must have the same length as self.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError : If the returned Series has a different length than self.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.agg : Only perform aggregating type operations.\n",
      " |      Series.apply : Invoke function on a Series.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Functions that mutate the passed object can produce unexpected\n",
      " |      behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
      " |      for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': range(3), 'B': range(1, 4)})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  0  1\n",
      " |      1  1  2\n",
      " |      2  2  3\n",
      " |      >>> df.transform(lambda x: x + 1)\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      1  2  3\n",
      " |      2  3  4\n",
      " |      \n",
      " |      Even though the resulting Series must have the same length as the\n",
      " |      input Series, it is possible to provide several input functions:\n",
      " |      \n",
      " |      >>> s = pd.Series(range(3))\n",
      " |      >>> s\n",
      " |      0    0\n",
      " |      1    1\n",
      " |      2    2\n",
      " |      dtype: int64\n",
      " |      >>> s.transform([np.sqrt, np.exp])\n",
      " |             sqrt        exp\n",
      " |      0  0.000000   1.000000\n",
      " |      1  1.000000   2.718282\n",
      " |      2  1.414214   7.389056\n",
      " |      \n",
      " |      You can call transform on a GroupBy object:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     \"Date\": [\n",
      " |      ...         \"2015-05-08\", \"2015-05-07\", \"2015-05-06\", \"2015-05-05\",\n",
      " |      ...         \"2015-05-08\", \"2015-05-07\", \"2015-05-06\", \"2015-05-05\"],\n",
      " |      ...     \"Data\": [5, 8, 6, 1, 50, 100, 60, 120],\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |               Date  Data\n",
      " |      0  2015-05-08     5\n",
      " |      1  2015-05-07     8\n",
      " |      2  2015-05-06     6\n",
      " |      3  2015-05-05     1\n",
      " |      4  2015-05-08    50\n",
      " |      5  2015-05-07   100\n",
      " |      6  2015-05-06    60\n",
      " |      7  2015-05-05   120\n",
      " |      >>> df.groupby('Date')['Data'].transform('sum')\n",
      " |      0     55\n",
      " |      1    108\n",
      " |      2     66\n",
      " |      3    121\n",
      " |      4     55\n",
      " |      5    108\n",
      " |      6     66\n",
      " |      7    121\n",
      " |      Name: Data, dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     \"c\": [1, 1, 1, 2, 2, 2, 2],\n",
      " |      ...     \"type\": [\"m\", \"n\", \"o\", \"m\", \"m\", \"n\", \"n\"]\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |         c type\n",
      " |      0  1    m\n",
      " |      1  1    n\n",
      " |      2  1    o\n",
      " |      3  2    m\n",
      " |      4  2    m\n",
      " |      5  2    n\n",
      " |      6  2    n\n",
      " |      >>> df['size'] = df.groupby('c')['type'].transform(len)\n",
      " |      >>> df\n",
      " |         c type size\n",
      " |      0  1    m    3\n",
      " |      1  1    n    3\n",
      " |      2  1    o    3\n",
      " |      3  2    m    4\n",
      " |      4  2    m    4\n",
      " |      5  2    n    4\n",
      " |      6  2    n    4\n",
      " |  \n",
      " |  truediv(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Return Floating division of series and other, element-wise (binary operator `truediv`).\n",
      " |      \n",
      " |      Equivalent to ``series / other``, but with support to substitute a fill_value for\n",
      " |      missing data in either one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result of filling (at that location) will be missing.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.rtruediv : Reverse of the Floating division operator, see\n",
      " |          `Python documentation\n",
      " |          <https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types>`_\n",
      " |          for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.divide(b, fill_value=0)\n",
      " |      a    1.0\n",
      " |      b    inf\n",
      " |      c    inf\n",
      " |      d    0.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  unique(self) -> 'ArrayLike'\n",
      " |      Return unique values of Series object.\n",
      " |      \n",
      " |      Uniques are returned in order of appearance. Hash table-based unique,\n",
      " |      therefore does NOT sort.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray or ExtensionArray\n",
      " |          The unique values returned as a NumPy array. See Notes.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      unique : Top-level unique method for any 1-d array-like object.\n",
      " |      Index.unique : Return Index with unique values from an Index object.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Returns the unique values as a NumPy array. In case of an\n",
      " |      extension-array backed Series, a new\n",
      " |      :class:`~api.extensions.ExtensionArray` of that type with just\n",
      " |      the unique values is returned. This includes\n",
      " |      \n",
      " |          * Categorical\n",
      " |          * Period\n",
      " |          * Datetime with Timezone\n",
      " |          * Interval\n",
      " |          * Sparse\n",
      " |          * IntegerNA\n",
      " |      \n",
      " |      See Examples section.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> pd.Series([2, 1, 3, 3], name='A').unique()\n",
      " |      array([2, 1, 3])\n",
      " |      \n",
      " |      >>> pd.Series([pd.Timestamp('2016-01-01') for _ in range(3)]).unique()\n",
      " |      array(['2016-01-01T00:00:00.000000000'], dtype='datetime64[ns]')\n",
      " |      \n",
      " |      >>> pd.Series([pd.Timestamp('2016-01-01', tz='US/Eastern')\n",
      " |      ...            for _ in range(3)]).unique()\n",
      " |      <DatetimeArray>\n",
      " |      ['2016-01-01 00:00:00-05:00']\n",
      " |      Length: 1, dtype: datetime64[ns, US/Eastern]\n",
      " |      \n",
      " |      An Categorical will return categories in the order of\n",
      " |      appearance and with the same dtype.\n",
      " |      \n",
      " |      >>> pd.Series(pd.Categorical(list('baabc'))).unique()\n",
      " |      ['b', 'a', 'c']\n",
      " |      Categories (3, object): ['a', 'b', 'c']\n",
      " |      >>> pd.Series(pd.Categorical(list('baabc'), categories=list('abc'),\n",
      " |      ...                          ordered=True)).unique()\n",
      " |      ['b', 'a', 'c']\n",
      " |      Categories (3, object): ['a' < 'b' < 'c']\n",
      " |  \n",
      " |  unstack(self, level=-1, fill_value=None) -> 'DataFrame'\n",
      " |      Unstack, also known as pivot, Series with MultiIndex to produce DataFrame.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, str, or list of these, default last level\n",
      " |          Level(s) to unstack, can pass level name.\n",
      " |      fill_value : scalar value, default None\n",
      " |          Value to use when replacing NaN values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Unstacked Series.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4],\n",
      " |      ...               index=pd.MultiIndex.from_product([['one', 'two'],\n",
      " |      ...                                                 ['a', 'b']]))\n",
      " |      >>> s\n",
      " |      one  a    1\n",
      " |           b    2\n",
      " |      two  a    3\n",
      " |           b    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.unstack(level=-1)\n",
      " |           a  b\n",
      " |      one  1  2\n",
      " |      two  3  4\n",
      " |      \n",
      " |      >>> s.unstack(level=0)\n",
      " |         one  two\n",
      " |      a    1    3\n",
      " |      b    2    4\n",
      " |  \n",
      " |  update(self, other) -> 'None'\n",
      " |      Modify Series in place using values from passed Series.\n",
      " |      \n",
      " |      Uses non-NA values from passed Series to make updates. Aligns\n",
      " |      on index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, or object coercible into Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.update(pd.Series([4, 5, 6]))\n",
      " |      >>> s\n",
      " |      0    4\n",
      " |      1    5\n",
      " |      2    6\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s = pd.Series(['a', 'b', 'c'])\n",
      " |      >>> s.update(pd.Series(['d', 'e'], index=[0, 2]))\n",
      " |      >>> s\n",
      " |      0    d\n",
      " |      1    b\n",
      " |      2    e\n",
      " |      dtype: object\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.update(pd.Series([4, 5, 6, 7, 8]))\n",
      " |      >>> s\n",
      " |      0    4\n",
      " |      1    5\n",
      " |      2    6\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      If ``other`` contains NaNs the corresponding values are not updated\n",
      " |      in the original Series.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.update(pd.Series([4, np.nan, 6]))\n",
      " |      >>> s\n",
      " |      0    4\n",
      " |      1    2\n",
      " |      2    6\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      ``other`` can also be a non-Series object type\n",
      " |      that is coercible into a Series\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.update([4, np.nan, 6])\n",
      " |      >>> s\n",
      " |      0    4\n",
      " |      1    2\n",
      " |      2    6\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.update({1: 9})\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    9\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  var(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      " |      Return unbiased variance over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar.\n",
      " |      ddof : int, default 1\n",
      " |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\n",
      " |          where N represents the number of elements.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series (if level specified)\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      To have the same behaviour as `numpy.std`, use `ddof=0` (instead of the\n",
      " |      default `ddof=1`)\n",
      " |  \n",
      " |  view(self, dtype: 'Dtype | None' = None) -> 'Series'\n",
      " |      Create a new view of the Series.\n",
      " |      \n",
      " |      This function will return a new Series with a view of the same\n",
      " |      underlying values in memory, optionally reinterpreted with a new data\n",
      " |      type. The new data type must preserve the same size in bytes as to not\n",
      " |      cause index misalignment.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : data type\n",
      " |          Data type object or one of their string representations.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          A new Series object as a view of the same data in memory.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.view : Equivalent numpy function to create a new view of\n",
      " |          the same data in memory.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Series are instantiated with ``dtype=float64`` by default. While\n",
      " |      ``numpy.ndarray.view()`` will return a view with the same data type as\n",
      " |      the original array, ``Series.view()`` (without specified dtype)\n",
      " |      will try using ``float64`` and may fail if the original data type size\n",
      " |      in bytes is not the same.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([-2, -1, 0, 1, 2], dtype='int8')\n",
      " |      >>> s\n",
      " |      0   -2\n",
      " |      1   -1\n",
      " |      2    0\n",
      " |      3    1\n",
      " |      4    2\n",
      " |      dtype: int8\n",
      " |      \n",
      " |      The 8 bit signed integer representation of `-1` is `0b11111111`, but\n",
      " |      the same bytes represent 255 if read as an 8 bit unsigned integer:\n",
      " |      \n",
      " |      >>> us = s.view('uint8')\n",
      " |      >>> us\n",
      " |      0    254\n",
      " |      1    255\n",
      " |      2      0\n",
      " |      3      1\n",
      " |      4      2\n",
      " |      dtype: uint8\n",
      " |      \n",
      " |      The views share the same underlying values:\n",
      " |      \n",
      " |      >>> us[0] = 128\n",
      " |      >>> s\n",
      " |      0   -128\n",
      " |      1     -1\n",
      " |      2      0\n",
      " |      3      1\n",
      " |      4      2\n",
      " |      dtype: int8\n",
      " |  \n",
      " |  where(self, cond, other=nan, inplace=False, axis=None, level=None, errors='raise', try_cast=<no_default>)\n",
      " |      Replace values where the condition is False.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      cond : bool Series/DataFrame, array-like, or callable\n",
      " |          Where `cond` is True, keep the original value. Where\n",
      " |          False, replace with corresponding value from `other`.\n",
      " |          If `cond` is callable, it is computed on the Series/DataFrame and\n",
      " |          should return boolean Series/DataFrame or array. The callable must\n",
      " |          not change input Series/DataFrame (though pandas doesn't check it).\n",
      " |      other : scalar, Series/DataFrame, or callable\n",
      " |          Entries where `cond` is False are replaced with\n",
      " |          corresponding value from `other`.\n",
      " |          If other is callable, it is computed on the Series/DataFrame and\n",
      " |          should return scalar or Series/DataFrame. The callable must not\n",
      " |          change input Series/DataFrame (though pandas doesn't check it).\n",
      " |      inplace : bool, default False\n",
      " |          Whether to perform the operation in place on the data.\n",
      " |      axis : int, default None\n",
      " |          Alignment axis if needed.\n",
      " |      level : int, default None\n",
      " |          Alignment level if needed.\n",
      " |      errors : str, {'raise', 'ignore'}, default 'raise'\n",
      " |          Note that currently this parameter won't affect\n",
      " |          the results and will always coerce to a suitable dtype.\n",
      " |      \n",
      " |          - 'raise' : allow exceptions to be raised.\n",
      " |          - 'ignore' : suppress exceptions. On error return original object.\n",
      " |      \n",
      " |      try_cast : bool, default None\n",
      " |          Try to cast the result back to the input type (if possible).\n",
      " |      \n",
      " |          .. deprecated:: 1.3.0\n",
      " |              Manually cast back if necessary.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Same type as caller or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :func:`DataFrame.mask` : Return an object of same shape as\n",
      " |          self.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The where method is an application of the if-then idiom. For each\n",
      " |      element in the calling DataFrame, if ``cond`` is ``True`` the\n",
      " |      element is used; otherwise the corresponding element from the DataFrame\n",
      " |      ``other`` is used.\n",
      " |      \n",
      " |      The signature for :func:`DataFrame.where` differs from\n",
      " |      :func:`numpy.where`. Roughly ``df1.where(m, df2)`` is equivalent to\n",
      " |      ``np.where(m, df1, df2)``.\n",
      " |      \n",
      " |      For further details and examples see the ``where`` documentation in\n",
      " |      :ref:`indexing <indexing.where_mask>`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(range(5))\n",
      " |      >>> s.where(s > 0)\n",
      " |      0    NaN\n",
      " |      1    1.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      4    4.0\n",
      " |      dtype: float64\n",
      " |      >>> s.mask(s > 0)\n",
      " |      0    0.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.where(s > 1, 10)\n",
      " |      0    10\n",
      " |      1    10\n",
      " |      2    2\n",
      " |      3    3\n",
      " |      4    4\n",
      " |      dtype: int64\n",
      " |      >>> s.mask(s > 1, 10)\n",
      " |      0     0\n",
      " |      1     1\n",
      " |      2    10\n",
      " |      3    10\n",
      " |      4    10\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  0  1\n",
      " |      1  2  3\n",
      " |      2  4  5\n",
      " |      3  6  7\n",
      " |      4  8  9\n",
      " |      >>> m = df % 3 == 0\n",
      " |      >>> df.where(m, -df)\n",
      " |         A  B\n",
      " |      0  0 -1\n",
      " |      1 -2  3\n",
      " |      2 -4 -5\n",
      " |      3  6 -7\n",
      " |      4 -8  9\n",
      " |      >>> df.where(m, -df) == np.where(m, df, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      >>> df.where(m, -df) == df.mask(~m, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  array\n",
      " |      The ExtensionArray of the data backing this Series or Index.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ExtensionArray\n",
      " |          An ExtensionArray of the values stored within. For extension\n",
      " |          types, this is the actual array. For NumPy native types, this\n",
      " |          is a thin (no copy) wrapper around :class:`numpy.ndarray`.\n",
      " |      \n",
      " |          ``.array`` differs ``.values`` which may require converting the\n",
      " |          data to a different form.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.to_numpy : Similar method that always returns a NumPy array.\n",
      " |      Series.to_numpy : Similar method that always returns a NumPy array.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This table lays out the different array types for each extension\n",
      " |      dtype within pandas.\n",
      " |      \n",
      " |      ================== =============================\n",
      " |      dtype              array type\n",
      " |      ================== =============================\n",
      " |      category           Categorical\n",
      " |      period             PeriodArray\n",
      " |      interval           IntervalArray\n",
      " |      IntegerNA          IntegerArray\n",
      " |      string             StringArray\n",
      " |      boolean            BooleanArray\n",
      " |      datetime64[ns, tz] DatetimeArray\n",
      " |      ================== =============================\n",
      " |      \n",
      " |      For any 3rd-party extension types, the array type will be an\n",
      " |      ExtensionArray.\n",
      " |      \n",
      " |      For all remaining dtypes ``.array`` will be a\n",
      " |      :class:`arrays.NumpyExtensionArray` wrapping the actual ndarray\n",
      " |      stored within. If you absolutely need a NumPy array (possibly with\n",
      " |      copying / coercing data), then use :meth:`Series.to_numpy` instead.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      For regular NumPy types like int, and float, a PandasArray\n",
      " |      is returned.\n",
      " |      \n",
      " |      >>> pd.Series([1, 2, 3]).array\n",
      " |      <PandasArray>\n",
      " |      [1, 2, 3]\n",
      " |      Length: 3, dtype: int64\n",
      " |      \n",
      " |      For extension types, like Categorical, the actual ExtensionArray\n",
      " |      is returned\n",
      " |      \n",
      " |      >>> ser = pd.Series(pd.Categorical(['a', 'b', 'a']))\n",
      " |      >>> ser.array\n",
      " |      ['a', 'b', 'a']\n",
      " |      Categories (2, object): ['a', 'b']\n",
      " |  \n",
      " |  axes\n",
      " |      Return a list of the row axis labels.\n",
      " |  \n",
      " |  dtype\n",
      " |      Return the dtype object of the underlying data.\n",
      " |  \n",
      " |  dtypes\n",
      " |      Return the dtype object of the underlying data.\n",
      " |  \n",
      " |  hasnans\n",
      " |      Return if I have any nans; enables various perf speedups.\n",
      " |  \n",
      " |  values\n",
      " |      Return Series as ndarray or ndarray-like depending on the dtype.\n",
      " |      \n",
      " |      .. warning::\n",
      " |      \n",
      " |         We recommend using :attr:`Series.array` or\n",
      " |         :meth:`Series.to_numpy`, depending on whether you need\n",
      " |         a reference to the underlying data or a NumPy array.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray or ndarray-like\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.array : Reference to the underlying data.\n",
      " |      Series.to_numpy : A NumPy array representing the underlying data.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> pd.Series([1, 2, 3]).values\n",
      " |      array([1, 2, 3])\n",
      " |      \n",
      " |      >>> pd.Series(list('aabc')).values\n",
      " |      array(['a', 'a', 'b', 'c'], dtype=object)\n",
      " |      \n",
      " |      >>> pd.Series(list('aabc')).astype('category').values\n",
      " |      ['a', 'a', 'b', 'c']\n",
      " |      Categories (3, object): ['a', 'b', 'c']\n",
      " |      \n",
      " |      Timezone aware datetime data is converted to UTC:\n",
      " |      \n",
      " |      >>> pd.Series(pd.date_range('20130101', periods=3,\n",
      " |      ...                         tz='US/Eastern')).values\n",
      " |      array(['2013-01-01T05:00:00.000000000',\n",
      " |             '2013-01-02T05:00:00.000000000',\n",
      " |             '2013-01-03T05:00:00.000000000'], dtype='datetime64[ns]')\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  index\n",
      " |      The index (axis labels) of the Series.\n",
      " |  \n",
      " |  name\n",
      " |      Return the name of the Series.\n",
      " |      \n",
      " |      The name of a Series becomes its index or column name if it is used\n",
      " |      to form a DataFrame. It is also used whenever displaying the Series\n",
      " |      using the interpreter.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      label (hashable object)\n",
      " |          The name of the Series, also the column name if part of a DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.rename : Sets the Series name when given a scalar input.\n",
      " |      Index.name : Corresponding Index property.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The Series name can be set initially when calling the constructor.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3], dtype=np.int64, name='Numbers')\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      Name: Numbers, dtype: int64\n",
      " |      >>> s.name = \"Integers\"\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      Name: Integers, dtype: int64\n",
      " |      \n",
      " |      The name of a Series within a DataFrame is its column name.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2], [3, 4], [5, 6]],\n",
      " |      ...                   columns=[\"Odd Numbers\", \"Even Numbers\"])\n",
      " |      >>> df\n",
      " |         Odd Numbers  Even Numbers\n",
      " |      0            1             2\n",
      " |      1            3             4\n",
      " |      2            5             6\n",
      " |      >>> df[\"Even Numbers\"].name\n",
      " |      'Even Numbers'\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {'_index': 'Index | None', '_metadata': 'list[str]',...\n",
      " |  \n",
      " |  cat = <class 'pandas.core.arrays.categorical.CategoricalAccessor'>\n",
      " |      Accessor object for categorical properties of the Series values.\n",
      " |      \n",
      " |      Be aware that assigning to `categories` is a inplace operation, while all\n",
      " |      methods return new categorical data per default (but can be called with\n",
      " |      `inplace=True`).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : Series or CategoricalIndex\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(list(\"abbccc\")).astype(\"category\")\n",
      " |      >>> s\n",
      " |      0    a\n",
      " |      1    b\n",
      " |      2    b\n",
      " |      3    c\n",
      " |      4    c\n",
      " |      5    c\n",
      " |      dtype: category\n",
      " |      Categories (3, object): ['a', 'b', 'c']\n",
      " |      \n",
      " |      >>> s.cat.categories\n",
      " |      Index(['a', 'b', 'c'], dtype='object')\n",
      " |      \n",
      " |      >>> s.cat.rename_categories(list(\"cba\"))\n",
      " |      0    c\n",
      " |      1    b\n",
      " |      2    b\n",
      " |      3    a\n",
      " |      4    a\n",
      " |      5    a\n",
      " |      dtype: category\n",
      " |      Categories (3, object): ['c', 'b', 'a']\n",
      " |      \n",
      " |      >>> s.cat.reorder_categories(list(\"cba\"))\n",
      " |      0    a\n",
      " |      1    b\n",
      " |      2    b\n",
      " |      3    c\n",
      " |      4    c\n",
      " |      5    c\n",
      " |      dtype: category\n",
      " |      Categories (3, object): ['c', 'b', 'a']\n",
      " |      \n",
      " |      >>> s.cat.add_categories([\"d\", \"e\"])\n",
      " |      0    a\n",
      " |      1    b\n",
      " |      2    b\n",
      " |      3    c\n",
      " |      4    c\n",
      " |      5    c\n",
      " |      dtype: category\n",
      " |      Categories (5, object): ['a', 'b', 'c', 'd', 'e']\n",
      " |      \n",
      " |      >>> s.cat.remove_categories([\"a\", \"c\"])\n",
      " |      0    NaN\n",
      " |      1      b\n",
      " |      2      b\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      5    NaN\n",
      " |      dtype: category\n",
      " |      Categories (1, object): ['b']\n",
      " |      \n",
      " |      >>> s1 = s.cat.add_categories([\"d\", \"e\"])\n",
      " |      >>> s1.cat.remove_unused_categories()\n",
      " |      0    a\n",
      " |      1    b\n",
      " |      2    b\n",
      " |      3    c\n",
      " |      4    c\n",
      " |      5    c\n",
      " |      dtype: category\n",
      " |      Categories (3, object): ['a', 'b', 'c']\n",
      " |      \n",
      " |      >>> s.cat.set_categories(list(\"abcde\"))\n",
      " |      0    a\n",
      " |      1    b\n",
      " |      2    b\n",
      " |      3    c\n",
      " |      4    c\n",
      " |      5    c\n",
      " |      dtype: category\n",
      " |      Categories (5, object): ['a', 'b', 'c', 'd', 'e']\n",
      " |      \n",
      " |      >>> s.cat.as_ordered()\n",
      " |      0    a\n",
      " |      1    b\n",
      " |      2    b\n",
      " |      3    c\n",
      " |      4    c\n",
      " |      5    c\n",
      " |      dtype: category\n",
      " |      Categories (3, object): ['a' < 'b' < 'c']\n",
      " |      \n",
      " |      >>> s.cat.as_unordered()\n",
      " |      0    a\n",
      " |      1    b\n",
      " |      2    b\n",
      " |      3    c\n",
      " |      4    c\n",
      " |      5    c\n",
      " |      dtype: category\n",
      " |      Categories (3, object): ['a', 'b', 'c']\n",
      " |  \n",
      " |  \n",
      " |  dt = <class 'pandas.core.indexes.accessors.CombinedDatetimelikePropert...\n",
      " |  \n",
      " |  plot = <class 'pandas.plotting._core.PlotAccessor'>\n",
      " |      Make plots of Series or DataFrame.\n",
      " |      \n",
      " |      Uses the backend specified by the\n",
      " |      option ``plotting.backend``. By default, matplotlib is used.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : Series or DataFrame\n",
      " |          The object for which the method is called.\n",
      " |      x : label or position, default None\n",
      " |          Only used if data is a DataFrame.\n",
      " |      y : label, position or list of label, positions, default None\n",
      " |          Allows plotting of one column versus another. Only used if data is a\n",
      " |          DataFrame.\n",
      " |      kind : str\n",
      " |          The kind of plot to produce:\n",
      " |      \n",
      " |          - 'line' : line plot (default)\n",
      " |          - 'bar' : vertical bar plot\n",
      " |          - 'barh' : horizontal bar plot\n",
      " |          - 'hist' : histogram\n",
      " |          - 'box' : boxplot\n",
      " |          - 'kde' : Kernel Density Estimation plot\n",
      " |          - 'density' : same as 'kde'\n",
      " |          - 'area' : area plot\n",
      " |          - 'pie' : pie plot\n",
      " |          - 'scatter' : scatter plot (DataFrame only)\n",
      " |          - 'hexbin' : hexbin plot (DataFrame only)\n",
      " |      ax : matplotlib axes object, default None\n",
      " |          An axes of the current figure.\n",
      " |      subplots : bool, default False\n",
      " |          Make separate subplots for each column.\n",
      " |      sharex : bool, default True if ax is None else False\n",
      " |          In case ``subplots=True``, share x axis and set some x axis labels\n",
      " |          to invisible; defaults to True if ax is None otherwise False if\n",
      " |          an ax is passed in; Be aware, that passing in both an ax and\n",
      " |          ``sharex=True`` will alter all x axis labels for all axis in a figure.\n",
      " |      sharey : bool, default False\n",
      " |          In case ``subplots=True``, share y axis and set some y axis labels to invisible.\n",
      " |      layout : tuple, optional\n",
      " |          (rows, columns) for the layout of subplots.\n",
      " |      figsize : a tuple (width, height) in inches\n",
      " |          Size of a figure object.\n",
      " |      use_index : bool, default True\n",
      " |          Use index as ticks for x axis.\n",
      " |      title : str or list\n",
      " |          Title to use for the plot. If a string is passed, print the string\n",
      " |          at the top of the figure. If a list is passed and `subplots` is\n",
      " |          True, print each item in the list above the corresponding subplot.\n",
      " |      grid : bool, default None (matlab style default)\n",
      " |          Axis grid lines.\n",
      " |      legend : bool or {'reverse'}\n",
      " |          Place legend on axis subplots.\n",
      " |      style : list or dict\n",
      " |          The matplotlib line style per column.\n",
      " |      logx : bool or 'sym', default False\n",
      " |          Use log scaling or symlog scaling on x axis.\n",
      " |          .. versionchanged:: 0.25.0\n",
      " |      \n",
      " |      logy : bool or 'sym' default False\n",
      " |          Use log scaling or symlog scaling on y axis.\n",
      " |          .. versionchanged:: 0.25.0\n",
      " |      \n",
      " |      loglog : bool or 'sym', default False\n",
      " |          Use log scaling or symlog scaling on both x and y axes.\n",
      " |          .. versionchanged:: 0.25.0\n",
      " |      \n",
      " |      xticks : sequence\n",
      " |          Values to use for the xticks.\n",
      " |      yticks : sequence\n",
      " |          Values to use for the yticks.\n",
      " |      xlim : 2-tuple/list\n",
      " |          Set the x limits of the current axes.\n",
      " |      ylim : 2-tuple/list\n",
      " |          Set the y limits of the current axes.\n",
      " |      xlabel : label, optional\n",
      " |          Name to use for the xlabel on x-axis. Default uses index name as xlabel, or the\n",
      " |          x-column name for planar plots.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |             Now applicable to planar plots (`scatter`, `hexbin`).\n",
      " |      \n",
      " |      ylabel : label, optional\n",
      " |          Name to use for the ylabel on y-axis. Default will show no ylabel, or the\n",
      " |          y-column name for planar plots.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |             Now applicable to planar plots (`scatter`, `hexbin`).\n",
      " |      \n",
      " |      rot : int, default None\n",
      " |          Rotation for ticks (xticks for vertical, yticks for horizontal\n",
      " |          plots).\n",
      " |      fontsize : int, default None\n",
      " |          Font size for xticks and yticks.\n",
      " |      colormap : str or matplotlib colormap object, default None\n",
      " |          Colormap to select colors from. If string, load colormap with that\n",
      " |          name from matplotlib.\n",
      " |      colorbar : bool, optional\n",
      " |          If True, plot colorbar (only relevant for 'scatter' and 'hexbin'\n",
      " |          plots).\n",
      " |      position : float\n",
      " |          Specify relative alignments for bar plot layout.\n",
      " |          From 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5\n",
      " |          (center).\n",
      " |      table : bool, Series or DataFrame, default False\n",
      " |          If True, draw a table using the data in the DataFrame and the data\n",
      " |          will be transposed to meet matplotlib's default layout.\n",
      " |          If a Series or DataFrame is passed, use passed data to draw a\n",
      " |          table.\n",
      " |      yerr : DataFrame, Series, array-like, dict and str\n",
      " |          See :ref:`Plotting with Error Bars <visualization.errorbars>` for\n",
      " |          detail.\n",
      " |      xerr : DataFrame, Series, array-like, dict and str\n",
      " |          Equivalent to yerr.\n",
      " |      stacked : bool, default False in line and bar plots, and True in area plot\n",
      " |          If True, create stacked plot.\n",
      " |      sort_columns : bool, default False\n",
      " |          Sort column names to determine plot ordering.\n",
      " |      secondary_y : bool or sequence, default False\n",
      " |          Whether to plot on the secondary y-axis if a list/tuple, which\n",
      " |          columns to plot on secondary y-axis.\n",
      " |      mark_right : bool, default True\n",
      " |          When using a secondary_y axis, automatically mark the column\n",
      " |          labels with \"(right)\" in the legend.\n",
      " |      include_bool : bool, default is False\n",
      " |          If True, boolean values can be plotted.\n",
      " |      backend : str, default None\n",
      " |          Backend to use instead of the backend specified in the option\n",
      " |          ``plotting.backend``. For instance, 'matplotlib'. Alternatively, to\n",
      " |          specify the ``plotting.backend`` for the whole session, set\n",
      " |          ``pd.options.plotting.backend``.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      **kwargs\n",
      " |          Options to pass to matplotlib plotting method.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      :class:`matplotlib.axes.Axes` or numpy.ndarray of them\n",
      " |          If the backend is not the default matplotlib one, the return value\n",
      " |          will be the object returned by the backend.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      - See matplotlib documentation online for more on this subject\n",
      " |      - If `kind` = 'bar' or 'barh', you can specify relative alignments\n",
      " |        for bar plot layout by `position` keyword.\n",
      " |        From 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5\n",
      " |        (center)\n",
      " |  \n",
      " |  \n",
      " |  sparse = <class 'pandas.core.arrays.sparse.accessor.SparseAccessor'>\n",
      " |      Accessor for SparseSparse from other sparse matrix data types.\n",
      " |  \n",
      " |  \n",
      " |  str = <class 'pandas.core.strings.accessor.StringMethods'>\n",
      " |      Vectorized string functions for Series and Index.\n",
      " |      \n",
      " |      NAs stay NA unless handled otherwise by a particular method.\n",
      " |      Patterned after Python's string methods, with some inspiration from\n",
      " |      R's stringr package.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([\"A_Str_Series\"])\n",
      " |      >>> s\n",
      " |      0    A_Str_Series\n",
      " |      dtype: object\n",
      " |      \n",
      " |      >>> s.str.split(\"_\")\n",
      " |      0    [A, Str, Series]\n",
      " |      dtype: object\n",
      " |      \n",
      " |      >>> s.str.replace(\"_\", \"\")\n",
      " |      0    AStrSeries\n",
      " |      dtype: object\n",
      " |  \n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.IndexOpsMixin:\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Return an iterator of the values.\n",
      " |      \n",
      " |      These are each a scalar type, which is a Python scalar\n",
      " |      (for str, int, float) or a pandas scalar\n",
      " |      (for Timestamp/Timedelta/Interval/Period)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      iterator\n",
      " |  \n",
      " |  argmax(self, axis=None, skipna: 'bool' = True, *args, **kwargs) -> 'int'\n",
      " |      Return int position of the largest value in the Series.\n",
      " |      \n",
      " |      If the maximum is achieved in multiple locations,\n",
      " |      the first row position is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {None}\n",
      " |          Dummy argument for consistency with Series.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when showing the result.\n",
      " |      *args, **kwargs\n",
      " |          Additional arguments and keywords for compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      int\n",
      " |          Row position of the maximum value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.argmax : Return position of the maximum value.\n",
      " |      Series.argmin : Return position of the minimum value.\n",
      " |      numpy.ndarray.argmax : Equivalent method for numpy arrays.\n",
      " |      Series.idxmax : Return index label of the maximum values.\n",
      " |      Series.idxmin : Return index label of the minimum values.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Consider dataset containing cereal calories\n",
      " |      \n",
      " |      >>> s = pd.Series({'Corn Flakes': 100.0, 'Almond Delight': 110.0,\n",
      " |      ...                'Cinnamon Toast Crunch': 120.0, 'Cocoa Puff': 110.0})\n",
      " |      >>> s\n",
      " |      Corn Flakes              100.0\n",
      " |      Almond Delight           110.0\n",
      " |      Cinnamon Toast Crunch    120.0\n",
      " |      Cocoa Puff               110.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.argmax()\n",
      " |      2\n",
      " |      >>> s.argmin()\n",
      " |      0\n",
      " |      \n",
      " |      The maximum cereal calories is the third element and\n",
      " |      the minimum cereal calories is the first element,\n",
      " |      since series is zero-indexed.\n",
      " |  \n",
      " |  argmin(self, axis=None, skipna=True, *args, **kwargs) -> 'int'\n",
      " |      Return int position of the smallest value in the Series.\n",
      " |      \n",
      " |      If the minimum is achieved in multiple locations,\n",
      " |      the first row position is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {None}\n",
      " |          Dummy argument for consistency with Series.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when showing the result.\n",
      " |      *args, **kwargs\n",
      " |          Additional arguments and keywords for compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      int\n",
      " |          Row position of the minimum value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.argmin : Return position of the minimum value.\n",
      " |      Series.argmax : Return position of the maximum value.\n",
      " |      numpy.ndarray.argmin : Equivalent method for numpy arrays.\n",
      " |      Series.idxmax : Return index label of the maximum values.\n",
      " |      Series.idxmin : Return index label of the minimum values.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Consider dataset containing cereal calories\n",
      " |      \n",
      " |      >>> s = pd.Series({'Corn Flakes': 100.0, 'Almond Delight': 110.0,\n",
      " |      ...                'Cinnamon Toast Crunch': 120.0, 'Cocoa Puff': 110.0})\n",
      " |      >>> s\n",
      " |      Corn Flakes              100.0\n",
      " |      Almond Delight           110.0\n",
      " |      Cinnamon Toast Crunch    120.0\n",
      " |      Cocoa Puff               110.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.argmax()\n",
      " |      2\n",
      " |      >>> s.argmin()\n",
      " |      0\n",
      " |      \n",
      " |      The maximum cereal calories is the third element and\n",
      " |      the minimum cereal calories is the first element,\n",
      " |      since series is zero-indexed.\n",
      " |  \n",
      " |  factorize(self, sort: 'bool' = False, na_sentinel: 'int | None' = -1)\n",
      " |      Encode the object as an enumerated type or categorical variable.\n",
      " |      \n",
      " |      This method is useful for obtaining a numeric representation of an\n",
      " |      array when all that matters is identifying distinct values. `factorize`\n",
      " |      is available as both a top-level function :func:`pandas.factorize`,\n",
      " |      and as a method :meth:`Series.factorize` and :meth:`Index.factorize`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sort : bool, default False\n",
      " |          Sort `uniques` and shuffle `codes` to maintain the\n",
      " |          relationship.\n",
      " |      \n",
      " |      na_sentinel : int or None, default -1\n",
      " |          Value to mark \"not found\". If None, will not drop the NaN\n",
      " |          from the uniques of the values.\n",
      " |      \n",
      " |          .. versionchanged:: 1.1.2\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      codes : ndarray\n",
      " |          An integer ndarray that's an indexer into `uniques`.\n",
      " |          ``uniques.take(codes)`` will have the same values as `values`.\n",
      " |      uniques : ndarray, Index, or Categorical\n",
      " |          The unique valid values. When `values` is Categorical, `uniques`\n",
      " |          is a Categorical. When `values` is some other pandas object, an\n",
      " |          `Index` is returned. Otherwise, a 1-D ndarray is returned.\n",
      " |      \n",
      " |          .. note ::\n",
      " |      \n",
      " |             Even if there's a missing value in `values`, `uniques` will\n",
      " |             *not* contain an entry for it.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      cut : Discretize continuous-valued array.\n",
      " |      unique : Find the unique value in an array.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      These examples all show factorize as a top-level method like\n",
      " |      ``pd.factorize(values)``. The results are identical for methods like\n",
      " |      :meth:`Series.factorize`.\n",
      " |      \n",
      " |      >>> codes, uniques = pd.factorize(['b', 'b', 'a', 'c', 'b'])\n",
      " |      >>> codes\n",
      " |      array([0, 0, 1, 2, 0]...)\n",
      " |      >>> uniques\n",
      " |      array(['b', 'a', 'c'], dtype=object)\n",
      " |      \n",
      " |      With ``sort=True``, the `uniques` will be sorted, and `codes` will be\n",
      " |      shuffled so that the relationship is the maintained.\n",
      " |      \n",
      " |      >>> codes, uniques = pd.factorize(['b', 'b', 'a', 'c', 'b'], sort=True)\n",
      " |      >>> codes\n",
      " |      array([1, 1, 0, 2, 1]...)\n",
      " |      >>> uniques\n",
      " |      array(['a', 'b', 'c'], dtype=object)\n",
      " |      \n",
      " |      Missing values are indicated in `codes` with `na_sentinel`\n",
      " |      (``-1`` by default). Note that missing values are never\n",
      " |      included in `uniques`.\n",
      " |      \n",
      " |      >>> codes, uniques = pd.factorize(['b', None, 'a', 'c', 'b'])\n",
      " |      >>> codes\n",
      " |      array([ 0, -1,  1,  2,  0]...)\n",
      " |      >>> uniques\n",
      " |      array(['b', 'a', 'c'], dtype=object)\n",
      " |      \n",
      " |      Thus far, we've only factorized lists (which are internally coerced to\n",
      " |      NumPy arrays). When factorizing pandas objects, the type of `uniques`\n",
      " |      will differ. For Categoricals, a `Categorical` is returned.\n",
      " |      \n",
      " |      >>> cat = pd.Categorical(['a', 'a', 'c'], categories=['a', 'b', 'c'])\n",
      " |      >>> codes, uniques = pd.factorize(cat)\n",
      " |      >>> codes\n",
      " |      array([0, 0, 1]...)\n",
      " |      >>> uniques\n",
      " |      ['a', 'c']\n",
      " |      Categories (3, object): ['a', 'b', 'c']\n",
      " |      \n",
      " |      Notice that ``'b'`` is in ``uniques.categories``, despite not being\n",
      " |      present in ``cat.values``.\n",
      " |      \n",
      " |      For all other pandas objects, an Index of the appropriate type is\n",
      " |      returned.\n",
      " |      \n",
      " |      >>> cat = pd.Series(['a', 'a', 'c'])\n",
      " |      >>> codes, uniques = pd.factorize(cat)\n",
      " |      >>> codes\n",
      " |      array([0, 0, 1]...)\n",
      " |      >>> uniques\n",
      " |      Index(['a', 'c'], dtype='object')\n",
      " |      \n",
      " |      If NaN is in the values, and we want to include NaN in the uniques of the\n",
      " |      values, it can be achieved by setting ``na_sentinel=None``.\n",
      " |      \n",
      " |      >>> values = np.array([1, 2, 1, np.nan])\n",
      " |      >>> codes, uniques = pd.factorize(values)  # default: na_sentinel=-1\n",
      " |      >>> codes\n",
      " |      array([ 0,  1,  0, -1])\n",
      " |      >>> uniques\n",
      " |      array([1., 2.])\n",
      " |      \n",
      " |      >>> codes, uniques = pd.factorize(values, na_sentinel=None)\n",
      " |      >>> codes\n",
      " |      array([0, 1, 0, 2])\n",
      " |      >>> uniques\n",
      " |      array([ 1.,  2., nan])\n",
      " |  \n",
      " |  item(self)\n",
      " |      Return the first element of the underlying data as a Python scalar.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar\n",
      " |          The first element of %(klass)s.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          If the data is not length-1.\n",
      " |  \n",
      " |  nunique(self, dropna: 'bool' = True) -> 'int'\n",
      " |      Return number of unique elements in the object.\n",
      " |      \n",
      " |      Excludes NA values by default.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dropna : bool, default True\n",
      " |          Don't include NaN in the count.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      int\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.nunique: Method nunique for DataFrame.\n",
      " |      Series.count: Count non-NA/null observations in the Series.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 3, 5, 7, 7])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    3\n",
      " |      2    5\n",
      " |      3    7\n",
      " |      4    7\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.nunique()\n",
      " |      4\n",
      " |  \n",
      " |  to_list = tolist(self)\n",
      " |  \n",
      " |  to_numpy(self, dtype: 'Dtype | None' = None, copy: 'bool' = False, na_value=<no_default>, **kwargs) -> 'np.ndarray'\n",
      " |      A NumPy ndarray representing the values in this Series or Index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : str or numpy.dtype, optional\n",
      " |          The dtype to pass to :meth:`numpy.asarray`.\n",
      " |      copy : bool, default False\n",
      " |          Whether to ensure that the returned value is not a view on\n",
      " |          another array. Note that ``copy=False`` does not *ensure* that\n",
      " |          ``to_numpy()`` is no-copy. Rather, ``copy=True`` ensure that\n",
      " |          a copy is made, even if not strictly necessary.\n",
      " |      na_value : Any, optional\n",
      " |          The value to use for missing values. The default value depends\n",
      " |          on `dtype` and the type of the array.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      **kwargs\n",
      " |          Additional keywords passed through to the ``to_numpy`` method\n",
      " |          of the underlying array (for extension arrays).\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.array : Get the actual data stored within.\n",
      " |      Index.array : Get the actual data stored within.\n",
      " |      DataFrame.to_numpy : Similar method for DataFrame.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The returned array will be the same up to equality (values equal\n",
      " |      in `self` will be equal in the returned array; likewise for values\n",
      " |      that are not equal). When `self` contains an ExtensionArray, the\n",
      " |      dtype may be different. For example, for a category-dtype Series,\n",
      " |      ``to_numpy()`` will return a NumPy array and the categorical dtype\n",
      " |      will be lost.\n",
      " |      \n",
      " |      For NumPy dtypes, this will be a reference to the actual data stored\n",
      " |      in this Series or Index (assuming ``copy=False``). Modifying the result\n",
      " |      in place will modify the data stored in the Series or Index (not that\n",
      " |      we recommend doing that).\n",
      " |      \n",
      " |      For extension types, ``to_numpy()`` *may* require copying data and\n",
      " |      coercing the result to a NumPy type (possibly object), which may be\n",
      " |      expensive. When you need a no-copy reference to the underlying data,\n",
      " |      :attr:`Series.array` should be used instead.\n",
      " |      \n",
      " |      This table lays out the different dtypes and default return types of\n",
      " |      ``to_numpy()`` for various dtypes within pandas.\n",
      " |      \n",
      " |      ================== ================================\n",
      " |      dtype              array type\n",
      " |      ================== ================================\n",
      " |      category[T]        ndarray[T] (same dtype as input)\n",
      " |      period             ndarray[object] (Periods)\n",
      " |      interval           ndarray[object] (Intervals)\n",
      " |      IntegerNA          ndarray[object]\n",
      " |      datetime64[ns]     datetime64[ns]\n",
      " |      datetime64[ns, tz] ndarray[object] (Timestamps)\n",
      " |      ================== ================================\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> ser = pd.Series(pd.Categorical(['a', 'b', 'a']))\n",
      " |      >>> ser.to_numpy()\n",
      " |      array(['a', 'b', 'a'], dtype=object)\n",
      " |      \n",
      " |      Specify the `dtype` to control how datetime-aware data is represented.\n",
      " |      Use ``dtype=object`` to return an ndarray of pandas :class:`Timestamp`\n",
      " |      objects, each with the correct ``tz``.\n",
      " |      \n",
      " |      >>> ser = pd.Series(pd.date_range('2000', periods=2, tz=\"CET\"))\n",
      " |      >>> ser.to_numpy(dtype=object)\n",
      " |      array([Timestamp('2000-01-01 00:00:00+0100', tz='CET'),\n",
      " |             Timestamp('2000-01-02 00:00:00+0100', tz='CET')],\n",
      " |            dtype=object)\n",
      " |      \n",
      " |      Or ``dtype='datetime64[ns]'`` to return an ndarray of native\n",
      " |      datetime64 values. The values are converted to UTC and the timezone\n",
      " |      info is dropped.\n",
      " |      \n",
      " |      >>> ser.to_numpy(dtype=\"datetime64[ns]\")\n",
      " |      ... # doctest: +ELLIPSIS\n",
      " |      array(['1999-12-31T23:00:00.000000000', '2000-01-01T23:00:00...'],\n",
      " |            dtype='datetime64[ns]')\n",
      " |  \n",
      " |  tolist(self)\n",
      " |      Return a list of the values.\n",
      " |      \n",
      " |      These are each a scalar type, which is a Python scalar\n",
      " |      (for str, int, float) or a pandas scalar\n",
      " |      (for Timestamp/Timedelta/Interval/Period)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.tolist : Return the array as an a.ndim-levels deep\n",
      " |          nested list of Python scalars.\n",
      " |  \n",
      " |  transpose(self: '_T', *args, **kwargs) -> '_T'\n",
      " |      Return the transpose, which is by definition self.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      %(klass)s\n",
      " |  \n",
      " |  value_counts(self, normalize: 'bool' = False, sort: 'bool' = True, ascending: 'bool' = False, bins=None, dropna: 'bool' = True)\n",
      " |      Return a Series containing counts of unique values.\n",
      " |      \n",
      " |      The resulting object will be in descending order so that the\n",
      " |      first element is the most frequently-occurring element.\n",
      " |      Excludes NA values by default.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      normalize : bool, default False\n",
      " |          If True then the object returned will contain the relative\n",
      " |          frequencies of the unique values.\n",
      " |      sort : bool, default True\n",
      " |          Sort by frequencies.\n",
      " |      ascending : bool, default False\n",
      " |          Sort in ascending order.\n",
      " |      bins : int, optional\n",
      " |          Rather than count values, group them into half-open bins,\n",
      " |          a convenience for ``pd.cut``, only works with numeric data.\n",
      " |      dropna : bool, default True\n",
      " |          Don't include counts of NaN.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.count: Number of non-NA elements in a Series.\n",
      " |      DataFrame.count: Number of non-NA elements in a DataFrame.\n",
      " |      DataFrame.value_counts: Equivalent method on DataFrames.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> index = pd.Index([3, 1, 2, 3, 4, np.nan])\n",
      " |      >>> index.value_counts()\n",
      " |      3.0    2\n",
      " |      1.0    1\n",
      " |      2.0    1\n",
      " |      4.0    1\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      With `normalize` set to `True`, returns the relative frequency by\n",
      " |      dividing all values by the sum of values.\n",
      " |      \n",
      " |      >>> s = pd.Series([3, 1, 2, 3, 4, np.nan])\n",
      " |      >>> s.value_counts(normalize=True)\n",
      " |      3.0    0.4\n",
      " |      1.0    0.2\n",
      " |      2.0    0.2\n",
      " |      4.0    0.2\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **bins**\n",
      " |      \n",
      " |      Bins can be useful for going from a continuous variable to a\n",
      " |      categorical variable; instead of counting unique\n",
      " |      apparitions of values, divide the index in the specified\n",
      " |      number of half-open bins.\n",
      " |      \n",
      " |      >>> s.value_counts(bins=3)\n",
      " |      (0.996, 2.0]    2\n",
      " |      (2.0, 3.0]      2\n",
      " |      (3.0, 4.0]      1\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      **dropna**\n",
      " |      \n",
      " |      With `dropna` set to `False` we can also see NaN index values.\n",
      " |      \n",
      " |      >>> s.value_counts(dropna=False)\n",
      " |      3.0    2\n",
      " |      1.0    1\n",
      " |      2.0    1\n",
      " |      4.0    1\n",
      " |      NaN    1\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from pandas.core.base.IndexOpsMixin:\n",
      " |  \n",
      " |  T\n",
      " |      Return the transpose, which is by definition self.\n",
      " |  \n",
      " |  empty\n",
      " |  \n",
      " |  is_monotonic\n",
      " |      Return boolean if values in the object are\n",
      " |      monotonic_increasing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |  \n",
      " |  is_monotonic_decreasing\n",
      " |      Return boolean if values in the object are\n",
      " |      monotonic_decreasing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |  \n",
      " |  is_monotonic_increasing\n",
      " |      Alias for is_monotonic.\n",
      " |  \n",
      " |  is_unique\n",
      " |      Return boolean if values in the object are unique.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |  \n",
      " |  nbytes\n",
      " |      Return the number of bytes in the underlying data.\n",
      " |  \n",
      " |  ndim\n",
      " |      Number of dimensions of the underlying data, by definition 1.\n",
      " |  \n",
      " |  shape\n",
      " |      Return a tuple of the shape of the underlying data.\n",
      " |  \n",
      " |  size\n",
      " |      Return the number of elements in the underlying data.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pandas.core.base.IndexOpsMixin:\n",
      " |  \n",
      " |  __array_priority__ = 1000\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.arraylike.OpsMixin:\n",
      " |  \n",
      " |  __add__(self, other)\n",
      " |  \n",
      " |  __and__(self, other)\n",
      " |  \n",
      " |  __divmod__(self, other)\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __floordiv__(self, other)\n",
      " |  \n",
      " |  __ge__(self, other)\n",
      " |      Return self>=value.\n",
      " |  \n",
      " |  __gt__(self, other)\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __le__(self, other)\n",
      " |      Return self<=value.\n",
      " |  \n",
      " |  __lt__(self, other)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __mod__(self, other)\n",
      " |  \n",
      " |  __mul__(self, other)\n",
      " |  \n",
      " |  __ne__(self, other)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __or__(self, other)\n",
      " |  \n",
      " |  __pow__(self, other)\n",
      " |  \n",
      " |  __radd__(self, other)\n",
      " |  \n",
      " |  __rand__(self, other)\n",
      " |  \n",
      " |  __rdivmod__(self, other)\n",
      " |  \n",
      " |  __rfloordiv__(self, other)\n",
      " |  \n",
      " |  __rmod__(self, other)\n",
      " |  \n",
      " |  __rmul__(self, other)\n",
      " |  \n",
      " |  __ror__(self, other)\n",
      " |  \n",
      " |  __rpow__(self, other)\n",
      " |  \n",
      " |  __rsub__(self, other)\n",
      " |  \n",
      " |  __rtruediv__(self, other)\n",
      " |  \n",
      " |  __rxor__(self, other)\n",
      " |  \n",
      " |  __sub__(self, other)\n",
      " |  \n",
      " |  __truediv__(self, other)\n",
      " |  \n",
      " |  __xor__(self, other)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.arraylike.OpsMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pandas.core.arraylike.OpsMixin:\n",
      " |  \n",
      " |  __hash__ = None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  __abs__(self: 'FrameOrSeries') -> 'FrameOrSeries'\n",
      " |  \n",
      " |  __array_ufunc__(self, ufunc: 'np.ufunc', method: 'str', *inputs: 'Any', **kwargs: 'Any')\n",
      " |  \n",
      " |  __array_wrap__(self, result: 'np.ndarray', context: 'tuple[Callable, tuple[Any, ...], int] | None' = None)\n",
      " |      Gets called after a ufunc and other functions.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      result: np.ndarray\n",
      " |          The result of the ufunc or other function called on the NumPy array\n",
      " |          returned by __array__\n",
      " |      context: tuple of (func, tuple, int)\n",
      " |          This parameter is returned by ufuncs as a 3-element tuple: (name of the\n",
      " |          ufunc, arguments of the ufunc, domain of the ufunc), but is not set by\n",
      " |          other numpy functions.q\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Series implements __array_ufunc_ so this not called for ufunc on Series.\n",
      " |  \n",
      " |  __bool__ = __nonzero__(self)\n",
      " |  \n",
      " |  __contains__(self, key) -> 'bool_t'\n",
      " |      True if the key is in the info axis\n",
      " |  \n",
      " |  __copy__(self: 'FrameOrSeries', deep: 'bool_t' = True) -> 'FrameOrSeries'\n",
      " |  \n",
      " |  __deepcopy__(self: 'FrameOrSeries', memo=None) -> 'FrameOrSeries'\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      memo, default None\n",
      " |          Standard signature. Unused\n",
      " |  \n",
      " |  __delitem__(self, key) -> 'None'\n",
      " |      Delete item\n",
      " |  \n",
      " |  __finalize__(self: 'FrameOrSeries', other, method: 'str | None' = None, **kwargs) -> 'FrameOrSeries'\n",
      " |      Propagate metadata from other to self.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : the object from which to get the attributes that we are going\n",
      " |          to propagate\n",
      " |      method : str, optional\n",
      " |          A passed method name providing context on where ``__finalize__``\n",
      " |          was called.\n",
      " |      \n",
      " |          .. warning::\n",
      " |      \n",
      " |             The value passed as `method` are not currently considered\n",
      " |             stable across pandas releases.\n",
      " |  \n",
      " |  __getattr__(self, name: 'str')\n",
      " |      After regular attribute access, try looking up the name\n",
      " |      This allows simpler access to columns for interactive use.\n",
      " |  \n",
      " |  __getstate__(self) -> 'dict[str, Any]'\n",
      " |  \n",
      " |  __iadd__(self, other)\n",
      " |  \n",
      " |  __iand__(self, other)\n",
      " |  \n",
      " |  __ifloordiv__(self, other)\n",
      " |  \n",
      " |  __imod__(self, other)\n",
      " |  \n",
      " |  __imul__(self, other)\n",
      " |  \n",
      " |  __invert__(self)\n",
      " |  \n",
      " |  __ior__(self, other)\n",
      " |  \n",
      " |  __ipow__(self, other)\n",
      " |  \n",
      " |  __isub__(self, other)\n",
      " |  \n",
      " |  __itruediv__(self, other)\n",
      " |  \n",
      " |  __ixor__(self, other)\n",
      " |  \n",
      " |  __neg__(self)\n",
      " |  \n",
      " |  __nonzero__(self)\n",
      " |  \n",
      " |  __pos__(self)\n",
      " |  \n",
      " |  __round__(self: 'FrameOrSeries', decimals: 'int' = 0) -> 'FrameOrSeries'\n",
      " |  \n",
      " |  __setattr__(self, name: 'str', value) -> 'None'\n",
      " |      After regular attribute access, try setting the name\n",
      " |      This allows simpler access to columns for interactive use.\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  abs(self: 'FrameOrSeries') -> 'FrameOrSeries'\n",
      " |      Return a Series/DataFrame with absolute numeric value of each element.\n",
      " |      \n",
      " |      This function only applies to elements that are all numeric.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      abs\n",
      " |          Series/DataFrame containing the absolute value of each element.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.absolute : Calculate the absolute value element-wise.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For ``complex`` inputs, ``1.2 + 1j``, the absolute value is\n",
      " |      :math:`\\sqrt{ a^2 + b^2 }`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Absolute numeric values in a Series.\n",
      " |      \n",
      " |      >>> s = pd.Series([-1.10, 2, -3.33, 4])\n",
      " |      >>> s.abs()\n",
      " |      0    1.10\n",
      " |      1    2.00\n",
      " |      2    3.33\n",
      " |      3    4.00\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Absolute numeric values in a Series with complex numbers.\n",
      " |      \n",
      " |      >>> s = pd.Series([1.2 + 1j])\n",
      " |      >>> s.abs()\n",
      " |      0    1.56205\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Absolute numeric values in a Series with a Timedelta element.\n",
      " |      \n",
      " |      >>> s = pd.Series([pd.Timedelta('1 days')])\n",
      " |      >>> s.abs()\n",
      " |      0   1 days\n",
      " |      dtype: timedelta64[ns]\n",
      " |      \n",
      " |      Select rows with data closest to certain value using argsort (from\n",
      " |      `StackOverflow <https://stackoverflow.com/a/17758115>`__).\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'a': [4, 5, 6, 7],\n",
      " |      ...     'b': [10, 20, 30, 40],\n",
      " |      ...     'c': [100, 50, -30, -50]\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |           a    b    c\n",
      " |      0    4   10  100\n",
      " |      1    5   20   50\n",
      " |      2    6   30  -30\n",
      " |      3    7   40  -50\n",
      " |      >>> df.loc[(df.c - 43).abs().argsort()]\n",
      " |           a    b    c\n",
      " |      1    5   20   50\n",
      " |      0    4   10  100\n",
      " |      2    6   30  -30\n",
      " |      3    7   40  -50\n",
      " |  \n",
      " |  add_prefix(self: 'FrameOrSeries', prefix: 'str') -> 'FrameOrSeries'\n",
      " |      Prefix labels with string `prefix`.\n",
      " |      \n",
      " |      For Series, the row labels are prefixed.\n",
      " |      For DataFrame, the column labels are prefixed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      prefix : str\n",
      " |          The string to add before each label.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          New Series or DataFrame with updated labels.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.add_suffix: Suffix row labels with string `suffix`.\n",
      " |      DataFrame.add_suffix: Suffix column labels with string `suffix`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.add_prefix('item_')\n",
      " |      item_0    1\n",
      " |      item_1    2\n",
      " |      item_2    3\n",
      " |      item_3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3, 4], 'B': [3, 4, 5, 6]})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  1  3\n",
      " |      1  2  4\n",
      " |      2  3  5\n",
      " |      3  4  6\n",
      " |      \n",
      " |      >>> df.add_prefix('col_')\n",
      " |           col_A  col_B\n",
      " |      0       1       3\n",
      " |      1       2       4\n",
      " |      2       3       5\n",
      " |      3       4       6\n",
      " |  \n",
      " |  add_suffix(self: 'FrameOrSeries', suffix: 'str') -> 'FrameOrSeries'\n",
      " |      Suffix labels with string `suffix`.\n",
      " |      \n",
      " |      For Series, the row labels are suffixed.\n",
      " |      For DataFrame, the column labels are suffixed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      suffix : str\n",
      " |          The string to add after each label.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          New Series or DataFrame with updated labels.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.add_prefix: Prefix row labels with string `prefix`.\n",
      " |      DataFrame.add_prefix: Prefix column labels with string `prefix`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.add_suffix('_item')\n",
      " |      0_item    1\n",
      " |      1_item    2\n",
      " |      2_item    3\n",
      " |      3_item    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3, 4], 'B': [3, 4, 5, 6]})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  1  3\n",
      " |      1  2  4\n",
      " |      2  3  5\n",
      " |      3  4  6\n",
      " |      \n",
      " |      >>> df.add_suffix('_col')\n",
      " |           A_col  B_col\n",
      " |      0       1       3\n",
      " |      1       2       4\n",
      " |      2       3       5\n",
      " |      3       4       6\n",
      " |  \n",
      " |  asof(self, where, subset=None)\n",
      " |      Return the last row(s) without any NaNs before `where`.\n",
      " |      \n",
      " |      The last row (for each element in `where`, if list) without any\n",
      " |      NaN is taken.\n",
      " |      In case of a :class:`~pandas.DataFrame`, the last row without NaN\n",
      " |      considering only the subset of columns (if not `None`)\n",
      " |      \n",
      " |      If there is no good value, NaN is returned for a Series or\n",
      " |      a Series of NaN values for a DataFrame\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      where : date or array-like of dates\n",
      " |          Date(s) before which the last row(s) are returned.\n",
      " |      subset : str or array-like of str, default `None`\n",
      " |          For DataFrame, if not `None`, only use these columns to\n",
      " |          check for NaNs.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar, Series, or DataFrame\n",
      " |      \n",
      " |          The return can be:\n",
      " |      \n",
      " |          * scalar : when `self` is a Series and `where` is a scalar\n",
      " |          * Series: when `self` is a Series and `where` is an array-like,\n",
      " |            or when `self` is a DataFrame and `where` is a scalar\n",
      " |          * DataFrame : when `self` is a DataFrame and `where` is an\n",
      " |            array-like\n",
      " |      \n",
      " |          Return scalar, Series, or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      merge_asof : Perform an asof merge. Similar to left join.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Dates are assumed to be sorted. Raises if this is not the case.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      A Series and a scalar `where`.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, np.nan, 4], index=[10, 20, 30, 40])\n",
      " |      >>> s\n",
      " |      10    1.0\n",
      " |      20    2.0\n",
      " |      30    NaN\n",
      " |      40    4.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.asof(20)\n",
      " |      2.0\n",
      " |      \n",
      " |      For a sequence `where`, a Series is returned. The first value is\n",
      " |      NaN, because the first element of `where` is before the first\n",
      " |      index value.\n",
      " |      \n",
      " |      >>> s.asof([5, 20])\n",
      " |      5     NaN\n",
      " |      20    2.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Missing values are not considered. The following is ``2.0``, not\n",
      " |      NaN, even though NaN is at the index location for ``30``.\n",
      " |      \n",
      " |      >>> s.asof(30)\n",
      " |      2.0\n",
      " |      \n",
      " |      Take all columns into consideration\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'a': [10, 20, 30, 40, 50],\n",
      " |      ...                    'b': [None, None, None, None, 500]},\n",
      " |      ...                   index=pd.DatetimeIndex(['2018-02-27 09:01:00',\n",
      " |      ...                                           '2018-02-27 09:02:00',\n",
      " |      ...                                           '2018-02-27 09:03:00',\n",
      " |      ...                                           '2018-02-27 09:04:00',\n",
      " |      ...                                           '2018-02-27 09:05:00']))\n",
      " |      >>> df.asof(pd.DatetimeIndex(['2018-02-27 09:03:30',\n",
      " |      ...                           '2018-02-27 09:04:30']))\n",
      " |                            a   b\n",
      " |      2018-02-27 09:03:30 NaN NaN\n",
      " |      2018-02-27 09:04:30 NaN NaN\n",
      " |      \n",
      " |      Take a single column into consideration\n",
      " |      \n",
      " |      >>> df.asof(pd.DatetimeIndex(['2018-02-27 09:03:30',\n",
      " |      ...                           '2018-02-27 09:04:30']),\n",
      " |      ...         subset=['a'])\n",
      " |                               a   b\n",
      " |      2018-02-27 09:03:30   30.0 NaN\n",
      " |      2018-02-27 09:04:30   40.0 NaN\n",
      " |  \n",
      " |  astype(self: 'FrameOrSeries', dtype, copy: 'bool_t' = True, errors: 'str' = 'raise') -> 'FrameOrSeries'\n",
      " |      Cast a pandas object to a specified dtype ``dtype``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : data type, or dict of column name -> data type\n",
      " |          Use a numpy.dtype or Python type to cast entire pandas object to\n",
      " |          the same type. Alternatively, use {col: dtype, ...}, where col is a\n",
      " |          column label and dtype is a numpy.dtype or Python type to cast one\n",
      " |          or more of the DataFrame's columns to column-specific types.\n",
      " |      copy : bool, default True\n",
      " |          Return a copy when ``copy=True`` (be very careful setting\n",
      " |          ``copy=False`` as changes to values then may propagate to other\n",
      " |          pandas objects).\n",
      " |      errors : {'raise', 'ignore'}, default 'raise'\n",
      " |          Control raising of exceptions on invalid data for provided dtype.\n",
      " |      \n",
      " |          - ``raise`` : allow exceptions to be raised\n",
      " |          - ``ignore`` : suppress exceptions. On error return original object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      casted : same type as caller\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_datetime : Convert argument to datetime.\n",
      " |      to_timedelta : Convert argument to timedelta.\n",
      " |      to_numeric : Convert argument to a numeric type.\n",
      " |      numpy.ndarray.astype : Cast a numpy array to a specified type.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      .. deprecated:: 1.3.0\n",
      " |      \n",
      " |          Using ``astype`` to convert from timezone-naive dtype to\n",
      " |          timezone-aware dtype is deprecated and will raise in a\n",
      " |          future version.  Use :meth:`Series.dt.tz_localize` instead.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Create a DataFrame:\n",
      " |      \n",
      " |      >>> d = {'col1': [1, 2], 'col2': [3, 4]}\n",
      " |      >>> df = pd.DataFrame(data=d)\n",
      " |      >>> df.dtypes\n",
      " |      col1    int64\n",
      " |      col2    int64\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Cast all columns to int32:\n",
      " |      \n",
      " |      >>> df.astype('int32').dtypes\n",
      " |      col1    int32\n",
      " |      col2    int32\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Cast col1 to int32 using a dictionary:\n",
      " |      \n",
      " |      >>> df.astype({'col1': 'int32'}).dtypes\n",
      " |      col1    int32\n",
      " |      col2    int64\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Create a series:\n",
      " |      \n",
      " |      >>> ser = pd.Series([1, 2], dtype='int32')\n",
      " |      >>> ser\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: int32\n",
      " |      >>> ser.astype('int64')\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Convert to categorical type:\n",
      " |      \n",
      " |      >>> ser.astype('category')\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: category\n",
      " |      Categories (2, int64): [1, 2]\n",
      " |      \n",
      " |      Convert to ordered categorical type with custom ordering:\n",
      " |      \n",
      " |      >>> from pandas.api.types import CategoricalDtype\n",
      " |      >>> cat_dtype = CategoricalDtype(\n",
      " |      ...     categories=[2, 1], ordered=True)\n",
      " |      >>> ser.astype(cat_dtype)\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: category\n",
      " |      Categories (2, int64): [2 < 1]\n",
      " |      \n",
      " |      Note that using ``copy=False`` and changing data on a new\n",
      " |      pandas object may propagate changes:\n",
      " |      \n",
      " |      >>> s1 = pd.Series([1, 2])\n",
      " |      >>> s2 = s1.astype('int64', copy=False)\n",
      " |      >>> s2[0] = 10\n",
      " |      >>> s1  # note that s1[0] has changed too\n",
      " |      0    10\n",
      " |      1     2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Create a series of dates:\n",
      " |      \n",
      " |      >>> ser_date = pd.Series(pd.date_range('20200101', periods=3))\n",
      " |      >>> ser_date\n",
      " |      0   2020-01-01\n",
      " |      1   2020-01-02\n",
      " |      2   2020-01-03\n",
      " |      dtype: datetime64[ns]\n",
      " |  \n",
      " |  at_time(self: 'FrameOrSeries', time, asof: 'bool_t' = False, axis=None) -> 'FrameOrSeries'\n",
      " |      Select values at particular time of day (e.g., 9:30AM).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      time : datetime.time or str\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      between_time : Select values between particular times of the day.\n",
      " |      first : Select initial periods of time series based on a date offset.\n",
      " |      last : Select final periods of time series based on a date offset.\n",
      " |      DatetimeIndex.indexer_at_time : Get just the index locations for\n",
      " |          values at particular time of the day.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='12H')\n",
      " |      >>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n",
      " |      >>> ts\n",
      " |                           A\n",
      " |      2018-04-09 00:00:00  1\n",
      " |      2018-04-09 12:00:00  2\n",
      " |      2018-04-10 00:00:00  3\n",
      " |      2018-04-10 12:00:00  4\n",
      " |      \n",
      " |      >>> ts.at_time('12:00')\n",
      " |                           A\n",
      " |      2018-04-09 12:00:00  2\n",
      " |      2018-04-10 12:00:00  4\n",
      " |  \n",
      " |  backfill = bfill(self: 'FrameOrSeries', axis: 'None | Axis' = None, inplace: 'bool_t' = False, limit: 'None | int' = None, downcast=None) -> 'FrameOrSeries | None'\n",
      " |      Synonym for :meth:`DataFrame.fillna` with ``method='bfill'``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame or None\n",
      " |          Object with missing values filled or None if ``inplace=True``.\n",
      " |  \n",
      " |  between_time(self: 'FrameOrSeries', start_time, end_time, include_start: 'bool_t' = True, include_end: 'bool_t' = True, axis=None) -> 'FrameOrSeries'\n",
      " |      Select values between particular times of the day (e.g., 9:00-9:30 AM).\n",
      " |      \n",
      " |      By setting ``start_time`` to be later than ``end_time``,\n",
      " |      you can get the times that are *not* between the two times.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      start_time : datetime.time or str\n",
      " |          Initial time as a time filter limit.\n",
      " |      end_time : datetime.time or str\n",
      " |          End time as a time filter limit.\n",
      " |      include_start : bool, default True\n",
      " |          Whether the start time needs to be included in the result.\n",
      " |      include_end : bool, default True\n",
      " |          Whether the end time needs to be included in the result.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Determine range time on index or columns value.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Data from the original object filtered to the specified dates range.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      at_time : Select values at a particular time of the day.\n",
      " |      first : Select initial periods of time series based on a date offset.\n",
      " |      last : Select final periods of time series based on a date offset.\n",
      " |      DatetimeIndex.indexer_between_time : Get just the index locations for\n",
      " |          values between particular times of the day.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='1D20min')\n",
      " |      >>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n",
      " |      >>> ts\n",
      " |                           A\n",
      " |      2018-04-09 00:00:00  1\n",
      " |      2018-04-10 00:20:00  2\n",
      " |      2018-04-11 00:40:00  3\n",
      " |      2018-04-12 01:00:00  4\n",
      " |      \n",
      " |      >>> ts.between_time('0:15', '0:45')\n",
      " |                           A\n",
      " |      2018-04-10 00:20:00  2\n",
      " |      2018-04-11 00:40:00  3\n",
      " |      \n",
      " |      You get the times that are *not* between two times by setting\n",
      " |      ``start_time`` later than ``end_time``:\n",
      " |      \n",
      " |      >>> ts.between_time('0:45', '0:15')\n",
      " |                           A\n",
      " |      2018-04-09 00:00:00  1\n",
      " |      2018-04-12 01:00:00  4\n",
      " |  \n",
      " |  bool(self)\n",
      " |      Return the bool of a single element Series or DataFrame.\n",
      " |      \n",
      " |      This must be a boolean scalar value, either True or False. It will raise a\n",
      " |      ValueError if the Series or DataFrame does not have exactly 1 element, or that\n",
      " |      element is not boolean (integer values 0 and 1 will also raise an exception).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          The value in the Series or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.astype : Change the data type of a Series, including to boolean.\n",
      " |      DataFrame.astype : Change the data type of a DataFrame, including to boolean.\n",
      " |      numpy.bool_ : NumPy boolean data type, used by pandas for boolean values.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The method will only work for single element objects with a boolean value:\n",
      " |      \n",
      " |      >>> pd.Series([True]).bool()\n",
      " |      True\n",
      " |      >>> pd.Series([False]).bool()\n",
      " |      False\n",
      " |      \n",
      " |      >>> pd.DataFrame({'col': [True]}).bool()\n",
      " |      True\n",
      " |      >>> pd.DataFrame({'col': [False]}).bool()\n",
      " |      False\n",
      " |  \n",
      " |  convert_dtypes(self: 'FrameOrSeries', infer_objects: 'bool_t' = True, convert_string: 'bool_t' = True, convert_integer: 'bool_t' = True, convert_boolean: 'bool_t' = True, convert_floating: 'bool_t' = True) -> 'FrameOrSeries'\n",
      " |      Convert columns to best possible dtypes using dtypes supporting ``pd.NA``.\n",
      " |      \n",
      " |      .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      infer_objects : bool, default True\n",
      " |          Whether object dtypes should be converted to the best possible types.\n",
      " |      convert_string : bool, default True\n",
      " |          Whether object dtypes should be converted to ``StringDtype()``.\n",
      " |      convert_integer : bool, default True\n",
      " |          Whether, if possible, conversion can be done to integer extension types.\n",
      " |      convert_boolean : bool, defaults True\n",
      " |          Whether object dtypes should be converted to ``BooleanDtypes()``.\n",
      " |      convert_floating : bool, defaults True\n",
      " |          Whether, if possible, conversion can be done to floating extension types.\n",
      " |          If `convert_integer` is also True, preference will be give to integer\n",
      " |          dtypes if the floats can be faithfully casted to integers.\n",
      " |      \n",
      " |          .. versionadded:: 1.2.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Copy of input object with new dtype.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      infer_objects : Infer dtypes of objects.\n",
      " |      to_datetime : Convert argument to datetime.\n",
      " |      to_timedelta : Convert argument to timedelta.\n",
      " |      to_numeric : Convert argument to a numeric type.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      By default, ``convert_dtypes`` will attempt to convert a Series (or each\n",
      " |      Series in a DataFrame) to dtypes that support ``pd.NA``. By using the options\n",
      " |      ``convert_string``, ``convert_integer``, ``convert_boolean`` and\n",
      " |      ``convert_boolean``, it is possible to turn off individual conversions\n",
      " |      to ``StringDtype``, the integer extension types, ``BooleanDtype``\n",
      " |      or floating extension types, respectively.\n",
      " |      \n",
      " |      For object-dtyped columns, if ``infer_objects`` is ``True``, use the inference\n",
      " |      rules as during normal Series/DataFrame construction.  Then, if possible,\n",
      " |      convert to ``StringDtype``, ``BooleanDtype`` or an appropriate integer\n",
      " |      or floating extension type, otherwise leave as ``object``.\n",
      " |      \n",
      " |      If the dtype is integer, convert to an appropriate integer extension type.\n",
      " |      \n",
      " |      If the dtype is numeric, and consists of all integers, convert to an\n",
      " |      appropriate integer extension type. Otherwise, convert to an\n",
      " |      appropriate floating extension type.\n",
      " |      \n",
      " |      .. versionchanged:: 1.2\n",
      " |          Starting with pandas 1.2, this method also converts float columns\n",
      " |          to the nullable floating extension type.\n",
      " |      \n",
      " |      In the future, as new dtypes are added that support ``pd.NA``, the results\n",
      " |      of this method will change to support those new dtypes.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": pd.Series([1, 2, 3], dtype=np.dtype(\"int32\")),\n",
      " |      ...         \"b\": pd.Series([\"x\", \"y\", \"z\"], dtype=np.dtype(\"O\")),\n",
      " |      ...         \"c\": pd.Series([True, False, np.nan], dtype=np.dtype(\"O\")),\n",
      " |      ...         \"d\": pd.Series([\"h\", \"i\", np.nan], dtype=np.dtype(\"O\")),\n",
      " |      ...         \"e\": pd.Series([10, np.nan, 20], dtype=np.dtype(\"float\")),\n",
      " |      ...         \"f\": pd.Series([np.nan, 100.5, 200], dtype=np.dtype(\"float\")),\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      \n",
      " |      Start with a DataFrame with default dtypes.\n",
      " |      \n",
      " |      >>> df\n",
      " |         a  b      c    d     e      f\n",
      " |      0  1  x   True    h  10.0    NaN\n",
      " |      1  2  y  False    i   NaN  100.5\n",
      " |      2  3  z    NaN  NaN  20.0  200.0\n",
      " |      \n",
      " |      >>> df.dtypes\n",
      " |      a      int32\n",
      " |      b     object\n",
      " |      c     object\n",
      " |      d     object\n",
      " |      e    float64\n",
      " |      f    float64\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Convert the DataFrame to use best possible dtypes.\n",
      " |      \n",
      " |      >>> dfn = df.convert_dtypes()\n",
      " |      >>> dfn\n",
      " |         a  b      c     d     e      f\n",
      " |      0  1  x   True     h    10   <NA>\n",
      " |      1  2  y  False     i  <NA>  100.5\n",
      " |      2  3  z   <NA>  <NA>    20  200.0\n",
      " |      \n",
      " |      >>> dfn.dtypes\n",
      " |      a      Int32\n",
      " |      b     string\n",
      " |      c    boolean\n",
      " |      d     string\n",
      " |      e      Int64\n",
      " |      f    Float64\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Start with a Series of strings and missing data represented by ``np.nan``.\n",
      " |      \n",
      " |      >>> s = pd.Series([\"a\", \"b\", np.nan])\n",
      " |      >>> s\n",
      " |      0      a\n",
      " |      1      b\n",
      " |      2    NaN\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Obtain a Series with dtype ``StringDtype``.\n",
      " |      \n",
      " |      >>> s.convert_dtypes()\n",
      " |      0       a\n",
      " |      1       b\n",
      " |      2    <NA>\n",
      " |      dtype: string\n",
      " |  \n",
      " |  copy(self: 'FrameOrSeries', deep: 'bool_t' = True) -> 'FrameOrSeries'\n",
      " |      Make a copy of this object's indices and data.\n",
      " |      \n",
      " |      When ``deep=True`` (default), a new object will be created with a\n",
      " |      copy of the calling object's data and indices. Modifications to\n",
      " |      the data or indices of the copy will not be reflected in the\n",
      " |      original object (see notes below).\n",
      " |      \n",
      " |      When ``deep=False``, a new object will be created without copying\n",
      " |      the calling object's data or index (only references to the data\n",
      " |      and index are copied). Any changes to the data of the original\n",
      " |      will be reflected in the shallow copy (and vice versa).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default True\n",
      " |          Make a deep copy, including a copy of the data and the indices.\n",
      " |          With ``deep=False`` neither the indices nor the data are copied.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      copy : Series or DataFrame\n",
      " |          Object type matches caller.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      When ``deep=True``, data is copied but actual Python objects\n",
      " |      will not be copied recursively, only the reference to the object.\n",
      " |      This is in contrast to `copy.deepcopy` in the Standard Library,\n",
      " |      which recursively copies object data (see examples below).\n",
      " |      \n",
      " |      While ``Index`` objects are copied when ``deep=True``, the underlying\n",
      " |      numpy array is not copied for performance reasons. Since ``Index`` is\n",
      " |      immutable, the underlying data can be safely shared and a copy\n",
      " |      is not needed.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2], index=[\"a\", \"b\"])\n",
      " |      >>> s\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s_copy = s.copy()\n",
      " |      >>> s_copy\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      **Shallow copy versus default (deep) copy:**\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2], index=[\"a\", \"b\"])\n",
      " |      >>> deep = s.copy()\n",
      " |      >>> shallow = s.copy(deep=False)\n",
      " |      \n",
      " |      Shallow copy shares data and index with original.\n",
      " |      \n",
      " |      >>> s is shallow\n",
      " |      False\n",
      " |      >>> s.values is shallow.values and s.index is shallow.index\n",
      " |      True\n",
      " |      \n",
      " |      Deep copy has own copy of data and index.\n",
      " |      \n",
      " |      >>> s is deep\n",
      " |      False\n",
      " |      >>> s.values is deep.values or s.index is deep.index\n",
      " |      False\n",
      " |      \n",
      " |      Updates to the data shared by shallow copy and original is reflected\n",
      " |      in both; deep copy remains unchanged.\n",
      " |      \n",
      " |      >>> s[0] = 3\n",
      " |      >>> shallow[1] = 4\n",
      " |      >>> s\n",
      " |      a    3\n",
      " |      b    4\n",
      " |      dtype: int64\n",
      " |      >>> shallow\n",
      " |      a    3\n",
      " |      b    4\n",
      " |      dtype: int64\n",
      " |      >>> deep\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Note that when copying an object containing Python objects, a deep copy\n",
      " |      will copy the data, but will not do so recursively. Updating a nested\n",
      " |      data object will be reflected in the deep copy.\n",
      " |      \n",
      " |      >>> s = pd.Series([[1, 2], [3, 4]])\n",
      " |      >>> deep = s.copy()\n",
      " |      >>> s[0][0] = 10\n",
      " |      >>> s\n",
      " |      0    [10, 2]\n",
      " |      1     [3, 4]\n",
      " |      dtype: object\n",
      " |      >>> deep\n",
      " |      0    [10, 2]\n",
      " |      1     [3, 4]\n",
      " |      dtype: object\n",
      " |  \n",
      " |  describe(self: 'FrameOrSeries', percentiles=None, include=None, exclude=None, datetime_is_numeric=False) -> 'FrameOrSeries'\n",
      " |      Generate descriptive statistics.\n",
      " |      \n",
      " |      Descriptive statistics include those that summarize the central\n",
      " |      tendency, dispersion and shape of a\n",
      " |      dataset's distribution, excluding ``NaN`` values.\n",
      " |      \n",
      " |      Analyzes both numeric and object series, as well\n",
      " |      as ``DataFrame`` column sets of mixed data types. The output\n",
      " |      will vary depending on what is provided. Refer to the notes\n",
      " |      below for more detail.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      percentiles : list-like of numbers, optional\n",
      " |          The percentiles to include in the output. All should\n",
      " |          fall between 0 and 1. The default is\n",
      " |          ``[.25, .5, .75]``, which returns the 25th, 50th, and\n",
      " |          75th percentiles.\n",
      " |      include : 'all', list-like of dtypes or None (default), optional\n",
      " |          A white list of data types to include in the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |      \n",
      " |          - 'all' : All columns of the input will be included in the output.\n",
      " |          - A list-like of dtypes : Limits the results to the\n",
      " |            provided data types.\n",
      " |            To limit the result to numeric types submit\n",
      " |            ``numpy.number``. To limit it instead to object columns submit\n",
      " |            the ``numpy.object`` data type. Strings\n",
      " |            can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      " |            select pandas categorical columns, use ``'category'``\n",
      " |          - None (default) : The result will include all numeric columns.\n",
      " |      exclude : list-like of dtypes or None (default), optional,\n",
      " |          A black list of data types to omit from the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |      \n",
      " |          - A list-like of dtypes : Excludes the provided data types\n",
      " |            from the result. To exclude numeric types submit\n",
      " |            ``numpy.number``. To exclude object columns submit the data\n",
      " |            type ``numpy.object``. Strings can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      " |            exclude pandas categorical columns, use ``'category'``\n",
      " |          - None (default) : The result will exclude nothing.\n",
      " |      datetime_is_numeric : bool, default False\n",
      " |          Whether to treat datetime dtypes as numeric. This affects statistics\n",
      " |          calculated for the column. For DataFrame input, this also\n",
      " |          controls whether datetime columns are included by default.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Summary statistics of the Series or Dataframe provided.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.count: Count number of non-NA/null observations.\n",
      " |      DataFrame.max: Maximum of the values in the object.\n",
      " |      DataFrame.min: Minimum of the values in the object.\n",
      " |      DataFrame.mean: Mean of the values.\n",
      " |      DataFrame.std: Standard deviation of the observations.\n",
      " |      DataFrame.select_dtypes: Subset of a DataFrame including/excluding\n",
      " |          columns based on their dtype.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For numeric data, the result's index will include ``count``,\n",
      " |      ``mean``, ``std``, ``min``, ``max`` as well as lower, ``50`` and\n",
      " |      upper percentiles. By default the lower percentile is ``25`` and the\n",
      " |      upper percentile is ``75``. The ``50`` percentile is the\n",
      " |      same as the median.\n",
      " |      \n",
      " |      For object data (e.g. strings or timestamps), the result's index\n",
      " |      will include ``count``, ``unique``, ``top``, and ``freq``. The ``top``\n",
      " |      is the most common value. The ``freq`` is the most common value's\n",
      " |      frequency. Timestamps also include the ``first`` and ``last`` items.\n",
      " |      \n",
      " |      If multiple object values have the highest count, then the\n",
      " |      ``count`` and ``top`` results will be arbitrarily chosen from\n",
      " |      among those with the highest count.\n",
      " |      \n",
      " |      For mixed data types provided via a ``DataFrame``, the default is to\n",
      " |      return only an analysis of numeric columns. If the dataframe consists\n",
      " |      only of object and categorical data without any numeric columns, the\n",
      " |      default is to return an analysis of both the object and categorical\n",
      " |      columns. If ``include='all'`` is provided as an option, the result\n",
      " |      will include a union of attributes of each type.\n",
      " |      \n",
      " |      The `include` and `exclude` parameters can be used to limit\n",
      " |      which columns in a ``DataFrame`` are analyzed for the output.\n",
      " |      The parameters are ignored when analyzing a ``Series``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Describing a numeric ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Describing a categorical ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series(['a', 'a', 'b', 'c'])\n",
      " |      >>> s.describe()\n",
      " |      count     4\n",
      " |      unique    3\n",
      " |      top       a\n",
      " |      freq      2\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Describing a timestamp ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series([\n",
      " |      ...   np.datetime64(\"2000-01-01\"),\n",
      " |      ...   np.datetime64(\"2010-01-01\"),\n",
      " |      ...   np.datetime64(\"2010-01-01\")\n",
      " |      ... ])\n",
      " |      >>> s.describe(datetime_is_numeric=True)\n",
      " |      count                      3\n",
      " |      mean     2006-09-01 08:00:00\n",
      " |      min      2000-01-01 00:00:00\n",
      " |      25%      2004-12-31 12:00:00\n",
      " |      50%      2010-01-01 00:00:00\n",
      " |      75%      2010-01-01 00:00:00\n",
      " |      max      2010-01-01 00:00:00\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Describing a ``DataFrame``. By default only numeric fields\n",
      " |      are returned.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'categorical': pd.Categorical(['d','e','f']),\n",
      " |      ...                    'numeric': [1, 2, 3],\n",
      " |      ...                    'object': ['a', 'b', 'c']\n",
      " |      ...                   })\n",
      " |      >>> df.describe()\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |      \n",
      " |      Describing all columns of a ``DataFrame`` regardless of data type.\n",
      " |      \n",
      " |      >>> df.describe(include='all')  # doctest: +SKIP\n",
      " |             categorical  numeric object\n",
      " |      count            3      3.0      3\n",
      " |      unique           3      NaN      3\n",
      " |      top              f      NaN      a\n",
      " |      freq             1      NaN      1\n",
      " |      mean           NaN      2.0    NaN\n",
      " |      std            NaN      1.0    NaN\n",
      " |      min            NaN      1.0    NaN\n",
      " |      25%            NaN      1.5    NaN\n",
      " |      50%            NaN      2.0    NaN\n",
      " |      75%            NaN      2.5    NaN\n",
      " |      max            NaN      3.0    NaN\n",
      " |      \n",
      " |      Describing a column from a ``DataFrame`` by accessing it as\n",
      " |      an attribute.\n",
      " |      \n",
      " |      >>> df.numeric.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      Name: numeric, dtype: float64\n",
      " |      \n",
      " |      Including only numeric columns in a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=[np.number])\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |      \n",
      " |      Including only string columns in a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=[object])  # doctest: +SKIP\n",
      " |             object\n",
      " |      count       3\n",
      " |      unique      3\n",
      " |      top         a\n",
      " |      freq        1\n",
      " |      \n",
      " |      Including only categorical columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=['category'])\n",
      " |             categorical\n",
      " |      count            3\n",
      " |      unique           3\n",
      " |      top              d\n",
      " |      freq             1\n",
      " |      \n",
      " |      Excluding numeric columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(exclude=[np.number])  # doctest: +SKIP\n",
      " |             categorical object\n",
      " |      count            3      3\n",
      " |      unique           3      3\n",
      " |      top              f      a\n",
      " |      freq             1      1\n",
      " |      \n",
      " |      Excluding object columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(exclude=[object])  # doctest: +SKIP\n",
      " |             categorical  numeric\n",
      " |      count            3      3.0\n",
      " |      unique           3      NaN\n",
      " |      top              f      NaN\n",
      " |      freq             1      NaN\n",
      " |      mean           NaN      2.0\n",
      " |      std            NaN      1.0\n",
      " |      min            NaN      1.0\n",
      " |      25%            NaN      1.5\n",
      " |      50%            NaN      2.0\n",
      " |      75%            NaN      2.5\n",
      " |      max            NaN      3.0\n",
      " |  \n",
      " |  droplevel(self: 'FrameOrSeries', level, axis=0) -> 'FrameOrSeries'\n",
      " |      Return Series/DataFrame with requested index / column level(s) removed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, str, or list-like\n",
      " |          If a string is given, must be the name of a level\n",
      " |          If list-like, elements must be names or positional indexes\n",
      " |          of levels.\n",
      " |      \n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Axis along which the level(s) is removed:\n",
      " |      \n",
      " |          * 0 or 'index': remove level(s) in column.\n",
      " |          * 1 or 'columns': remove level(s) in row.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame\n",
      " |          Series/DataFrame with requested index / column level(s) removed.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([\n",
      " |      ...     [1, 2, 3, 4],\n",
      " |      ...     [5, 6, 7, 8],\n",
      " |      ...     [9, 10, 11, 12]\n",
      " |      ... ]).set_index([0, 1]).rename_axis(['a', 'b'])\n",
      " |      \n",
      " |      >>> df.columns = pd.MultiIndex.from_tuples([\n",
      " |      ...     ('c', 'e'), ('d', 'f')\n",
      " |      ... ], names=['level_1', 'level_2'])\n",
      " |      \n",
      " |      >>> df\n",
      " |      level_1   c   d\n",
      " |      level_2   e   f\n",
      " |      a b\n",
      " |      1 2      3   4\n",
      " |      5 6      7   8\n",
      " |      9 10    11  12\n",
      " |      \n",
      " |      >>> df.droplevel('a')\n",
      " |      level_1   c   d\n",
      " |      level_2   e   f\n",
      " |      b\n",
      " |      2        3   4\n",
      " |      6        7   8\n",
      " |      10      11  12\n",
      " |      \n",
      " |      >>> df.droplevel('level_2', axis=1)\n",
      " |      level_1   c   d\n",
      " |      a b\n",
      " |      1 2      3   4\n",
      " |      5 6      7   8\n",
      " |      9 10    11  12\n",
      " |  \n",
      " |  equals(self, other: 'object') -> 'bool_t'\n",
      " |      Test whether two objects contain the same elements.\n",
      " |      \n",
      " |      This function allows two Series or DataFrames to be compared against\n",
      " |      each other to see if they have the same shape and elements. NaNs in\n",
      " |      the same location are considered equal.\n",
      " |      \n",
      " |      The row/column index do not need to have the same type, as long\n",
      " |      as the values are considered equal. Corresponding columns must be of\n",
      " |      the same dtype.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or DataFrame\n",
      " |          The other Series or DataFrame to be compared with the first.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          True if all elements are the same in both objects, False\n",
      " |          otherwise.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.eq : Compare two Series objects of the same length\n",
      " |          and return a Series where each element is True if the element\n",
      " |          in each Series is equal, False otherwise.\n",
      " |      DataFrame.eq : Compare two DataFrame objects of the same shape and\n",
      " |          return a DataFrame where each element is True if the respective\n",
      " |          element in each DataFrame is equal, False otherwise.\n",
      " |      testing.assert_series_equal : Raises an AssertionError if left and\n",
      " |          right are not equal. Provides an easy interface to ignore\n",
      " |          inequality in dtypes, indexes and precision among others.\n",
      " |      testing.assert_frame_equal : Like assert_series_equal, but targets\n",
      " |          DataFrames.\n",
      " |      numpy.array_equal : Return True if two arrays have the same shape\n",
      " |          and elements, False otherwise.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({1: [10], 2: [20]})\n",
      " |      >>> df\n",
      " |          1   2\n",
      " |      0  10  20\n",
      " |      \n",
      " |      DataFrames df and exactly_equal have the same types and values for\n",
      " |      their elements and column labels, which will return True.\n",
      " |      \n",
      " |      >>> exactly_equal = pd.DataFrame({1: [10], 2: [20]})\n",
      " |      >>> exactly_equal\n",
      " |          1   2\n",
      " |      0  10  20\n",
      " |      >>> df.equals(exactly_equal)\n",
      " |      True\n",
      " |      \n",
      " |      DataFrames df and different_column_type have the same element\n",
      " |      types and values, but have different types for the column labels,\n",
      " |      which will still return True.\n",
      " |      \n",
      " |      >>> different_column_type = pd.DataFrame({1.0: [10], 2.0: [20]})\n",
      " |      >>> different_column_type\n",
      " |         1.0  2.0\n",
      " |      0   10   20\n",
      " |      >>> df.equals(different_column_type)\n",
      " |      True\n",
      " |      \n",
      " |      DataFrames df and different_data_type have different types for the\n",
      " |      same values for their elements, and will return False even though\n",
      " |      their column labels are the same values and types.\n",
      " |      \n",
      " |      >>> different_data_type = pd.DataFrame({1: [10.0], 2: [20.0]})\n",
      " |      >>> different_data_type\n",
      " |            1     2\n",
      " |      0  10.0  20.0\n",
      " |      >>> df.equals(different_data_type)\n",
      " |      False\n",
      " |  \n",
      " |  ewm(self, com: 'float | None' = None, span: 'float | None' = None, halflife: 'float | TimedeltaConvertibleTypes | None' = None, alpha: 'float | None' = None, min_periods: 'int | None' = 0, adjust: 'bool_t' = True, ignore_na: 'bool_t' = False, axis: 'Axis' = 0, times: 'str | np.ndarray | FrameOrSeries | None' = None) -> 'ExponentialMovingWindow'\n",
      " |      Provide exponential weighted (EW) functions.\n",
      " |      \n",
      " |      Available EW functions: ``mean()``, ``var()``, ``std()``, ``corr()``, ``cov()``.\n",
      " |      \n",
      " |      Exactly one parameter: ``com``, ``span``, ``halflife``, or ``alpha`` must be\n",
      " |      provided.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      com : float, optional\n",
      " |          Specify decay in terms of center of mass,\n",
      " |          :math:`\\alpha = 1 / (1 + com)`, for :math:`com \\geq 0`.\n",
      " |      span : float, optional\n",
      " |          Specify decay in terms of span,\n",
      " |          :math:`\\alpha = 2 / (span + 1)`, for :math:`span \\geq 1`.\n",
      " |      halflife : float, str, timedelta, optional\n",
      " |          Specify decay in terms of half-life,\n",
      " |          :math:`\\alpha = 1 - \\exp\\left(-\\ln(2) / halflife\\right)`, for\n",
      " |          :math:`halflife > 0`.\n",
      " |      \n",
      " |          If ``times`` is specified, the time unit (str or timedelta) over which an\n",
      " |          observation decays to half its value. Only applicable to ``mean()``\n",
      " |          and halflife value will not apply to the other functions.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      alpha : float, optional\n",
      " |          Specify smoothing factor :math:`\\alpha` directly,\n",
      " |          :math:`0 < \\alpha \\leq 1`.\n",
      " |      min_periods : int, default 0\n",
      " |          Minimum number of observations in window required to have a value\n",
      " |          (otherwise result is NA).\n",
      " |      adjust : bool, default True\n",
      " |          Divide by decaying adjustment factor in beginning periods to account\n",
      " |          for imbalance in relative weightings (viewing EWMA as a moving average).\n",
      " |      \n",
      " |          - When ``adjust=True`` (default), the EW function is calculated using weights\n",
      " |            :math:`w_i = (1 - \\alpha)^i`. For example, the EW moving average of the series\n",
      " |            [:math:`x_0, x_1, ..., x_t`] would be:\n",
      " |      \n",
      " |          .. math::\n",
      " |              y_t = \\frac{x_t + (1 - \\alpha)x_{t-1} + (1 - \\alpha)^2 x_{t-2} + ... + (1 -\n",
      " |              \\alpha)^t x_0}{1 + (1 - \\alpha) + (1 - \\alpha)^2 + ... + (1 - \\alpha)^t}\n",
      " |      \n",
      " |          - When ``adjust=False``, the exponentially weighted function is calculated\n",
      " |            recursively:\n",
      " |      \n",
      " |          .. math::\n",
      " |              \\begin{split}\n",
      " |                  y_0 &= x_0\\\\\n",
      " |                  y_t &= (1 - \\alpha) y_{t-1} + \\alpha x_t,\n",
      " |              \\end{split}\n",
      " |      ignore_na : bool, default False\n",
      " |          Ignore missing values when calculating weights; specify ``True`` to reproduce\n",
      " |          pre-0.15.0 behavior.\n",
      " |      \n",
      " |          - When ``ignore_na=False`` (default), weights are based on absolute positions.\n",
      " |            For example, the weights of :math:`x_0` and :math:`x_2` used in calculating\n",
      " |            the final weighted average of [:math:`x_0`, None, :math:`x_2`] are\n",
      " |            :math:`(1-\\alpha)^2` and :math:`1` if ``adjust=True``, and\n",
      " |            :math:`(1-\\alpha)^2` and :math:`\\alpha` if ``adjust=False``.\n",
      " |      \n",
      " |          - When ``ignore_na=True`` (reproducing pre-0.15.0 behavior), weights are based\n",
      " |            on relative positions. For example, the weights of :math:`x_0` and :math:`x_2`\n",
      " |            used in calculating the final weighted average of\n",
      " |            [:math:`x_0`, None, :math:`x_2`] are :math:`1-\\alpha` and :math:`1` if\n",
      " |            ``adjust=True``, and :math:`1-\\alpha` and :math:`\\alpha` if ``adjust=False``.\n",
      " |      axis : {0, 1}, default 0\n",
      " |          The axis to use. The value 0 identifies the rows, and 1\n",
      " |          identifies the columns.\n",
      " |      times : str, np.ndarray, Series, default None\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |          Times corresponding to the observations. Must be monotonically increasing and\n",
      " |          ``datetime64[ns]`` dtype.\n",
      " |      \n",
      " |          If str, the name of the column in the DataFrame representing the times.\n",
      " |      \n",
      " |          If 1-D array like, a sequence with the same shape as the observations.\n",
      " |      \n",
      " |          Only applicable to ``mean()``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          A Window sub-classed for the particular operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      rolling : Provides rolling window calculations.\n",
      " |      expanding : Provides expanding transformations.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      \n",
      " |      More details can be found at:\n",
      " |      :ref:`Exponentially weighted windows <window.exponentially_weighted>`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      " |      >>> df\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |      \n",
      " |      >>> df.ewm(com=0.5).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.750000\n",
      " |      2  1.615385\n",
      " |      3  1.615385\n",
      " |      4  3.670213\n",
      " |      \n",
      " |      Specifying ``times`` with a timedelta ``halflife`` when computing mean.\n",
      " |      \n",
      " |      >>> times = ['2020-01-01', '2020-01-03', '2020-01-10', '2020-01-15', '2020-01-17']\n",
      " |      >>> df.ewm(halflife='4 days', times=pd.DatetimeIndex(times)).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.585786\n",
      " |      2  1.523889\n",
      " |      3  1.523889\n",
      " |      4  3.233686\n",
      " |  \n",
      " |  expanding(self, min_periods: 'int' = 1, center: 'bool_t | None' = None, axis: 'Axis' = 0, method: 'str' = 'single') -> 'Expanding'\n",
      " |      Provide expanding transformations.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      min_periods : int, default 1\n",
      " |          Minimum number of observations in window required to have a value\n",
      " |          (otherwise result is NA).\n",
      " |      center : bool, default False\n",
      " |          Set the labels at the center of the window.\n",
      " |      axis : int or str, default 0\n",
      " |      method : str {'single', 'table'}, default 'single'\n",
      " |          Execute the rolling operation per single column or row (``'single'``)\n",
      " |          or over the entire object (``'table'``).\n",
      " |      \n",
      " |          This argument is only implemented when specifying ``engine='numba'``\n",
      " |          in the method call.\n",
      " |      \n",
      " |          .. versionadded:: 1.3.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      a Window sub-classed for the particular operation\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      rolling : Provides rolling window calculations.\n",
      " |      ewm : Provides exponential weighted functions.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      By default, the result is set to the right edge of the window. This can be\n",
      " |      changed to the center of the window by setting ``center=True``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"B\": [0, 1, 2, np.nan, 4]})\n",
      " |      >>> df\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |      \n",
      " |      >>> df.expanding(2).sum()\n",
      " |           B\n",
      " |      0  NaN\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  3.0\n",
      " |      4  7.0\n",
      " |  \n",
      " |  filter(self: 'FrameOrSeries', items=None, like: 'str | None' = None, regex: 'str | None' = None, axis=None) -> 'FrameOrSeries'\n",
      " |      Subset the dataframe rows or columns according to the specified index labels.\n",
      " |      \n",
      " |      Note that this routine does not filter a dataframe on its\n",
      " |      contents. The filter is applied to the labels of the index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      items : list-like\n",
      " |          Keep labels from axis which are in items.\n",
      " |      like : str\n",
      " |          Keep labels from axis for which \"like in label == True\".\n",
      " |      regex : str (regular expression)\n",
      " |          Keep labels from axis for which re.search(regex, label) == True.\n",
      " |      axis : {0 or ‘index’, 1 or ‘columns’, None}, default None\n",
      " |          The axis to filter on, expressed either as an index (int)\n",
      " |          or axis name (str). By default this is the info axis,\n",
      " |          'index' for Series, 'columns' for DataFrame.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as input object\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Access a group of rows and columns\n",
      " |          by label(s) or a boolean array.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The ``items``, ``like``, and ``regex`` parameters are\n",
      " |      enforced to be mutually exclusive.\n",
      " |      \n",
      " |      ``axis`` defaults to the info axis that is used when indexing\n",
      " |      with ``[]``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(np.array(([1, 2, 3], [4, 5, 6])),\n",
      " |      ...                   index=['mouse', 'rabbit'],\n",
      " |      ...                   columns=['one', 'two', 'three'])\n",
      " |      >>> df\n",
      " |              one  two  three\n",
      " |      mouse     1    2      3\n",
      " |      rabbit    4    5      6\n",
      " |      \n",
      " |      >>> # select columns by name\n",
      " |      >>> df.filter(items=['one', 'three'])\n",
      " |               one  three\n",
      " |      mouse     1      3\n",
      " |      rabbit    4      6\n",
      " |      \n",
      " |      >>> # select columns by regular expression\n",
      " |      >>> df.filter(regex='e$', axis=1)\n",
      " |               one  three\n",
      " |      mouse     1      3\n",
      " |      rabbit    4      6\n",
      " |      \n",
      " |      >>> # select rows containing 'bbi'\n",
      " |      >>> df.filter(like='bbi', axis=0)\n",
      " |               one  two  three\n",
      " |      rabbit    4    5      6\n",
      " |  \n",
      " |  first(self: 'FrameOrSeries', offset) -> 'FrameOrSeries'\n",
      " |      Select initial periods of time series data based on a date offset.\n",
      " |      \n",
      " |      When having a DataFrame with dates as index, this function can\n",
      " |      select the first few rows based on a date offset.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      offset : str, DateOffset or dateutil.relativedelta\n",
      " |          The offset length of the data that will be selected. For instance,\n",
      " |          '1M' will display all the rows having their index within the first month.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          A subset of the caller.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      last : Select final periods of time series based on a date offset.\n",
      " |      at_time : Select values at a particular time of the day.\n",
      " |      between_time : Select values between particular times of the day.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='2D')\n",
      " |      >>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n",
      " |      >>> ts\n",
      " |                  A\n",
      " |      2018-04-09  1\n",
      " |      2018-04-11  2\n",
      " |      2018-04-13  3\n",
      " |      2018-04-15  4\n",
      " |      \n",
      " |      Get the rows for the first 3 days:\n",
      " |      \n",
      " |      >>> ts.first('3D')\n",
      " |                  A\n",
      " |      2018-04-09  1\n",
      " |      2018-04-11  2\n",
      " |      \n",
      " |      Notice the data for 3 first calendar days were returned, not the first\n",
      " |      3 days observed in the dataset, and therefore data for 2018-04-13 was\n",
      " |      not returned.\n",
      " |  \n",
      " |  first_valid_index(self) -> 'Hashable | None'\n",
      " |      Return index for first non-NA value or None, if no NA value is found.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar : type of index\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If all elements are non-NA/null, returns None.\n",
      " |      Also returns None for empty Series/DataFrame.\n",
      " |  \n",
      " |  get(self, key, default=None)\n",
      " |      Get item from object for given key (ex: DataFrame column).\n",
      " |      \n",
      " |      Returns default value if not found.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : object\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      value : same type as items contained in object\n",
      " |  \n",
      " |  head(self: 'FrameOrSeries', n: 'int' = 5) -> 'FrameOrSeries'\n",
      " |      Return the first `n` rows.\n",
      " |      \n",
      " |      This function returns the first `n` rows for the object based\n",
      " |      on position. It is useful for quickly testing if your object\n",
      " |      has the right type of data in it.\n",
      " |      \n",
      " |      For negative values of `n`, this function returns all rows except\n",
      " |      the last `n` rows, equivalent to ``df[:-n]``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, default 5\n",
      " |          Number of rows to select.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as caller\n",
      " |          The first `n` rows of the caller object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.tail: Returns the last `n` rows.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',\n",
      " |      ...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n",
      " |      >>> df\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      5     parrot\n",
      " |      6      shark\n",
      " |      7      whale\n",
      " |      8      zebra\n",
      " |      \n",
      " |      Viewing the first 5 lines\n",
      " |      \n",
      " |      >>> df.head()\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      \n",
      " |      Viewing the first `n` lines (three in this case)\n",
      " |      \n",
      " |      >>> df.head(3)\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      \n",
      " |      For negative values of `n`\n",
      " |      \n",
      " |      >>> df.head(-3)\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      5     parrot\n",
      " |  \n",
      " |  infer_objects(self: 'FrameOrSeries') -> 'FrameOrSeries'\n",
      " |      Attempt to infer better dtypes for object columns.\n",
      " |      \n",
      " |      Attempts soft conversion of object-dtyped\n",
      " |      columns, leaving non-object and unconvertible\n",
      " |      columns unchanged. The inference rules are the\n",
      " |      same as during normal Series/DataFrame construction.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      converted : same type as input object\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_datetime : Convert argument to datetime.\n",
      " |      to_timedelta : Convert argument to timedelta.\n",
      " |      to_numeric : Convert argument to numeric type.\n",
      " |      convert_dtypes : Convert argument to best possible dtype.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"A\": [\"a\", 1, 2, 3]})\n",
      " |      >>> df = df.iloc[1:]\n",
      " |      >>> df\n",
      " |         A\n",
      " |      1  1\n",
      " |      2  2\n",
      " |      3  3\n",
      " |      \n",
      " |      >>> df.dtypes\n",
      " |      A    object\n",
      " |      dtype: object\n",
      " |      \n",
      " |      >>> df.infer_objects().dtypes\n",
      " |      A    int64\n",
      " |      dtype: object\n",
      " |  \n",
      " |  last(self: 'FrameOrSeries', offset) -> 'FrameOrSeries'\n",
      " |      Select final periods of time series data based on a date offset.\n",
      " |      \n",
      " |      For a DataFrame with a sorted DatetimeIndex, this function\n",
      " |      selects the last few rows based on a date offset.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      offset : str, DateOffset, dateutil.relativedelta\n",
      " |          The offset length of the data that will be selected. For instance,\n",
      " |          '3D' will display all the rows having their index within the last 3 days.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          A subset of the caller.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      first : Select initial periods of time series based on a date offset.\n",
      " |      at_time : Select values at a particular time of the day.\n",
      " |      between_time : Select values between particular times of the day.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='2D')\n",
      " |      >>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n",
      " |      >>> ts\n",
      " |                  A\n",
      " |      2018-04-09  1\n",
      " |      2018-04-11  2\n",
      " |      2018-04-13  3\n",
      " |      2018-04-15  4\n",
      " |      \n",
      " |      Get the rows for the last 3 days:\n",
      " |      \n",
      " |      >>> ts.last('3D')\n",
      " |                  A\n",
      " |      2018-04-13  3\n",
      " |      2018-04-15  4\n",
      " |      \n",
      " |      Notice the data for 3 last calendar days were returned, not the last\n",
      " |      3 observed days in the dataset, and therefore data for 2018-04-11 was\n",
      " |      not returned.\n",
      " |  \n",
      " |  last_valid_index(self) -> 'Hashable | None'\n",
      " |      Return index for last non-NA value or None, if no NA value is found.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar : type of index\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If all elements are non-NA/null, returns None.\n",
      " |      Also returns None for empty Series/DataFrame.\n",
      " |  \n",
      " |  pad = ffill(self: 'FrameOrSeries', axis: 'None | Axis' = None, inplace: 'bool_t' = False, limit: 'None | int' = None, downcast=None) -> 'FrameOrSeries | None'\n",
      " |      Synonym for :meth:`DataFrame.fillna` with ``method='ffill'``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame or None\n",
      " |          Object with missing values filled or None if ``inplace=True``.\n",
      " |  \n",
      " |  pct_change(self: 'FrameOrSeries', periods=1, fill_method='pad', limit=None, freq=None, **kwargs) -> 'FrameOrSeries'\n",
      " |      Percentage change between the current and a prior element.\n",
      " |      \n",
      " |      Computes the percentage change from the immediately previous row by\n",
      " |      default. This is useful in comparing the percentage of change in a time\n",
      " |      series of elements.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for forming percent change.\n",
      " |      fill_method : str, default 'pad'\n",
      " |          How to handle NAs before computing percent changes.\n",
      " |      limit : int, default None\n",
      " |          The number of consecutive NAs to fill before stopping.\n",
      " |      freq : DateOffset, timedelta, or str, optional\n",
      " |          Increment to use from time series API (e.g. 'M' or BDay()).\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments are passed into\n",
      " |          `DataFrame.shift` or `Series.shift`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      chg : Series or DataFrame\n",
      " |          The same type as the calling object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.diff : Compute the difference of two elements in a Series.\n",
      " |      DataFrame.diff : Compute the difference of two elements in a DataFrame.\n",
      " |      Series.shift : Shift the index by some number of periods.\n",
      " |      DataFrame.shift : Shift the index by some number of periods.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([90, 91, 85])\n",
      " |      >>> s\n",
      " |      0    90\n",
      " |      1    91\n",
      " |      2    85\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.pct_change()\n",
      " |      0         NaN\n",
      " |      1    0.011111\n",
      " |      2   -0.065934\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.pct_change(periods=2)\n",
      " |      0         NaN\n",
      " |      1         NaN\n",
      " |      2   -0.055556\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See the percentage change in a Series where filling NAs with last\n",
      " |      valid observation forward to next valid.\n",
      " |      \n",
      " |      >>> s = pd.Series([90, 91, None, 85])\n",
      " |      >>> s\n",
      " |      0    90.0\n",
      " |      1    91.0\n",
      " |      2     NaN\n",
      " |      3    85.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.pct_change(fill_method='ffill')\n",
      " |      0         NaN\n",
      " |      1    0.011111\n",
      " |      2    0.000000\n",
      " |      3   -0.065934\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      Percentage change in French franc, Deutsche Mark, and Italian lira from\n",
      " |      1980-01-01 to 1980-03-01.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'FR': [4.0405, 4.0963, 4.3149],\n",
      " |      ...     'GR': [1.7246, 1.7482, 1.8519],\n",
      " |      ...     'IT': [804.74, 810.01, 860.13]},\n",
      " |      ...     index=['1980-01-01', '1980-02-01', '1980-03-01'])\n",
      " |      >>> df\n",
      " |                      FR      GR      IT\n",
      " |      1980-01-01  4.0405  1.7246  804.74\n",
      " |      1980-02-01  4.0963  1.7482  810.01\n",
      " |      1980-03-01  4.3149  1.8519  860.13\n",
      " |      \n",
      " |      >>> df.pct_change()\n",
      " |                        FR        GR        IT\n",
      " |      1980-01-01       NaN       NaN       NaN\n",
      " |      1980-02-01  0.013810  0.013684  0.006549\n",
      " |      1980-03-01  0.053365  0.059318  0.061876\n",
      " |      \n",
      " |      Percentage of change in GOOG and APPL stock volume. Shows computing\n",
      " |      the percentage change between columns.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     '2016': [1769950, 30586265],\n",
      " |      ...     '2015': [1500923, 40912316],\n",
      " |      ...     '2014': [1371819, 41403351]},\n",
      " |      ...     index=['GOOG', 'APPL'])\n",
      " |      >>> df\n",
      " |                2016      2015      2014\n",
      " |      GOOG   1769950   1500923   1371819\n",
      " |      APPL  30586265  40912316  41403351\n",
      " |      \n",
      " |      >>> df.pct_change(axis='columns', periods=-1)\n",
      " |                2016      2015  2014\n",
      " |      GOOG  0.179241  0.094112   NaN\n",
      " |      APPL -0.252395 -0.011860   NaN\n",
      " |  \n",
      " |  pipe(self, func: 'Callable[..., T] | tuple[Callable[..., T], str]', *args, **kwargs) -> 'T'\n",
      " |      Apply func(self, \\*args, \\*\\*kwargs).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |          Function to apply to the Series/DataFrame.\n",
      " |          ``args``, and ``kwargs`` are passed into ``func``.\n",
      " |          Alternatively a ``(callable, data_keyword)`` tuple where\n",
      " |          ``data_keyword`` is a string indicating the keyword of\n",
      " |          ``callable`` that expects the Series/DataFrame.\n",
      " |      args : iterable, optional\n",
      " |          Positional arguments passed into ``func``.\n",
      " |      kwargs : mapping, optional\n",
      " |          A dictionary of keyword arguments passed into ``func``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      object : the return type of ``func``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.apply : Apply a function along input axis of DataFrame.\n",
      " |      DataFrame.applymap : Apply a function elementwise on a whole DataFrame.\n",
      " |      Series.map : Apply a mapping correspondence on a\n",
      " |          :class:`~pandas.Series`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Use ``.pipe`` when chaining together functions that expect\n",
      " |      Series, DataFrames or GroupBy objects. Instead of writing\n",
      " |      \n",
      " |      >>> func(g(h(df), arg1=a), arg2=b, arg3=c)  # doctest: +SKIP\n",
      " |      \n",
      " |      You can write\n",
      " |      \n",
      " |      >>> (df.pipe(h)\n",
      " |      ...    .pipe(g, arg1=a)\n",
      " |      ...    .pipe(func, arg2=b, arg3=c)\n",
      " |      ... )  # doctest: +SKIP\n",
      " |      \n",
      " |      If you have a function that takes the data as (say) the second\n",
      " |      argument, pass a tuple indicating which keyword expects the\n",
      " |      data. For example, suppose ``f`` takes its data as ``arg2``:\n",
      " |      \n",
      " |      >>> (df.pipe(h)\n",
      " |      ...    .pipe(g, arg1=a)\n",
      " |      ...    .pipe((func, 'arg2'), arg1=a, arg3=c)\n",
      " |      ...  )  # doctest: +SKIP\n",
      " |  \n",
      " |  rank(self: 'FrameOrSeries', axis=0, method: 'str' = 'average', numeric_only: 'bool_t | None' = None, na_option: 'str' = 'keep', ascending: 'bool_t' = True, pct: 'bool_t' = False) -> 'FrameOrSeries'\n",
      " |      Compute numerical data ranks (1 through n) along axis.\n",
      " |      \n",
      " |      By default, equal values are assigned a rank that is the average of the\n",
      " |      ranks of those values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Index to direct ranking.\n",
      " |      method : {'average', 'min', 'max', 'first', 'dense'}, default 'average'\n",
      " |          How to rank the group of records that have the same value (i.e. ties):\n",
      " |      \n",
      " |          * average: average rank of the group\n",
      " |          * min: lowest rank in the group\n",
      " |          * max: highest rank in the group\n",
      " |          * first: ranks assigned in order they appear in the array\n",
      " |          * dense: like 'min', but rank always increases by 1 between groups.\n",
      " |      \n",
      " |      numeric_only : bool, optional\n",
      " |          For DataFrame objects, rank only numeric columns if set to True.\n",
      " |      na_option : {'keep', 'top', 'bottom'}, default 'keep'\n",
      " |          How to rank NaN values:\n",
      " |      \n",
      " |          * keep: assign NaN rank to NaN values\n",
      " |          * top: assign lowest rank to NaN values\n",
      " |          * bottom: assign highest rank to NaN values\n",
      " |      \n",
      " |      ascending : bool, default True\n",
      " |          Whether or not the elements should be ranked in ascending order.\n",
      " |      pct : bool, default False\n",
      " |          Whether or not to display the returned rankings in percentile\n",
      " |          form.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as caller\n",
      " |          Return a Series or DataFrame with data ranks as values.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.groupby.GroupBy.rank : Rank of values within each group.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(data={'Animal': ['cat', 'penguin', 'dog',\n",
      " |      ...                                    'spider', 'snake'],\n",
      " |      ...                         'Number_legs': [4, 2, 4, 8, np.nan]})\n",
      " |      >>> df\n",
      " |          Animal  Number_legs\n",
      " |      0      cat          4.0\n",
      " |      1  penguin          2.0\n",
      " |      2      dog          4.0\n",
      " |      3   spider          8.0\n",
      " |      4    snake          NaN\n",
      " |      \n",
      " |      The following example shows how the method behaves with the above\n",
      " |      parameters:\n",
      " |      \n",
      " |      * default_rank: this is the default behaviour obtained without using\n",
      " |        any parameter.\n",
      " |      * max_rank: setting ``method = 'max'`` the records that have the\n",
      " |        same values are ranked using the highest rank (e.g.: since 'cat'\n",
      " |        and 'dog' are both in the 2nd and 3rd position, rank 3 is assigned.)\n",
      " |      * NA_bottom: choosing ``na_option = 'bottom'``, if there are records\n",
      " |        with NaN values they are placed at the bottom of the ranking.\n",
      " |      * pct_rank: when setting ``pct = True``, the ranking is expressed as\n",
      " |        percentile rank.\n",
      " |      \n",
      " |      >>> df['default_rank'] = df['Number_legs'].rank()\n",
      " |      >>> df['max_rank'] = df['Number_legs'].rank(method='max')\n",
      " |      >>> df['NA_bottom'] = df['Number_legs'].rank(na_option='bottom')\n",
      " |      >>> df['pct_rank'] = df['Number_legs'].rank(pct=True)\n",
      " |      >>> df\n",
      " |          Animal  Number_legs  default_rank  max_rank  NA_bottom  pct_rank\n",
      " |      0      cat          4.0           2.5       3.0        2.5     0.625\n",
      " |      1  penguin          2.0           1.0       1.0        1.0     0.250\n",
      " |      2      dog          4.0           2.5       3.0        2.5     0.625\n",
      " |      3   spider          8.0           4.0       4.0        4.0     1.000\n",
      " |      4    snake          NaN           NaN       NaN        5.0       NaN\n",
      " |  \n",
      " |  reindex_like(self: 'FrameOrSeries', other, method: 'str | None' = None, copy: 'bool_t' = True, limit=None, tolerance=None) -> 'FrameOrSeries'\n",
      " |      Return an object with matching indices as other object.\n",
      " |      \n",
      " |      Conform the object to the same index on all axes. Optional\n",
      " |      filling logic, placing NaN in locations having no value\n",
      " |      in the previous index. A new object is produced unless the\n",
      " |      new index is equivalent to the current one and copy=False.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Object of the same data type\n",
      " |          Its row and column indices are used to define the new indices\n",
      " |          of this object.\n",
      " |      method : {None, 'backfill'/'bfill', 'pad'/'ffill', 'nearest'}\n",
      " |          Method to use for filling holes in reindexed DataFrame.\n",
      " |          Please note: this is only applicable to DataFrames/Series with a\n",
      " |          monotonically increasing/decreasing index.\n",
      " |      \n",
      " |          * None (default): don't fill gaps\n",
      " |          * pad / ffill: propagate last valid observation forward to next\n",
      " |            valid\n",
      " |          * backfill / bfill: use next valid observation to fill gap\n",
      " |          * nearest: use nearest valid observations to fill gap.\n",
      " |      \n",
      " |      copy : bool, default True\n",
      " |          Return a new object, even if the passed indexes are the same.\n",
      " |      limit : int, default None\n",
      " |          Maximum number of consecutive labels to fill for inexact matches.\n",
      " |      tolerance : optional\n",
      " |          Maximum distance between original and new labels for inexact\n",
      " |          matches. The values of the index at the matching locations must\n",
      " |          satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      " |      \n",
      " |          Tolerance may be a scalar value, which applies the same tolerance\n",
      " |          to all values, or list-like, which applies variable tolerance per\n",
      " |          element. List-like includes list, tuple, array, Series, and must be\n",
      " |          the same size as the index and its dtype must exactly match the\n",
      " |          index's type.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Same type as caller, but with changed indices on each axis.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.set_index : Set row labels.\n",
      " |      DataFrame.reset_index : Remove row labels or move them to new columns.\n",
      " |      DataFrame.reindex : Change to new indices or expand indices.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Same as calling\n",
      " |      ``.reindex(index=other.index, columns=other.columns,...)``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df1 = pd.DataFrame([[24.3, 75.7, 'high'],\n",
      " |      ...                     [31, 87.8, 'high'],\n",
      " |      ...                     [22, 71.6, 'medium'],\n",
      " |      ...                     [35, 95, 'medium']],\n",
      " |      ...                    columns=['temp_celsius', 'temp_fahrenheit',\n",
      " |      ...                             'windspeed'],\n",
      " |      ...                    index=pd.date_range(start='2014-02-12',\n",
      " |      ...                                        end='2014-02-15', freq='D'))\n",
      " |      \n",
      " |      >>> df1\n",
      " |                  temp_celsius  temp_fahrenheit windspeed\n",
      " |      2014-02-12          24.3             75.7      high\n",
      " |      2014-02-13          31.0             87.8      high\n",
      " |      2014-02-14          22.0             71.6    medium\n",
      " |      2014-02-15          35.0             95.0    medium\n",
      " |      \n",
      " |      >>> df2 = pd.DataFrame([[28, 'low'],\n",
      " |      ...                     [30, 'low'],\n",
      " |      ...                     [35.1, 'medium']],\n",
      " |      ...                    columns=['temp_celsius', 'windspeed'],\n",
      " |      ...                    index=pd.DatetimeIndex(['2014-02-12', '2014-02-13',\n",
      " |      ...                                            '2014-02-15']))\n",
      " |      \n",
      " |      >>> df2\n",
      " |                  temp_celsius windspeed\n",
      " |      2014-02-12          28.0       low\n",
      " |      2014-02-13          30.0       low\n",
      " |      2014-02-15          35.1    medium\n",
      " |      \n",
      " |      >>> df2.reindex_like(df1)\n",
      " |                  temp_celsius  temp_fahrenheit windspeed\n",
      " |      2014-02-12          28.0              NaN       low\n",
      " |      2014-02-13          30.0              NaN       low\n",
      " |      2014-02-14           NaN              NaN       NaN\n",
      " |      2014-02-15          35.1              NaN    medium\n",
      " |  \n",
      " |  rename_axis(self, mapper=None, index=None, columns=None, axis=None, copy=True, inplace=False)\n",
      " |      Set the name of the axis for the index or columns.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      mapper : scalar, list-like, optional\n",
      " |          Value to set the axis name attribute.\n",
      " |      index, columns : scalar, list-like, dict-like or function, optional\n",
      " |          A scalar, list-like, dict-like or functions transformations to\n",
      " |          apply to that axis' values.\n",
      " |          Note that the ``columns`` parameter is not allowed if the\n",
      " |          object is a Series. This parameter only apply for DataFrame\n",
      " |          type objects.\n",
      " |      \n",
      " |          Use either ``mapper`` and ``axis`` to\n",
      " |          specify the axis to target with ``mapper``, or ``index``\n",
      " |          and/or ``columns``.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to rename.\n",
      " |      copy : bool, default True\n",
      " |          Also copy underlying data.\n",
      " |      inplace : bool, default False\n",
      " |          Modifies the object directly, instead of creating a new Series\n",
      " |          or DataFrame.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series, DataFrame, or None\n",
      " |          The same type as the caller or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.rename : Alter Series index labels or name.\n",
      " |      DataFrame.rename : Alter DataFrame index labels or name.\n",
      " |      Index.rename : Set new names on index.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      ``DataFrame.rename_axis`` supports two calling conventions\n",
      " |      \n",
      " |      * ``(index=index_mapper, columns=columns_mapper, ...)``\n",
      " |      * ``(mapper, axis={'index', 'columns'}, ...)``\n",
      " |      \n",
      " |      The first calling convention will only modify the names of\n",
      " |      the index and/or the names of the Index object that is the columns.\n",
      " |      In this case, the parameter ``copy`` is ignored.\n",
      " |      \n",
      " |      The second calling convention will modify the names of the\n",
      " |      corresponding index if mapper is a list or a scalar.\n",
      " |      However, if mapper is dict-like or a function, it will use the\n",
      " |      deprecated behavior of modifying the axis *labels*.\n",
      " |      \n",
      " |      We *highly* recommend using keyword arguments to clarify your\n",
      " |      intent.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([\"dog\", \"cat\", \"monkey\"])\n",
      " |      >>> s\n",
      " |      0       dog\n",
      " |      1       cat\n",
      " |      2    monkey\n",
      " |      dtype: object\n",
      " |      >>> s.rename_axis(\"animal\")\n",
      " |      animal\n",
      " |      0    dog\n",
      " |      1    cat\n",
      " |      2    monkey\n",
      " |      dtype: object\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"num_legs\": [4, 4, 2],\n",
      " |      ...                    \"num_arms\": [0, 0, 2]},\n",
      " |      ...                   [\"dog\", \"cat\", \"monkey\"])\n",
      " |      >>> df\n",
      " |              num_legs  num_arms\n",
      " |      dog            4         0\n",
      " |      cat            4         0\n",
      " |      monkey         2         2\n",
      " |      >>> df = df.rename_axis(\"animal\")\n",
      " |      >>> df\n",
      " |              num_legs  num_arms\n",
      " |      animal\n",
      " |      dog            4         0\n",
      " |      cat            4         0\n",
      " |      monkey         2         2\n",
      " |      >>> df = df.rename_axis(\"limbs\", axis=\"columns\")\n",
      " |      >>> df\n",
      " |      limbs   num_legs  num_arms\n",
      " |      animal\n",
      " |      dog            4         0\n",
      " |      cat            4         0\n",
      " |      monkey         2         2\n",
      " |      \n",
      " |      **MultiIndex**\n",
      " |      \n",
      " |      >>> df.index = pd.MultiIndex.from_product([['mammal'],\n",
      " |      ...                                        ['dog', 'cat', 'monkey']],\n",
      " |      ...                                       names=['type', 'name'])\n",
      " |      >>> df\n",
      " |      limbs          num_legs  num_arms\n",
      " |      type   name\n",
      " |      mammal dog            4         0\n",
      " |             cat            4         0\n",
      " |             monkey         2         2\n",
      " |      \n",
      " |      >>> df.rename_axis(index={'type': 'class'})\n",
      " |      limbs          num_legs  num_arms\n",
      " |      class  name\n",
      " |      mammal dog            4         0\n",
      " |             cat            4         0\n",
      " |             monkey         2         2\n",
      " |      \n",
      " |      >>> df.rename_axis(columns=str.upper)\n",
      " |      LIMBS          num_legs  num_arms\n",
      " |      type   name\n",
      " |      mammal dog            4         0\n",
      " |             cat            4         0\n",
      " |             monkey         2         2\n",
      " |  \n",
      " |  rolling(self, window: 'int | timedelta | BaseOffset | BaseIndexer', min_periods: 'int | None' = None, center: 'bool_t' = False, win_type: 'str | None' = None, on: 'str | None' = None, axis: 'Axis' = 0, closed: 'str | None' = None, method: 'str' = 'single')\n",
      " |      Provide rolling window calculations.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      window : int, offset, or BaseIndexer subclass\n",
      " |          Size of the moving window. This is the number of observations used for\n",
      " |          calculating the statistic. Each window will be a fixed size.\n",
      " |      \n",
      " |          If its an offset then this will be the time period of each window. Each\n",
      " |          window will be a variable sized based on the observations included in\n",
      " |          the time-period. This is only valid for datetimelike indexes.\n",
      " |      \n",
      " |          If a BaseIndexer subclass is passed, calculates the window boundaries\n",
      " |          based on the defined ``get_window_bounds`` method. Additional rolling\n",
      " |          keyword arguments, namely `min_periods`, `center`, and\n",
      " |          `closed` will be passed to `get_window_bounds`.\n",
      " |      min_periods : int, default None\n",
      " |          Minimum number of observations in window required to have a value\n",
      " |          (otherwise result is NA). For a window that is specified by an offset,\n",
      " |          `min_periods` will default to 1. Otherwise, `min_periods` will default\n",
      " |          to the size of the window.\n",
      " |      center : bool, default False\n",
      " |          Set the labels at the center of the window.\n",
      " |      win_type : str, default None\n",
      " |          Provide a window type. If ``None``, all points are evenly weighted.\n",
      " |          See the notes below for further information.\n",
      " |      on : str, optional\n",
      " |          For a DataFrame, a datetime-like column or Index level on which\n",
      " |          to calculate the rolling window, rather than the DataFrame's index.\n",
      " |          Provided integer column is ignored and excluded from result since\n",
      " |          an integer index is not used to calculate the rolling window.\n",
      " |      axis : int or str, default 0\n",
      " |      closed : str, default None\n",
      " |          Make the interval closed on the 'right', 'left', 'both' or\n",
      " |          'neither' endpoints. Defaults to 'right'.\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |              The closed parameter with fixed windows is now supported.\n",
      " |      method : str {'single', 'table'}, default 'single'\n",
      " |          Execute the rolling operation per single column or row (``'single'``)\n",
      " |          or over the entire object (``'table'``).\n",
      " |      \n",
      " |          This argument is only implemented when specifying ``engine='numba'``\n",
      " |          in the method call.\n",
      " |      \n",
      " |          .. versionadded:: 1.3.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      a Window or Rolling sub-classed for the particular operation\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      expanding : Provides expanding transformations.\n",
      " |      ewm : Provides exponential weighted functions.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      By default, the result is set to the right edge of the window. This can be\n",
      " |      changed to the center of the window by setting ``center=True``.\n",
      " |      \n",
      " |      To learn more about the offsets & frequency strings, please see `this link\n",
      " |      <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\n",
      " |      \n",
      " |      If ``win_type=None``, all points are evenly weighted; otherwise, ``win_type``\n",
      " |      can accept a string of any `scipy.signal window function\n",
      " |      <https://docs.scipy.org/doc/scipy/reference/signal.windows.html#module-scipy.signal.windows>`__.\n",
      " |      \n",
      " |      Certain Scipy window types require additional parameters to be passed\n",
      " |      in the aggregation function. The additional parameters must match\n",
      " |      the keywords specified in the Scipy window type method signature.\n",
      " |      Please see the third example below on how to add the additional parameters.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      " |      >>> df\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |      \n",
      " |      Rolling sum with a window length of 2, using the 'triang'\n",
      " |      window type.\n",
      " |      \n",
      " |      >>> df.rolling(2, win_type='triang').sum()\n",
      " |           B\n",
      " |      0  NaN\n",
      " |      1  0.5\n",
      " |      2  1.5\n",
      " |      3  NaN\n",
      " |      4  NaN\n",
      " |      \n",
      " |      Rolling sum with a window length of 2, using the 'gaussian'\n",
      " |      window type (note how we need to specify std).\n",
      " |      \n",
      " |      >>> df.rolling(2, win_type='gaussian').sum(std=3)\n",
      " |                B\n",
      " |      0       NaN\n",
      " |      1  0.986207\n",
      " |      2  2.958621\n",
      " |      3       NaN\n",
      " |      4       NaN\n",
      " |      \n",
      " |      Rolling sum with a window length of 2, min_periods defaults\n",
      " |      to the window length.\n",
      " |      \n",
      " |      >>> df.rolling(2).sum()\n",
      " |           B\n",
      " |      0  NaN\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  NaN\n",
      " |      4  NaN\n",
      " |      \n",
      " |      Same as above, but explicitly set the min_periods\n",
      " |      \n",
      " |      >>> df.rolling(2, min_periods=1).sum()\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  2.0\n",
      " |      4  4.0\n",
      " |      \n",
      " |      Same as above, but with forward-looking windows\n",
      " |      \n",
      " |      >>> indexer = pd.api.indexers.FixedForwardWindowIndexer(window_size=2)\n",
      " |      >>> df.rolling(window=indexer, min_periods=1).sum()\n",
      " |           B\n",
      " |      0  1.0\n",
      " |      1  3.0\n",
      " |      2  2.0\n",
      " |      3  4.0\n",
      " |      4  4.0\n",
      " |      \n",
      " |      A ragged (meaning not-a-regular frequency), time-indexed DataFrame\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]},\n",
      " |      ...                   index = [pd.Timestamp('20130101 09:00:00'),\n",
      " |      ...                            pd.Timestamp('20130101 09:00:02'),\n",
      " |      ...                            pd.Timestamp('20130101 09:00:03'),\n",
      " |      ...                            pd.Timestamp('20130101 09:00:05'),\n",
      " |      ...                            pd.Timestamp('20130101 09:00:06')])\n",
      " |      \n",
      " |      >>> df\n",
      " |                             B\n",
      " |      2013-01-01 09:00:00  0.0\n",
      " |      2013-01-01 09:00:02  1.0\n",
      " |      2013-01-01 09:00:03  2.0\n",
      " |      2013-01-01 09:00:05  NaN\n",
      " |      2013-01-01 09:00:06  4.0\n",
      " |      \n",
      " |      Contrasting to an integer rolling window, this will roll a variable\n",
      " |      length window corresponding to the time period.\n",
      " |      The default for min_periods is 1.\n",
      " |      \n",
      " |      >>> df.rolling('2s').sum()\n",
      " |                             B\n",
      " |      2013-01-01 09:00:00  0.0\n",
      " |      2013-01-01 09:00:02  1.0\n",
      " |      2013-01-01 09:00:03  3.0\n",
      " |      2013-01-01 09:00:05  NaN\n",
      " |      2013-01-01 09:00:06  4.0\n",
      " |  \n",
      " |  sample(self: 'FrameOrSeries', n=None, frac: 'float | None' = None, replace: 'bool_t' = False, weights=None, random_state=None, axis: 'Axis | None' = None, ignore_index: 'bool_t' = False) -> 'FrameOrSeries'\n",
      " |      Return a random sample of items from an axis of object.\n",
      " |      \n",
      " |      You can use `random_state` for reproducibility.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, optional\n",
      " |          Number of items from axis to return. Cannot be used with `frac`.\n",
      " |          Default = 1 if `frac` = None.\n",
      " |      frac : float, optional\n",
      " |          Fraction of axis items to return. Cannot be used with `n`.\n",
      " |      replace : bool, default False\n",
      " |          Allow or disallow sampling of the same row more than once.\n",
      " |      weights : str or ndarray-like, optional\n",
      " |          Default 'None' results in equal probability weighting.\n",
      " |          If passed a Series, will align with target object on index. Index\n",
      " |          values in weights not found in sampled object will be ignored and\n",
      " |          index values in sampled object not in weights will be assigned\n",
      " |          weights of zero.\n",
      " |          If called on a DataFrame, will accept the name of a column\n",
      " |          when axis = 0.\n",
      " |          Unless weights are a Series, weights must be same length as axis\n",
      " |          being sampled.\n",
      " |          If weights do not sum to 1, they will be normalized to sum to 1.\n",
      " |          Missing values in the weights column will be treated as zero.\n",
      " |          Infinite values not allowed.\n",
      " |      random_state : int, array-like, BitGenerator, np.random.RandomState, optional\n",
      " |          If int, array-like, or BitGenerator (NumPy>=1.17), seed for\n",
      " |          random number generator\n",
      " |          If np.random.RandomState, use as numpy RandomState object.\n",
      " |      \n",
      " |          .. versionchanged:: 1.1.0\n",
      " |      \n",
      " |              array-like and BitGenerator (for NumPy>=1.17) object now passed to\n",
      " |              np.random.RandomState() as seed\n",
      " |      \n",
      " |      axis : {0 or ‘index’, 1 or ‘columns’, None}, default None\n",
      " |          Axis to sample. Accepts axis number or name. Default is stat axis\n",
      " |          for given data type (0 for Series and DataFrames).\n",
      " |      ignore_index : bool, default False\n",
      " |          If True, the resulting index will be labeled 0, 1, …, n - 1.\n",
      " |      \n",
      " |          .. versionadded:: 1.3.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          A new object of same type as caller containing `n` items randomly\n",
      " |          sampled from the caller object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrameGroupBy.sample: Generates random samples from each group of a\n",
      " |          DataFrame object.\n",
      " |      SeriesGroupBy.sample: Generates random samples from each group of a\n",
      " |          Series object.\n",
      " |      numpy.random.choice: Generates a random sample from a given 1-D numpy\n",
      " |          array.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If `frac` > 1, `replacement` should be set to `True`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'num_legs': [2, 4, 8, 0],\n",
      " |      ...                    'num_wings': [2, 0, 0, 0],\n",
      " |      ...                    'num_specimen_seen': [10, 2, 1, 8]},\n",
      " |      ...                   index=['falcon', 'dog', 'spider', 'fish'])\n",
      " |      >>> df\n",
      " |              num_legs  num_wings  num_specimen_seen\n",
      " |      falcon         2          2                 10\n",
      " |      dog            4          0                  2\n",
      " |      spider         8          0                  1\n",
      " |      fish           0          0                  8\n",
      " |      \n",
      " |      Extract 3 random elements from the ``Series`` ``df['num_legs']``:\n",
      " |      Note that we use `random_state` to ensure the reproducibility of\n",
      " |      the examples.\n",
      " |      \n",
      " |      >>> df['num_legs'].sample(n=3, random_state=1)\n",
      " |      fish      0\n",
      " |      spider    8\n",
      " |      falcon    2\n",
      " |      Name: num_legs, dtype: int64\n",
      " |      \n",
      " |      A random 50% sample of the ``DataFrame`` with replacement:\n",
      " |      \n",
      " |      >>> df.sample(frac=0.5, replace=True, random_state=1)\n",
      " |            num_legs  num_wings  num_specimen_seen\n",
      " |      dog          4          0                  2\n",
      " |      fish         0          0                  8\n",
      " |      \n",
      " |      An upsample sample of the ``DataFrame`` with replacement:\n",
      " |      Note that `replace` parameter has to be `True` for `frac` parameter > 1.\n",
      " |      \n",
      " |      >>> df.sample(frac=2, replace=True, random_state=1)\n",
      " |              num_legs  num_wings  num_specimen_seen\n",
      " |      dog            4          0                  2\n",
      " |      fish           0          0                  8\n",
      " |      falcon         2          2                 10\n",
      " |      falcon         2          2                 10\n",
      " |      fish           0          0                  8\n",
      " |      dog            4          0                  2\n",
      " |      fish           0          0                  8\n",
      " |      dog            4          0                  2\n",
      " |      \n",
      " |      Using a DataFrame column as weights. Rows with larger value in the\n",
      " |      `num_specimen_seen` column are more likely to be sampled.\n",
      " |      \n",
      " |      >>> df.sample(n=2, weights='num_specimen_seen', random_state=1)\n",
      " |              num_legs  num_wings  num_specimen_seen\n",
      " |      falcon         2          2                 10\n",
      " |      fish           0          0                  8\n",
      " |  \n",
      " |  set_flags(self: 'FrameOrSeries', *, copy: 'bool_t' = False, allows_duplicate_labels: 'bool_t | None' = None) -> 'FrameOrSeries'\n",
      " |      Return a new object with updated flags.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      allows_duplicate_labels : bool, optional\n",
      " |          Whether the returned object allows duplicate labels.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          The same type as the caller.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.attrs : Global metadata applying to this dataset.\n",
      " |      DataFrame.flags : Global flags applying to this object.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method returns a new object that's a view on the same data\n",
      " |      as the input. Mutating the input or the output values will be reflected\n",
      " |      in the other.\n",
      " |      \n",
      " |      This method is intended to be used in method chains.\n",
      " |      \n",
      " |      \"Flags\" differ from \"metadata\". Flags reflect properties of the\n",
      " |      pandas object (the Series or DataFrame). Metadata refer to properties\n",
      " |      of the dataset, and should be stored in :attr:`DataFrame.attrs`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2]})\n",
      " |      >>> df.flags.allows_duplicate_labels\n",
      " |      True\n",
      " |      >>> df2 = df.set_flags(allows_duplicate_labels=False)\n",
      " |      >>> df2.flags.allows_duplicate_labels\n",
      " |      False\n",
      " |  \n",
      " |  slice_shift(self: 'FrameOrSeries', periods: 'int' = 1, axis=0) -> 'FrameOrSeries'\n",
      " |      Equivalent to `shift` without copying data.\n",
      " |      The shifted data will not include the dropped periods and the\n",
      " |      shifted axis will be smaller than the original.\n",
      " |      \n",
      " |      .. deprecated:: 1.2.0\n",
      " |          slice_shift is deprecated,\n",
      " |          use DataFrame/Series.shift instead.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : same type as caller\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      While the `slice_shift` is faster than `shift`, you may pay for it\n",
      " |      later during alignment.\n",
      " |  \n",
      " |  squeeze(self, axis=None)\n",
      " |      Squeeze 1 dimensional axis objects into scalars.\n",
      " |      \n",
      " |      Series or DataFrames with a single element are squeezed to a scalar.\n",
      " |      DataFrames with a single column or a single row are squeezed to a\n",
      " |      Series. Otherwise the object is unchanged.\n",
      " |      \n",
      " |      This method is most useful when you don't know if your\n",
      " |      object is a Series or DataFrame, but you do know it has just a single\n",
      " |      column. In that case you can safely call `squeeze` to ensure you have a\n",
      " |      Series.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default None\n",
      " |          A specific axis to squeeze. By default, all length-1 axes are\n",
      " |          squeezed.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame, Series, or scalar\n",
      " |          The projection after squeezing `axis` or all the axes.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.iloc : Integer-location based indexing for selecting scalars.\n",
      " |      DataFrame.iloc : Integer-location based indexing for selecting Series.\n",
      " |      Series.to_frame : Inverse of DataFrame.squeeze for a\n",
      " |          single-column DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> primes = pd.Series([2, 3, 5, 7])\n",
      " |      \n",
      " |      Slicing might produce a Series with a single value:\n",
      " |      \n",
      " |      >>> even_primes = primes[primes % 2 == 0]\n",
      " |      >>> even_primes\n",
      " |      0    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> even_primes.squeeze()\n",
      " |      2\n",
      " |      \n",
      " |      Squeezing objects with more than one value in every axis does nothing:\n",
      " |      \n",
      " |      >>> odd_primes = primes[primes % 2 == 1]\n",
      " |      >>> odd_primes\n",
      " |      1    3\n",
      " |      2    5\n",
      " |      3    7\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> odd_primes.squeeze()\n",
      " |      1    3\n",
      " |      2    5\n",
      " |      3    7\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Squeezing is even more effective when used with DataFrames.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2], [3, 4]], columns=['a', 'b'])\n",
      " |      >>> df\n",
      " |         a  b\n",
      " |      0  1  2\n",
      " |      1  3  4\n",
      " |      \n",
      " |      Slicing a single column will produce a DataFrame with the columns\n",
      " |      having only one value:\n",
      " |      \n",
      " |      >>> df_a = df[['a']]\n",
      " |      >>> df_a\n",
      " |         a\n",
      " |      0  1\n",
      " |      1  3\n",
      " |      \n",
      " |      So the columns can be squeezed down, resulting in a Series:\n",
      " |      \n",
      " |      >>> df_a.squeeze('columns')\n",
      " |      0    1\n",
      " |      1    3\n",
      " |      Name: a, dtype: int64\n",
      " |      \n",
      " |      Slicing a single row from a single column will produce a single\n",
      " |      scalar DataFrame:\n",
      " |      \n",
      " |      >>> df_0a = df.loc[df.index < 1, ['a']]\n",
      " |      >>> df_0a\n",
      " |         a\n",
      " |      0  1\n",
      " |      \n",
      " |      Squeezing the rows produces a single scalar Series:\n",
      " |      \n",
      " |      >>> df_0a.squeeze('rows')\n",
      " |      a    1\n",
      " |      Name: 0, dtype: int64\n",
      " |      \n",
      " |      Squeezing all axes will project directly into a scalar:\n",
      " |      \n",
      " |      >>> df_0a.squeeze()\n",
      " |      1\n",
      " |  \n",
      " |  swapaxes(self: 'FrameOrSeries', axis1, axis2, copy=True) -> 'FrameOrSeries'\n",
      " |      Interchange axes and swap values axes appropriately.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : same as input\n",
      " |  \n",
      " |  tail(self: 'FrameOrSeries', n: 'int' = 5) -> 'FrameOrSeries'\n",
      " |      Return the last `n` rows.\n",
      " |      \n",
      " |      This function returns last `n` rows from the object based on\n",
      " |      position. It is useful for quickly verifying data, for example,\n",
      " |      after sorting or appending rows.\n",
      " |      \n",
      " |      For negative values of `n`, this function returns all rows except\n",
      " |      the first `n` rows, equivalent to ``df[n:]``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, default 5\n",
      " |          Number of rows to select.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of caller\n",
      " |          The last `n` rows of the caller object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.head : The first `n` rows of the caller object.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',\n",
      " |      ...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n",
      " |      >>> df\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      5     parrot\n",
      " |      6      shark\n",
      " |      7      whale\n",
      " |      8      zebra\n",
      " |      \n",
      " |      Viewing the last 5 lines\n",
      " |      \n",
      " |      >>> df.tail()\n",
      " |         animal\n",
      " |      4  monkey\n",
      " |      5  parrot\n",
      " |      6   shark\n",
      " |      7   whale\n",
      " |      8   zebra\n",
      " |      \n",
      " |      Viewing the last `n` lines (three in this case)\n",
      " |      \n",
      " |      >>> df.tail(3)\n",
      " |        animal\n",
      " |      6  shark\n",
      " |      7  whale\n",
      " |      8  zebra\n",
      " |      \n",
      " |      For negative values of `n`\n",
      " |      \n",
      " |      >>> df.tail(-3)\n",
      " |         animal\n",
      " |      3    lion\n",
      " |      4  monkey\n",
      " |      5  parrot\n",
      " |      6   shark\n",
      " |      7   whale\n",
      " |      8   zebra\n",
      " |  \n",
      " |  to_clipboard(self, excel: 'bool_t' = True, sep: 'str | None' = None, **kwargs) -> 'None'\n",
      " |      Copy object to the system clipboard.\n",
      " |      \n",
      " |      Write a text representation of object to the system clipboard.\n",
      " |      This can be pasted into Excel, for example.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      excel : bool, default True\n",
      " |          Produce output in a csv format for easy pasting into excel.\n",
      " |      \n",
      " |          - True, use the provided separator for csv pasting.\n",
      " |          - False, write a string representation of the object to the clipboard.\n",
      " |      \n",
      " |      sep : str, default ``'\\t'``\n",
      " |          Field delimiter.\n",
      " |      **kwargs\n",
      " |          These parameters will be passed to DataFrame.to_csv.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.to_csv : Write a DataFrame to a comma-separated values\n",
      " |          (csv) file.\n",
      " |      read_clipboard : Read text from clipboard and pass to read_table.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Requirements for your platform.\n",
      " |      \n",
      " |        - Linux : `xclip`, or `xsel` (with `PyQt4` modules)\n",
      " |        - Windows : none\n",
      " |        - OS X : none\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Copy the contents of a DataFrame to the clipboard.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2, 3], [4, 5, 6]], columns=['A', 'B', 'C'])\n",
      " |      \n",
      " |      >>> df.to_clipboard(sep=',')  # doctest: +SKIP\n",
      " |      ... # Wrote the following to the system clipboard:\n",
      " |      ... # ,A,B,C\n",
      " |      ... # 0,1,2,3\n",
      " |      ... # 1,4,5,6\n",
      " |      \n",
      " |      We can omit the index by passing the keyword `index` and setting\n",
      " |      it to false.\n",
      " |      \n",
      " |      >>> df.to_clipboard(sep=',', index=False)  # doctest: +SKIP\n",
      " |      ... # Wrote the following to the system clipboard:\n",
      " |      ... # A,B,C\n",
      " |      ... # 1,2,3\n",
      " |      ... # 4,5,6\n",
      " |  \n",
      " |  to_csv(self, path_or_buf: 'FilePathOrBuffer[AnyStr] | None' = None, sep: 'str' = ',', na_rep: 'str' = '', float_format: 'str | None' = None, columns: 'Sequence[Hashable] | None' = None, header: 'bool_t | list[str]' = True, index: 'bool_t' = True, index_label: 'IndexLabel | None' = None, mode: 'str' = 'w', encoding: 'str | None' = None, compression: 'CompressionOptions' = 'infer', quoting: 'int | None' = None, quotechar: 'str' = '\"', line_terminator: 'str | None' = None, chunksize: 'int | None' = None, date_format: 'str | None' = None, doublequote: 'bool_t' = True, escapechar: 'str | None' = None, decimal: 'str' = '.', errors: 'str' = 'strict', storage_options: 'StorageOptions' = None) -> 'str | None'\n",
      " |      Write object to a comma-separated values (csv) file.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : str or file handle, default None\n",
      " |          File path or object, if None is provided the result is returned as\n",
      " |          a string.  If a non-binary file object is passed, it should be opened\n",
      " |          with `newline=''`, disabling universal newlines. If a binary\n",
      " |          file object is passed, `mode` might need to contain a `'b'`.\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |             Support for binary file objects was introduced.\n",
      " |      \n",
      " |      sep : str, default ','\n",
      " |          String of length 1. Field delimiter for the output file.\n",
      " |      na_rep : str, default ''\n",
      " |          Missing data representation.\n",
      " |      float_format : str, default None\n",
      " |          Format string for floating point numbers.\n",
      " |      columns : sequence, optional\n",
      " |          Columns to write.\n",
      " |      header : bool or list of str, default True\n",
      " |          Write out the column names. If a list of strings is given it is\n",
      " |          assumed to be aliases for the column names.\n",
      " |      index : bool, default True\n",
      " |          Write row names (index).\n",
      " |      index_label : str or sequence, or False, default None\n",
      " |          Column label for index column(s) if desired. If None is given, and\n",
      " |          `header` and `index` are True, then the index names are used. A\n",
      " |          sequence should be given if the object uses MultiIndex. If\n",
      " |          False do not print fields for index names. Use index_label=False\n",
      " |          for easier importing in R.\n",
      " |      mode : str\n",
      " |          Python write mode, default 'w'.\n",
      " |      encoding : str, optional\n",
      " |          A string representing the encoding to use in the output file,\n",
      " |          defaults to 'utf-8'. `encoding` is not supported if `path_or_buf`\n",
      " |          is a non-binary file object.\n",
      " |      compression : str or dict, default 'infer'\n",
      " |          If str, represents compression mode. If dict, value at 'method' is\n",
      " |          the compression mode. Compression mode may be any of the following\n",
      " |          possible values: {'infer', 'gzip', 'bz2', 'zip', 'xz', None}. If\n",
      " |          compression mode is 'infer' and `path_or_buf` is path-like, then\n",
      " |          detect compression mode from the following extensions: '.gz',\n",
      " |          '.bz2', '.zip' or '.xz'. (otherwise no compression). If dict given\n",
      " |          and mode is one of {'zip', 'gzip', 'bz2'}, or inferred as\n",
      " |          one of the above, other entries passed as\n",
      " |          additional compression options.\n",
      " |      \n",
      " |          .. versionchanged:: 1.0.0\n",
      " |      \n",
      " |             May now be a dict with key 'method' as compression mode\n",
      " |             and other entries as additional compression options if\n",
      " |             compression mode is 'zip'.\n",
      " |      \n",
      " |          .. versionchanged:: 1.1.0\n",
      " |      \n",
      " |             Passing compression options as keys in dict is\n",
      " |             supported for compression modes 'gzip' and 'bz2'\n",
      " |             as well as 'zip'.\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |              Compression is supported for binary file objects.\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |              Previous versions forwarded dict entries for 'gzip' to\n",
      " |              `gzip.open` instead of `gzip.GzipFile` which prevented\n",
      " |              setting `mtime`.\n",
      " |      \n",
      " |      quoting : optional constant from csv module\n",
      " |          Defaults to csv.QUOTE_MINIMAL. If you have set a `float_format`\n",
      " |          then floats are converted to strings and thus csv.QUOTE_NONNUMERIC\n",
      " |          will treat them as non-numeric.\n",
      " |      quotechar : str, default '\\\"'\n",
      " |          String of length 1. Character used to quote fields.\n",
      " |      line_terminator : str, optional\n",
      " |          The newline character or character sequence to use in the output\n",
      " |          file. Defaults to `os.linesep`, which depends on the OS in which\n",
      " |          this method is called ('\\\\n' for linux, '\\\\r\\\\n' for Windows, i.e.).\n",
      " |      chunksize : int or None\n",
      " |          Rows to write at a time.\n",
      " |      date_format : str, default None\n",
      " |          Format string for datetime objects.\n",
      " |      doublequote : bool, default True\n",
      " |          Control quoting of `quotechar` inside a field.\n",
      " |      escapechar : str, default None\n",
      " |          String of length 1. Character used to escape `sep` and `quotechar`\n",
      " |          when appropriate.\n",
      " |      decimal : str, default '.'\n",
      " |          Character recognized as decimal separator. E.g. use ',' for\n",
      " |          European data.\n",
      " |      errors : str, default 'strict'\n",
      " |          Specifies how encoding and decoding errors are to be handled.\n",
      " |          See the errors argument for :func:`open` for a full list\n",
      " |          of options.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib`` as header options. For other URLs (e.g.\n",
      " |          starting with \"s3://\", and \"gcs://\") the key-value pairs are forwarded to\n",
      " |          ``fsspec``. Please see ``fsspec`` and ``urllib`` for more details.\n",
      " |      \n",
      " |          .. versionadded:: 1.2.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      None or str\n",
      " |          If path_or_buf is None, returns the resulting csv format as a\n",
      " |          string. Otherwise returns None.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_csv : Load a CSV file into a DataFrame.\n",
      " |      to_excel : Write DataFrame to an Excel file.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'name': ['Raphael', 'Donatello'],\n",
      " |      ...                    'mask': ['red', 'purple'],\n",
      " |      ...                    'weapon': ['sai', 'bo staff']})\n",
      " |      >>> df.to_csv(index=False)\n",
      " |      'name,mask,weapon\\nRaphael,red,sai\\nDonatello,purple,bo staff\\n'\n",
      " |      \n",
      " |      Create 'out.zip' containing 'out.csv'\n",
      " |      \n",
      " |      >>> compression_opts = dict(method='zip',\n",
      " |      ...                         archive_name='out.csv')  # doctest: +SKIP\n",
      " |      >>> df.to_csv('out.zip', index=False,\n",
      " |      ...           compression=compression_opts)  # doctest: +SKIP\n",
      " |  \n",
      " |  to_excel(self, excel_writer, sheet_name: 'str' = 'Sheet1', na_rep: 'str' = '', float_format: 'str | None' = None, columns=None, header=True, index=True, index_label=None, startrow=0, startcol=0, engine=None, merge_cells=True, encoding=None, inf_rep='inf', verbose=True, freeze_panes=None, storage_options: 'StorageOptions' = None) -> 'None'\n",
      " |      Write object to an Excel sheet.\n",
      " |      \n",
      " |      To write a single object to an Excel .xlsx file it is only necessary to\n",
      " |      specify a target file name. To write to multiple sheets it is necessary to\n",
      " |      create an `ExcelWriter` object with a target file name, and specify a sheet\n",
      " |      in the file to write to.\n",
      " |      \n",
      " |      Multiple sheets may be written to by specifying unique `sheet_name`.\n",
      " |      With all data written to the file it is necessary to save the changes.\n",
      " |      Note that creating an `ExcelWriter` object with a file name that already\n",
      " |      exists will result in the contents of the existing file being erased.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      excel_writer : path-like, file-like, or ExcelWriter object\n",
      " |          File path or existing ExcelWriter.\n",
      " |      sheet_name : str, default 'Sheet1'\n",
      " |          Name of sheet which will contain DataFrame.\n",
      " |      na_rep : str, default ''\n",
      " |          Missing data representation.\n",
      " |      float_format : str, optional\n",
      " |          Format string for floating point numbers. For example\n",
      " |          ``float_format=\"%.2f\"`` will format 0.1234 to 0.12.\n",
      " |      columns : sequence or list of str, optional\n",
      " |          Columns to write.\n",
      " |      header : bool or list of str, default True\n",
      " |          Write out the column names. If a list of string is given it is\n",
      " |          assumed to be aliases for the column names.\n",
      " |      index : bool, default True\n",
      " |          Write row names (index).\n",
      " |      index_label : str or sequence, optional\n",
      " |          Column label for index column(s) if desired. If not specified, and\n",
      " |          `header` and `index` are True, then the index names are used. A\n",
      " |          sequence should be given if the DataFrame uses MultiIndex.\n",
      " |      startrow : int, default 0\n",
      " |          Upper left cell row to dump data frame.\n",
      " |      startcol : int, default 0\n",
      " |          Upper left cell column to dump data frame.\n",
      " |      engine : str, optional\n",
      " |          Write engine to use, 'openpyxl' or 'xlsxwriter'. You can also set this\n",
      " |          via the options ``io.excel.xlsx.writer``, ``io.excel.xls.writer``, and\n",
      " |          ``io.excel.xlsm.writer``.\n",
      " |      \n",
      " |          .. deprecated:: 1.2.0\n",
      " |      \n",
      " |              As the `xlwt <https://pypi.org/project/xlwt/>`__ package is no longer\n",
      " |              maintained, the ``xlwt`` engine will be removed in a future version\n",
      " |              of pandas.\n",
      " |      \n",
      " |      merge_cells : bool, default True\n",
      " |          Write MultiIndex and Hierarchical Rows as merged cells.\n",
      " |      encoding : str, optional\n",
      " |          Encoding of the resulting excel file. Only necessary for xlwt,\n",
      " |          other writers support unicode natively.\n",
      " |      inf_rep : str, default 'inf'\n",
      " |          Representation for infinity (there is no native representation for\n",
      " |          infinity in Excel).\n",
      " |      verbose : bool, default True\n",
      " |          Display more information in the error logs.\n",
      " |      freeze_panes : tuple of int (length 2), optional\n",
      " |          Specifies the one-based bottommost row and rightmost column that\n",
      " |          is to be frozen.\n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib`` as header options. For other URLs (e.g.\n",
      " |          starting with \"s3://\", and \"gcs://\") the key-value pairs are forwarded to\n",
      " |          ``fsspec``. Please see ``fsspec`` and ``urllib`` for more details.\n",
      " |      \n",
      " |          .. versionadded:: 1.2.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
      " |      ExcelWriter : Class for writing DataFrame objects into excel sheets.\n",
      " |      read_excel : Read an Excel file into a pandas DataFrame.\n",
      " |      read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For compatibility with :meth:`~DataFrame.to_csv`,\n",
      " |      to_excel serializes lists and dicts to strings before writing.\n",
      " |      \n",
      " |      Once a workbook has been saved it is not possible to write further\n",
      " |      data without rewriting the whole workbook.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Create, write to and save a workbook:\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame([['a', 'b'], ['c', 'd']],\n",
      " |      ...                    index=['row 1', 'row 2'],\n",
      " |      ...                    columns=['col 1', 'col 2'])\n",
      " |      >>> df1.to_excel(\"output.xlsx\")  # doctest: +SKIP\n",
      " |      \n",
      " |      To specify the sheet name:\n",
      " |      \n",
      " |      >>> df1.to_excel(\"output.xlsx\",\n",
      " |      ...              sheet_name='Sheet_name_1')  # doctest: +SKIP\n",
      " |      \n",
      " |      If you wish to write to more than one sheet in the workbook, it is\n",
      " |      necessary to specify an ExcelWriter object:\n",
      " |      \n",
      " |      >>> df2 = df1.copy()\n",
      " |      >>> with pd.ExcelWriter('output.xlsx') as writer:  # doctest: +SKIP\n",
      " |      ...     df1.to_excel(writer, sheet_name='Sheet_name_1')\n",
      " |      ...     df2.to_excel(writer, sheet_name='Sheet_name_2')\n",
      " |      \n",
      " |      ExcelWriter can also be used to append to an existing Excel file:\n",
      " |      \n",
      " |      >>> with pd.ExcelWriter('output.xlsx',\n",
      " |      ...                     mode='a') as writer:  # doctest: +SKIP\n",
      " |      ...     df.to_excel(writer, sheet_name='Sheet_name_3')\n",
      " |      \n",
      " |      To set the library that is used to write the Excel file,\n",
      " |      you can pass the `engine` keyword (the default engine is\n",
      " |      automatically chosen depending on the file extension):\n",
      " |      \n",
      " |      >>> df1.to_excel('output1.xlsx', engine='xlsxwriter')  # doctest: +SKIP\n",
      " |  \n",
      " |  to_hdf(self, path_or_buf, key: 'str', mode: 'str' = 'a', complevel: 'int | None' = None, complib: 'str | None' = None, append: 'bool_t' = False, format: 'str | None' = None, index: 'bool_t' = True, min_itemsize: 'int | dict[str, int] | None' = None, nan_rep=None, dropna: 'bool_t | None' = None, data_columns: 'bool_t | list[str] | None' = None, errors: 'str' = 'strict', encoding: 'str' = 'UTF-8') -> 'None'\n",
      " |      Write the contained data to an HDF5 file using HDFStore.\n",
      " |      \n",
      " |      Hierarchical Data Format (HDF) is self-describing, allowing an\n",
      " |      application to interpret the structure and contents of a file with\n",
      " |      no outside information. One HDF file can hold a mix of related objects\n",
      " |      which can be accessed as a group or as individual objects.\n",
      " |      \n",
      " |      In order to add another DataFrame or Series to an existing HDF file\n",
      " |      please use append mode and a different a key.\n",
      " |      \n",
      " |      .. warning::\n",
      " |      \n",
      " |         One can store a subclass of ``DataFrame`` or ``Series`` to HDF5,\n",
      " |         but the type of the subclass is lost upon storing.\n",
      " |      \n",
      " |      For more information see the :ref:`user guide <io.hdf5>`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : str or pandas.HDFStore\n",
      " |          File path or HDFStore object.\n",
      " |      key : str\n",
      " |          Identifier for the group in the store.\n",
      " |      mode : {'a', 'w', 'r+'}, default 'a'\n",
      " |          Mode to open file:\n",
      " |      \n",
      " |          - 'w': write, a new file is created (an existing file with\n",
      " |            the same name would be deleted).\n",
      " |          - 'a': append, an existing file is opened for reading and\n",
      " |            writing, and if the file does not exist it is created.\n",
      " |          - 'r+': similar to 'a', but the file must already exist.\n",
      " |      complevel : {0-9}, optional\n",
      " |          Specifies a compression level for data.\n",
      " |          A value of 0 disables compression.\n",
      " |      complib : {'zlib', 'lzo', 'bzip2', 'blosc'}, default 'zlib'\n",
      " |          Specifies the compression library to be used.\n",
      " |          As of v0.20.2 these additional compressors for Blosc are supported\n",
      " |          (default if no compressor specified: 'blosc:blosclz'):\n",
      " |          {'blosc:blosclz', 'blosc:lz4', 'blosc:lz4hc', 'blosc:snappy',\n",
      " |          'blosc:zlib', 'blosc:zstd'}.\n",
      " |          Specifying a compression library which is not available issues\n",
      " |          a ValueError.\n",
      " |      append : bool, default False\n",
      " |          For Table formats, append the input data to the existing.\n",
      " |      format : {'fixed', 'table', None}, default 'fixed'\n",
      " |          Possible values:\n",
      " |      \n",
      " |          - 'fixed': Fixed format. Fast writing/reading. Not-appendable,\n",
      " |            nor searchable.\n",
      " |          - 'table': Table format. Write as a PyTables Table structure\n",
      " |            which may perform worse but allow more flexible operations\n",
      " |            like searching / selecting subsets of the data.\n",
      " |          - If None, pd.get_option('io.hdf.default_format') is checked,\n",
      " |            followed by fallback to \"fixed\"\n",
      " |      errors : str, default 'strict'\n",
      " |          Specifies how encoding and decoding errors are to be handled.\n",
      " |          See the errors argument for :func:`open` for a full list\n",
      " |          of options.\n",
      " |      encoding : str, default \"UTF-8\"\n",
      " |      min_itemsize : dict or int, optional\n",
      " |          Map column names to minimum string sizes for columns.\n",
      " |      nan_rep : Any, optional\n",
      " |          How to represent null values as str.\n",
      " |          Not allowed with append=True.\n",
      " |      data_columns : list of columns or True, optional\n",
      " |          List of columns to create as indexed data columns for on-disk\n",
      " |          queries, or True to use all columns. By default only the axes\n",
      " |          of the object are indexed. See :ref:`io.hdf5-query-data-columns`.\n",
      " |          Applicable only to format='table'.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_hdf : Read from HDF file.\n",
      " |      DataFrame.to_parquet : Write a DataFrame to the binary parquet format.\n",
      " |      DataFrame.to_sql : Write to a SQL table.\n",
      " |      DataFrame.to_feather : Write out feather-format for DataFrames.\n",
      " |      DataFrame.to_csv : Write out to a csv file.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]},\n",
      " |      ...                   index=['a', 'b', 'c'])\n",
      " |      >>> df.to_hdf('data.h5', key='df', mode='w')\n",
      " |      \n",
      " |      We can add another object to the same file:\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s.to_hdf('data.h5', key='s')\n",
      " |      \n",
      " |      Reading from HDF file:\n",
      " |      \n",
      " |      >>> pd.read_hdf('data.h5', 'df')\n",
      " |      A  B\n",
      " |      a  1  4\n",
      " |      b  2  5\n",
      " |      c  3  6\n",
      " |      >>> pd.read_hdf('data.h5', 's')\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Deleting file with data:\n",
      " |      \n",
      " |      >>> import os\n",
      " |      >>> os.remove('data.h5')\n",
      " |  \n",
      " |  to_json(self, path_or_buf: 'FilePathOrBuffer | None' = None, orient: 'str | None' = None, date_format: 'str | None' = None, double_precision: 'int' = 10, force_ascii: 'bool_t' = True, date_unit: 'str' = 'ms', default_handler: 'Callable[[Any], JSONSerializable] | None' = None, lines: 'bool_t' = False, compression: 'CompressionOptions' = 'infer', index: 'bool_t' = True, indent: 'int | None' = None, storage_options: 'StorageOptions' = None) -> 'str | None'\n",
      " |      Convert the object to a JSON string.\n",
      " |      \n",
      " |      Note NaN's and None will be converted to null and datetime objects\n",
      " |      will be converted to UNIX timestamps.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : str or file handle, optional\n",
      " |          File path or object. If not specified, the result is returned as\n",
      " |          a string.\n",
      " |      orient : str\n",
      " |          Indication of expected JSON string format.\n",
      " |      \n",
      " |          * Series:\n",
      " |      \n",
      " |              - default is 'index'\n",
      " |              - allowed values are: {'split', 'records', 'index', 'table'}.\n",
      " |      \n",
      " |          * DataFrame:\n",
      " |      \n",
      " |              - default is 'columns'\n",
      " |              - allowed values are: {'split', 'records', 'index', 'columns',\n",
      " |                'values', 'table'}.\n",
      " |      \n",
      " |          * The format of the JSON string:\n",
      " |      \n",
      " |              - 'split' : dict like {'index' -> [index], 'columns' -> [columns],\n",
      " |                'data' -> [values]}\n",
      " |              - 'records' : list like [{column -> value}, ... , {column -> value}]\n",
      " |              - 'index' : dict like {index -> {column -> value}}\n",
      " |              - 'columns' : dict like {column -> {index -> value}}\n",
      " |              - 'values' : just the values array\n",
      " |              - 'table' : dict like {'schema': {schema}, 'data': {data}}\n",
      " |      \n",
      " |              Describing the data, where data component is like ``orient='records'``.\n",
      " |      \n",
      " |      date_format : {None, 'epoch', 'iso'}\n",
      " |          Type of date conversion. 'epoch' = epoch milliseconds,\n",
      " |          'iso' = ISO8601. The default depends on the `orient`. For\n",
      " |          ``orient='table'``, the default is 'iso'. For all other orients,\n",
      " |          the default is 'epoch'.\n",
      " |      double_precision : int, default 10\n",
      " |          The number of decimal places to use when encoding\n",
      " |          floating point values.\n",
      " |      force_ascii : bool, default True\n",
      " |          Force encoded string to be ASCII.\n",
      " |      date_unit : str, default 'ms' (milliseconds)\n",
      " |          The time unit to encode to, governs timestamp and ISO8601\n",
      " |          precision.  One of 's', 'ms', 'us', 'ns' for second, millisecond,\n",
      " |          microsecond, and nanosecond respectively.\n",
      " |      default_handler : callable, default None\n",
      " |          Handler to call if object cannot otherwise be converted to a\n",
      " |          suitable format for JSON. Should receive a single argument which is\n",
      " |          the object to convert and return a serialisable object.\n",
      " |      lines : bool, default False\n",
      " |          If 'orient' is 'records' write out line-delimited json format. Will\n",
      " |          throw ValueError if incorrect 'orient' since others are not\n",
      " |          list-like.\n",
      " |      \n",
      " |      compression : {'infer', 'gzip', 'bz2', 'zip', 'xz', None}\n",
      " |      \n",
      " |          A string representing the compression to use in the output file,\n",
      " |          only used when the first argument is a filename. By default, the\n",
      " |          compression is inferred from the filename.\n",
      " |      index : bool, default True\n",
      " |          Whether to include the index values in the JSON string. Not\n",
      " |          including the index (``index=False``) is only supported when\n",
      " |          orient is 'split' or 'table'.\n",
      " |      indent : int, optional\n",
      " |         Length of whitespace used to indent each record.\n",
      " |      \n",
      " |         .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib`` as header options. For other URLs (e.g.\n",
      " |          starting with \"s3://\", and \"gcs://\") the key-value pairs are forwarded to\n",
      " |          ``fsspec``. Please see ``fsspec`` and ``urllib`` for more details.\n",
      " |      \n",
      " |          .. versionadded:: 1.2.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      None or str\n",
      " |          If path_or_buf is None, returns the resulting json format as a\n",
      " |          string. Otherwise returns None.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_json : Convert a JSON string to pandas object.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The behavior of ``indent=0`` varies from the stdlib, which does not\n",
      " |      indent the output but does insert newlines. Currently, ``indent=0``\n",
      " |      and the default ``indent=None`` are equivalent in pandas, though this\n",
      " |      may change in a future release.\n",
      " |      \n",
      " |      ``orient='table'`` contains a 'pandas_version' field under 'schema'.\n",
      " |      This stores the version of `pandas` used in the latest revision of the\n",
      " |      schema.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import json\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     [[\"a\", \"b\"], [\"c\", \"d\"]],\n",
      " |      ...     index=[\"row 1\", \"row 2\"],\n",
      " |      ...     columns=[\"col 1\", \"col 2\"],\n",
      " |      ... )\n",
      " |      \n",
      " |      >>> result = df.to_json(orient=\"split\")\n",
      " |      >>> parsed = json.loads(result)\n",
      " |      >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      {\n",
      " |          \"columns\": [\n",
      " |              \"col 1\",\n",
      " |              \"col 2\"\n",
      " |          ],\n",
      " |          \"index\": [\n",
      " |              \"row 1\",\n",
      " |              \"row 2\"\n",
      " |          ],\n",
      " |          \"data\": [\n",
      " |              [\n",
      " |                  \"a\",\n",
      " |                  \"b\"\n",
      " |              ],\n",
      " |              [\n",
      " |                  \"c\",\n",
      " |                  \"d\"\n",
      " |              ]\n",
      " |          ]\n",
      " |      }\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'records'`` formatted JSON.\n",
      " |      Note that index labels are not preserved with this encoding.\n",
      " |      \n",
      " |      >>> result = df.to_json(orient=\"records\")\n",
      " |      >>> parsed = json.loads(result)\n",
      " |      >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      [\n",
      " |          {\n",
      " |              \"col 1\": \"a\",\n",
      " |              \"col 2\": \"b\"\n",
      " |          },\n",
      " |          {\n",
      " |              \"col 1\": \"c\",\n",
      " |              \"col 2\": \"d\"\n",
      " |          }\n",
      " |      ]\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'index'`` formatted JSON:\n",
      " |      \n",
      " |      >>> result = df.to_json(orient=\"index\")\n",
      " |      >>> parsed = json.loads(result)\n",
      " |      >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      {\n",
      " |          \"row 1\": {\n",
      " |              \"col 1\": \"a\",\n",
      " |              \"col 2\": \"b\"\n",
      " |          },\n",
      " |          \"row 2\": {\n",
      " |              \"col 1\": \"c\",\n",
      " |              \"col 2\": \"d\"\n",
      " |          }\n",
      " |      }\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'columns'`` formatted JSON:\n",
      " |      \n",
      " |      >>> result = df.to_json(orient=\"columns\")\n",
      " |      >>> parsed = json.loads(result)\n",
      " |      >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      {\n",
      " |          \"col 1\": {\n",
      " |              \"row 1\": \"a\",\n",
      " |              \"row 2\": \"c\"\n",
      " |          },\n",
      " |          \"col 2\": {\n",
      " |              \"row 1\": \"b\",\n",
      " |              \"row 2\": \"d\"\n",
      " |          }\n",
      " |      }\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'values'`` formatted JSON:\n",
      " |      \n",
      " |      >>> result = df.to_json(orient=\"values\")\n",
      " |      >>> parsed = json.loads(result)\n",
      " |      >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      [\n",
      " |          [\n",
      " |              \"a\",\n",
      " |              \"b\"\n",
      " |          ],\n",
      " |          [\n",
      " |              \"c\",\n",
      " |              \"d\"\n",
      " |          ]\n",
      " |      ]\n",
      " |      \n",
      " |      Encoding with Table Schema:\n",
      " |      \n",
      " |      >>> result = df.to_json(orient=\"table\")\n",
      " |      >>> parsed = json.loads(result)\n",
      " |      >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      {\n",
      " |          \"schema\": {\n",
      " |              \"fields\": [\n",
      " |                  {\n",
      " |                      \"name\": \"index\",\n",
      " |                      \"type\": \"string\"\n",
      " |                  },\n",
      " |                  {\n",
      " |                      \"name\": \"col 1\",\n",
      " |                      \"type\": \"string\"\n",
      " |                  },\n",
      " |                  {\n",
      " |                      \"name\": \"col 2\",\n",
      " |                      \"type\": \"string\"\n",
      " |                  }\n",
      " |              ],\n",
      " |              \"primaryKey\": [\n",
      " |                  \"index\"\n",
      " |              ],\n",
      " |              \"pandas_version\": \"0.20.0\"\n",
      " |          },\n",
      " |          \"data\": [\n",
      " |              {\n",
      " |                  \"index\": \"row 1\",\n",
      " |                  \"col 1\": \"a\",\n",
      " |                  \"col 2\": \"b\"\n",
      " |              },\n",
      " |              {\n",
      " |                  \"index\": \"row 2\",\n",
      " |                  \"col 1\": \"c\",\n",
      " |                  \"col 2\": \"d\"\n",
      " |              }\n",
      " |          ]\n",
      " |      }\n",
      " |  \n",
      " |  to_latex(self, buf=None, columns=None, col_space=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, bold_rows=False, column_format=None, longtable=None, escape=None, encoding=None, decimal='.', multicolumn=None, multicolumn_format=None, multirow=None, caption=None, label=None, position=None)\n",
      " |      Render object to a LaTeX tabular, longtable, or nested table/tabular.\n",
      " |      \n",
      " |      Requires ``\\usepackage{booktabs}``.  The output can be copy/pasted\n",
      " |      into a main LaTeX document or read from an external file\n",
      " |      with ``\\input{table.tex}``.\n",
      " |      \n",
      " |      .. versionchanged:: 1.0.0\n",
      " |         Added caption and label arguments.\n",
      " |      \n",
      " |      .. versionchanged:: 1.2.0\n",
      " |         Added position argument, changed meaning of caption argument.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      buf : str, Path or StringIO-like, optional, default None\n",
      " |          Buffer to write to. If None, the output is returned as a string.\n",
      " |      columns : list of label, optional\n",
      " |          The subset of columns to write. Writes all columns by default.\n",
      " |      col_space : int, optional\n",
      " |          The minimum width of each column.\n",
      " |      header : bool or list of str, default True\n",
      " |          Write out the column names. If a list of strings is given,\n",
      " |          it is assumed to be aliases for the column names.\n",
      " |      index : bool, default True\n",
      " |          Write row names (index).\n",
      " |      na_rep : str, default 'NaN'\n",
      " |          Missing data representation.\n",
      " |      formatters : list of functions or dict of {str: function}, optional\n",
      " |          Formatter functions to apply to columns' elements by position or\n",
      " |          name. The result of each function must be a unicode string.\n",
      " |          List must be of length equal to the number of columns.\n",
      " |      float_format : one-parameter function or str, optional, default None\n",
      " |          Formatter for floating point numbers. For example\n",
      " |          ``float_format=\"%.2f\"`` and ``float_format=\"{:0.2f}\".format`` will\n",
      " |          both result in 0.1234 being formatted as 0.12.\n",
      " |      sparsify : bool, optional\n",
      " |          Set to False for a DataFrame with a hierarchical index to print\n",
      " |          every multiindex key at each row. By default, the value will be\n",
      " |          read from the config module.\n",
      " |      index_names : bool, default True\n",
      " |          Prints the names of the indexes.\n",
      " |      bold_rows : bool, default False\n",
      " |          Make the row labels bold in the output.\n",
      " |      column_format : str, optional\n",
      " |          The columns format as specified in `LaTeX table format\n",
      " |          <https://en.wikibooks.org/wiki/LaTeX/Tables>`__ e.g. 'rcl' for 3\n",
      " |          columns. By default, 'l' will be used for all columns except\n",
      " |          columns of numbers, which default to 'r'.\n",
      " |      longtable : bool, optional\n",
      " |          By default, the value will be read from the pandas config\n",
      " |          module. Use a longtable environment instead of tabular. Requires\n",
      " |          adding a \\usepackage{longtable} to your LaTeX preamble.\n",
      " |      escape : bool, optional\n",
      " |          By default, the value will be read from the pandas config\n",
      " |          module. When set to False prevents from escaping latex special\n",
      " |          characters in column names.\n",
      " |      encoding : str, optional\n",
      " |          A string representing the encoding to use in the output file,\n",
      " |          defaults to 'utf-8'.\n",
      " |      decimal : str, default '.'\n",
      " |          Character recognized as decimal separator, e.g. ',' in Europe.\n",
      " |      multicolumn : bool, default True\n",
      " |          Use \\multicolumn to enhance MultiIndex columns.\n",
      " |          The default will be read from the config module.\n",
      " |      multicolumn_format : str, default 'l'\n",
      " |          The alignment for multicolumns, similar to `column_format`\n",
      " |          The default will be read from the config module.\n",
      " |      multirow : bool, default False\n",
      " |          Use \\multirow to enhance MultiIndex rows. Requires adding a\n",
      " |          \\usepackage{multirow} to your LaTeX preamble. Will print\n",
      " |          centered labels (instead of top-aligned) across the contained\n",
      " |          rows, separating groups via clines. The default will be read\n",
      " |          from the pandas config module.\n",
      " |      caption : str or tuple, optional\n",
      " |          Tuple (full_caption, short_caption),\n",
      " |          which results in ``\\caption[short_caption]{full_caption}``;\n",
      " |          if a single string is passed, no short caption will be set.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |             Optionally allow caption to be a tuple ``(full_caption, short_caption)``.\n",
      " |      \n",
      " |      label : str, optional\n",
      " |          The LaTeX label to be placed inside ``\\label{}`` in the output.\n",
      " |          This is used with ``\\ref{}`` in the main ``.tex`` file.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      position : str, optional\n",
      " |          The LaTeX positional argument for tables, to be placed after\n",
      " |          ``\\begin{}`` in the output.\n",
      " |      \n",
      " |          .. versionadded:: 1.2.0\n",
      " |      \n",
      " |              Returns\n",
      " |              -------\n",
      " |              str or None\n",
      " |                  If buf is None, returns the result as a string. Otherwise returns\n",
      " |                  None.\n",
      " |          \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.to_string : Render a DataFrame to a console-friendly\n",
      " |          tabular output.\n",
      " |      DataFrame.to_html : Render a DataFrame as an HTML table.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(dict(name=['Raphael', 'Donatello'],\n",
      " |      ...                   mask=['red', 'purple'],\n",
      " |      ...                   weapon=['sai', 'bo staff']))\n",
      " |      >>> print(df.to_latex(index=False))  # doctest: +NORMALIZE_WHITESPACE\n",
      " |      \\begin{tabular}{lll}\n",
      " |       \\toprule\n",
      " |             name &    mask &    weapon \\\\\n",
      " |       \\midrule\n",
      " |          Raphael &     red &       sai \\\\\n",
      " |        Donatello &  purple &  bo staff \\\\\n",
      " |      \\bottomrule\n",
      " |      \\end{tabular}\n",
      " |  \n",
      " |  to_pickle(self, path, compression: 'CompressionOptions' = 'infer', protocol: 'int' = 5, storage_options: 'StorageOptions' = None) -> 'None'\n",
      " |      Pickle (serialize) object to file.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : str\n",
      " |          File path where the pickled object will be stored.\n",
      " |      compression : {'infer', 'gzip', 'bz2', 'zip', 'xz', None},         default 'infer'\n",
      " |          A string representing the compression to use in the output file. By\n",
      " |          default, infers from the file extension in specified path.\n",
      " |          Compression mode may be any of the following possible\n",
      " |          values: {‘infer’, ‘gzip’, ‘bz2’, ‘zip’, ‘xz’, None}. If compression\n",
      " |          mode is ‘infer’ and path_or_buf is path-like, then detect\n",
      " |          compression mode from the following extensions:\n",
      " |          ‘.gz’, ‘.bz2’, ‘.zip’ or ‘.xz’. (otherwise no compression).\n",
      " |          If dict given and mode is ‘zip’ or inferred as ‘zip’, other entries\n",
      " |          passed as additional compression options.\n",
      " |      protocol : int\n",
      " |          Int which indicates which protocol should be used by the pickler,\n",
      " |          default HIGHEST_PROTOCOL (see [1]_ paragraph 12.1.2). The possible\n",
      " |          values are 0, 1, 2, 3, 4, 5. A negative value for the protocol\n",
      " |          parameter is equivalent to setting its value to HIGHEST_PROTOCOL.\n",
      " |      \n",
      " |          .. [1] https://docs.python.org/3/library/pickle.html.\n",
      " |      \n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib`` as header options. For other URLs (e.g.\n",
      " |          starting with \"s3://\", and \"gcs://\") the key-value pairs are forwarded to\n",
      " |          ``fsspec``. Please see ``fsspec`` and ``urllib`` for more details.\n",
      " |      \n",
      " |          .. versionadded:: 1.2.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_pickle : Load pickled pandas object (or any object) from file.\n",
      " |      DataFrame.to_hdf : Write DataFrame to an HDF5 file.\n",
      " |      DataFrame.to_sql : Write DataFrame to a SQL database.\n",
      " |      DataFrame.to_parquet : Write a DataFrame to the binary parquet format.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> original_df = pd.DataFrame({\"foo\": range(5), \"bar\": range(5, 10)})\n",
      " |      >>> original_df\n",
      " |         foo  bar\n",
      " |      0    0    5\n",
      " |      1    1    6\n",
      " |      2    2    7\n",
      " |      3    3    8\n",
      " |      4    4    9\n",
      " |      >>> original_df.to_pickle(\"./dummy.pkl\")\n",
      " |      \n",
      " |      >>> unpickled_df = pd.read_pickle(\"./dummy.pkl\")\n",
      " |      >>> unpickled_df\n",
      " |         foo  bar\n",
      " |      0    0    5\n",
      " |      1    1    6\n",
      " |      2    2    7\n",
      " |      3    3    8\n",
      " |      4    4    9\n",
      " |      \n",
      " |      >>> import os\n",
      " |      >>> os.remove(\"./dummy.pkl\")\n",
      " |  \n",
      " |  to_sql(self, name: 'str', con, schema=None, if_exists: 'str' = 'fail', index: 'bool_t' = True, index_label=None, chunksize=None, dtype: 'DtypeArg | None' = None, method=None) -> 'None'\n",
      " |      Write records stored in a DataFrame to a SQL database.\n",
      " |      \n",
      " |      Databases supported by SQLAlchemy [1]_ are supported. Tables can be\n",
      " |      newly created, appended to, or overwritten.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : str\n",
      " |          Name of SQL table.\n",
      " |      con : sqlalchemy.engine.(Engine or Connection) or sqlite3.Connection\n",
      " |          Using SQLAlchemy makes it possible to use any DB supported by that\n",
      " |          library. Legacy support is provided for sqlite3.Connection objects. The user\n",
      " |          is responsible for engine disposal and connection closure for the SQLAlchemy\n",
      " |          connectable See `here                 <https://docs.sqlalchemy.org/en/13/core/connections.html>`_.\n",
      " |      \n",
      " |      schema : str, optional\n",
      " |          Specify the schema (if database flavor supports this). If None, use\n",
      " |          default schema.\n",
      " |      if_exists : {'fail', 'replace', 'append'}, default 'fail'\n",
      " |          How to behave if the table already exists.\n",
      " |      \n",
      " |          * fail: Raise a ValueError.\n",
      " |          * replace: Drop the table before inserting new values.\n",
      " |          * append: Insert new values to the existing table.\n",
      " |      \n",
      " |      index : bool, default True\n",
      " |          Write DataFrame index as a column. Uses `index_label` as the column\n",
      " |          name in the table.\n",
      " |      index_label : str or sequence, default None\n",
      " |          Column label for index column(s). If None is given (default) and\n",
      " |          `index` is True, then the index names are used.\n",
      " |          A sequence should be given if the DataFrame uses MultiIndex.\n",
      " |      chunksize : int, optional\n",
      " |          Specify the number of rows in each batch to be written at a time.\n",
      " |          By default, all rows will be written at once.\n",
      " |      dtype : dict or scalar, optional\n",
      " |          Specifying the datatype for columns. If a dictionary is used, the\n",
      " |          keys should be the column names and the values should be the\n",
      " |          SQLAlchemy types or strings for the sqlite3 legacy mode. If a\n",
      " |          scalar is provided, it will be applied to all columns.\n",
      " |      method : {None, 'multi', callable}, optional\n",
      " |          Controls the SQL insertion clause used:\n",
      " |      \n",
      " |          * None : Uses standard SQL ``INSERT`` clause (one per row).\n",
      " |          * 'multi': Pass multiple values in a single ``INSERT`` clause.\n",
      " |          * callable with signature ``(pd_table, conn, keys, data_iter)``.\n",
      " |      \n",
      " |          Details and a sample callable implementation can be found in the\n",
      " |          section :ref:`insert method <io.sql.method>`.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          When the table already exists and `if_exists` is 'fail' (the\n",
      " |          default).\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_sql : Read a DataFrame from a table.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Timezone aware datetime columns will be written as\n",
      " |      ``Timestamp with timezone`` type with SQLAlchemy if supported by the\n",
      " |      database. Otherwise, the datetimes will be stored as timezone unaware\n",
      " |      timestamps local to the original timezone.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] https://docs.sqlalchemy.org\n",
      " |      .. [2] https://www.python.org/dev/peps/pep-0249/\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Create an in-memory SQLite database.\n",
      " |      \n",
      " |      >>> from sqlalchemy import create_engine\n",
      " |      >>> engine = create_engine('sqlite://', echo=False)\n",
      " |      \n",
      " |      Create a table from scratch with 3 rows.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'name' : ['User 1', 'User 2', 'User 3']})\n",
      " |      >>> df\n",
      " |           name\n",
      " |      0  User 1\n",
      " |      1  User 2\n",
      " |      2  User 3\n",
      " |      \n",
      " |      >>> df.to_sql('users', con=engine)\n",
      " |      >>> engine.execute(\"SELECT * FROM users\").fetchall()\n",
      " |      [(0, 'User 1'), (1, 'User 2'), (2, 'User 3')]\n",
      " |      \n",
      " |      An `sqlalchemy.engine.Connection` can also be passed to `con`:\n",
      " |      \n",
      " |      >>> with engine.begin() as connection:\n",
      " |      ...     df1 = pd.DataFrame({'name' : ['User 4', 'User 5']})\n",
      " |      ...     df1.to_sql('users', con=connection, if_exists='append')\n",
      " |      \n",
      " |      This is allowed to support operations that require that the same\n",
      " |      DBAPI connection is used for the entire operation.\n",
      " |      \n",
      " |      >>> df2 = pd.DataFrame({'name' : ['User 6', 'User 7']})\n",
      " |      >>> df2.to_sql('users', con=engine, if_exists='append')\n",
      " |      >>> engine.execute(\"SELECT * FROM users\").fetchall()\n",
      " |      [(0, 'User 1'), (1, 'User 2'), (2, 'User 3'),\n",
      " |       (0, 'User 4'), (1, 'User 5'), (0, 'User 6'),\n",
      " |       (1, 'User 7')]\n",
      " |      \n",
      " |      Overwrite the table with just ``df2``.\n",
      " |      \n",
      " |      >>> df2.to_sql('users', con=engine, if_exists='replace',\n",
      " |      ...            index_label='id')\n",
      " |      >>> engine.execute(\"SELECT * FROM users\").fetchall()\n",
      " |      [(0, 'User 6'), (1, 'User 7')]\n",
      " |      \n",
      " |      Specify the dtype (especially useful for integers with missing values).\n",
      " |      Notice that while pandas is forced to store the data as floating point,\n",
      " |      the database supports nullable integers. When fetching the data with\n",
      " |      Python, we get back integer scalars.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, None, 2]})\n",
      " |      >>> df\n",
      " |           A\n",
      " |      0  1.0\n",
      " |      1  NaN\n",
      " |      2  2.0\n",
      " |      \n",
      " |      >>> from sqlalchemy.types import Integer\n",
      " |      >>> df.to_sql('integers', con=engine, index=False,\n",
      " |      ...           dtype={\"A\": Integer()})\n",
      " |      \n",
      " |      >>> engine.execute(\"SELECT * FROM integers\").fetchall()\n",
      " |      [(1,), (None,), (2,)]\n",
      " |  \n",
      " |  to_xarray(self)\n",
      " |      Return an xarray object from the pandas object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      xarray.DataArray or xarray.Dataset\n",
      " |          Data in the pandas structure converted to Dataset if the object is\n",
      " |          a DataFrame, or a DataArray if the object is a Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.to_hdf : Write DataFrame to an HDF5 file.\n",
      " |      DataFrame.to_parquet : Write a DataFrame to the binary parquet format.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the `xarray docs <https://xarray.pydata.org/en/stable/>`__\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('falcon', 'bird', 389.0, 2),\n",
      " |      ...                    ('parrot', 'bird', 24.0, 2),\n",
      " |      ...                    ('lion', 'mammal', 80.5, 4),\n",
      " |      ...                    ('monkey', 'mammal', np.nan, 4)],\n",
      " |      ...                   columns=['name', 'class', 'max_speed',\n",
      " |      ...                            'num_legs'])\n",
      " |      >>> df\n",
      " |           name   class  max_speed  num_legs\n",
      " |      0  falcon    bird      389.0         2\n",
      " |      1  parrot    bird       24.0         2\n",
      " |      2    lion  mammal       80.5         4\n",
      " |      3  monkey  mammal        NaN         4\n",
      " |      \n",
      " |      >>> df.to_xarray()\n",
      " |      <xarray.Dataset>\n",
      " |      Dimensions:    (index: 4)\n",
      " |      Coordinates:\n",
      " |        * index      (index) int64 0 1 2 3\n",
      " |      Data variables:\n",
      " |          name       (index) object 'falcon' 'parrot' 'lion' 'monkey'\n",
      " |          class      (index) object 'bird' 'bird' 'mammal' 'mammal'\n",
      " |          max_speed  (index) float64 389.0 24.0 80.5 nan\n",
      " |          num_legs   (index) int64 2 2 4 4\n",
      " |      \n",
      " |      >>> df['max_speed'].to_xarray()\n",
      " |      <xarray.DataArray 'max_speed' (index: 4)>\n",
      " |      array([389. ,  24. ,  80.5,   nan])\n",
      " |      Coordinates:\n",
      " |        * index    (index) int64 0 1 2 3\n",
      " |      \n",
      " |      >>> dates = pd.to_datetime(['2018-01-01', '2018-01-01',\n",
      " |      ...                         '2018-01-02', '2018-01-02'])\n",
      " |      >>> df_multiindex = pd.DataFrame({'date': dates,\n",
      " |      ...                               'animal': ['falcon', 'parrot',\n",
      " |      ...                                          'falcon', 'parrot'],\n",
      " |      ...                               'speed': [350, 18, 361, 15]})\n",
      " |      >>> df_multiindex = df_multiindex.set_index(['date', 'animal'])\n",
      " |      \n",
      " |      >>> df_multiindex\n",
      " |                         speed\n",
      " |      date       animal\n",
      " |      2018-01-01 falcon    350\n",
      " |                 parrot     18\n",
      " |      2018-01-02 falcon    361\n",
      " |                 parrot     15\n",
      " |      \n",
      " |      >>> df_multiindex.to_xarray()\n",
      " |      <xarray.Dataset>\n",
      " |      Dimensions:  (animal: 2, date: 2)\n",
      " |      Coordinates:\n",
      " |        * date     (date) datetime64[ns] 2018-01-01 2018-01-02\n",
      " |        * animal   (animal) object 'falcon' 'parrot'\n",
      " |      Data variables:\n",
      " |          speed    (date, animal) int64 350 18 361 15\n",
      " |  \n",
      " |  truncate(self: 'FrameOrSeries', before=None, after=None, axis=None, copy: 'bool_t' = True) -> 'FrameOrSeries'\n",
      " |      Truncate a Series or DataFrame before and after some index value.\n",
      " |      \n",
      " |      This is a useful shorthand for boolean indexing based on index\n",
      " |      values above or below certain thresholds.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      before : date, str, int\n",
      " |          Truncate all rows before this index value.\n",
      " |      after : date, str, int\n",
      " |          Truncate all rows after this index value.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, optional\n",
      " |          Axis to truncate. Truncates the index (rows) by default.\n",
      " |      copy : bool, default is True,\n",
      " |          Return a copy of the truncated section.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of caller\n",
      " |          The truncated Series or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Select a subset of a DataFrame by label.\n",
      " |      DataFrame.iloc : Select a subset of a DataFrame by position.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If the index being truncated contains only datetime values,\n",
      " |      `before` and `after` may be specified as strings instead of\n",
      " |      Timestamps.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c', 'd', 'e'],\n",
      " |      ...                    'B': ['f', 'g', 'h', 'i', 'j'],\n",
      " |      ...                    'C': ['k', 'l', 'm', 'n', 'o']},\n",
      " |      ...                   index=[1, 2, 3, 4, 5])\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |      1  a  f  k\n",
      " |      2  b  g  l\n",
      " |      3  c  h  m\n",
      " |      4  d  i  n\n",
      " |      5  e  j  o\n",
      " |      \n",
      " |      >>> df.truncate(before=2, after=4)\n",
      " |         A  B  C\n",
      " |      2  b  g  l\n",
      " |      3  c  h  m\n",
      " |      4  d  i  n\n",
      " |      \n",
      " |      The columns of a DataFrame can be truncated.\n",
      " |      \n",
      " |      >>> df.truncate(before=\"A\", after=\"B\", axis=\"columns\")\n",
      " |         A  B\n",
      " |      1  a  f\n",
      " |      2  b  g\n",
      " |      3  c  h\n",
      " |      4  d  i\n",
      " |      5  e  j\n",
      " |      \n",
      " |      For Series, only rows can be truncated.\n",
      " |      \n",
      " |      >>> df['A'].truncate(before=2, after=4)\n",
      " |      2    b\n",
      " |      3    c\n",
      " |      4    d\n",
      " |      Name: A, dtype: object\n",
      " |      \n",
      " |      The index values in ``truncate`` can be datetimes or string\n",
      " |      dates.\n",
      " |      \n",
      " |      >>> dates = pd.date_range('2016-01-01', '2016-02-01', freq='s')\n",
      " |      >>> df = pd.DataFrame(index=dates, data={'A': 1})\n",
      " |      >>> df.tail()\n",
      " |                           A\n",
      " |      2016-01-31 23:59:56  1\n",
      " |      2016-01-31 23:59:57  1\n",
      " |      2016-01-31 23:59:58  1\n",
      " |      2016-01-31 23:59:59  1\n",
      " |      2016-02-01 00:00:00  1\n",
      " |      \n",
      " |      >>> df.truncate(before=pd.Timestamp('2016-01-05'),\n",
      " |      ...             after=pd.Timestamp('2016-01-10')).tail()\n",
      " |                           A\n",
      " |      2016-01-09 23:59:56  1\n",
      " |      2016-01-09 23:59:57  1\n",
      " |      2016-01-09 23:59:58  1\n",
      " |      2016-01-09 23:59:59  1\n",
      " |      2016-01-10 00:00:00  1\n",
      " |      \n",
      " |      Because the index is a DatetimeIndex containing only dates, we can\n",
      " |      specify `before` and `after` as strings. They will be coerced to\n",
      " |      Timestamps before truncation.\n",
      " |      \n",
      " |      >>> df.truncate('2016-01-05', '2016-01-10').tail()\n",
      " |                           A\n",
      " |      2016-01-09 23:59:56  1\n",
      " |      2016-01-09 23:59:57  1\n",
      " |      2016-01-09 23:59:58  1\n",
      " |      2016-01-09 23:59:59  1\n",
      " |      2016-01-10 00:00:00  1\n",
      " |      \n",
      " |      Note that ``truncate`` assumes a 0 value for any unspecified time\n",
      " |      component (midnight). This differs from partial string slicing, which\n",
      " |      returns any partially matching dates.\n",
      " |      \n",
      " |      >>> df.loc['2016-01-05':'2016-01-10', :].tail()\n",
      " |                           A\n",
      " |      2016-01-10 23:59:55  1\n",
      " |      2016-01-10 23:59:56  1\n",
      " |      2016-01-10 23:59:57  1\n",
      " |      2016-01-10 23:59:58  1\n",
      " |      2016-01-10 23:59:59  1\n",
      " |  \n",
      " |  tshift(self: 'FrameOrSeries', periods: 'int' = 1, freq=None, axis: 'Axis' = 0) -> 'FrameOrSeries'\n",
      " |      Shift the time index, using the index's frequency if available.\n",
      " |      \n",
      " |      .. deprecated:: 1.1.0\n",
      " |          Use `shift` instead.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative.\n",
      " |      freq : DateOffset, timedelta, or str, default None\n",
      " |          Increment to use from the tseries module\n",
      " |          or time rule expressed as a string (e.g. 'EOM').\n",
      " |      axis : {0 or ‘index’, 1 or ‘columns’, None}, default 0\n",
      " |          Corresponds to the axis that contains the Index.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : Series/DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If freq is not specified then tries to use the freq or inferred_freq\n",
      " |      attributes of the index. If neither of those attributes exist, a\n",
      " |      ValueError is thrown\n",
      " |  \n",
      " |  tz_convert(self: 'FrameOrSeries', tz, axis=0, level=None, copy: 'bool_t' = True) -> 'FrameOrSeries'\n",
      " |      Convert tz-aware axis to target time zone.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      tz : str or tzinfo object\n",
      " |      axis : the axis to convert\n",
      " |      level : int, str, default None\n",
      " |          If axis is a MultiIndex, convert a specific level. Otherwise\n",
      " |          must be None.\n",
      " |      copy : bool, default True\n",
      " |          Also make a copy of the underlying data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      {klass}\n",
      " |          Object with time zone converted axis.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the axis is tz-naive.\n",
      " |  \n",
      " |  tz_localize(self: 'FrameOrSeries', tz, axis=0, level=None, copy: 'bool_t' = True, ambiguous='raise', nonexistent: 'str' = 'raise') -> 'FrameOrSeries'\n",
      " |      Localize tz-naive index of a Series or DataFrame to target time zone.\n",
      " |      \n",
      " |      This operation localizes the Index. To localize the values in a\n",
      " |      timezone-naive Series, use :meth:`Series.dt.tz_localize`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      tz : str or tzinfo\n",
      " |      axis : the axis to localize\n",
      " |      level : int, str, default None\n",
      " |          If axis ia a MultiIndex, localize a specific level. Otherwise\n",
      " |          must be None.\n",
      " |      copy : bool, default True\n",
      " |          Also make a copy of the underlying data.\n",
      " |      ambiguous : 'infer', bool-ndarray, 'NaT', default 'raise'\n",
      " |          When clocks moved backward due to DST, ambiguous times may arise.\n",
      " |          For example in Central European Time (UTC+01), when going from\n",
      " |          03:00 DST to 02:00 non-DST, 02:30:00 local time occurs both at\n",
      " |          00:30:00 UTC and at 01:30:00 UTC. In such a situation, the\n",
      " |          `ambiguous` parameter dictates how ambiguous times should be\n",
      " |          handled.\n",
      " |      \n",
      " |          - 'infer' will attempt to infer fall dst-transition hours based on\n",
      " |            order\n",
      " |          - bool-ndarray where True signifies a DST time, False designates\n",
      " |            a non-DST time (note that this flag is only applicable for\n",
      " |            ambiguous times)\n",
      " |          - 'NaT' will return NaT where there are ambiguous times\n",
      " |          - 'raise' will raise an AmbiguousTimeError if there are ambiguous\n",
      " |            times.\n",
      " |      nonexistent : str, default 'raise'\n",
      " |          A nonexistent time does not exist in a particular timezone\n",
      " |          where clocks moved forward due to DST. Valid values are:\n",
      " |      \n",
      " |          - 'shift_forward' will shift the nonexistent time forward to the\n",
      " |            closest existing time\n",
      " |          - 'shift_backward' will shift the nonexistent time backward to the\n",
      " |            closest existing time\n",
      " |          - 'NaT' will return NaT where there are nonexistent times\n",
      " |          - timedelta objects will shift nonexistent times by the timedelta\n",
      " |          - 'raise' will raise an NonExistentTimeError if there are\n",
      " |            nonexistent times.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Same type as the input.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the TimeSeries is tz-aware and tz is not None.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Localize local times:\n",
      " |      \n",
      " |      >>> s = pd.Series([1],\n",
      " |      ...               index=pd.DatetimeIndex(['2018-09-15 01:30:00']))\n",
      " |      >>> s.tz_localize('CET')\n",
      " |      2018-09-15 01:30:00+02:00    1\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Be careful with DST changes. When there is sequential data, pandas\n",
      " |      can infer the DST time:\n",
      " |      \n",
      " |      >>> s = pd.Series(range(7),\n",
      " |      ...               index=pd.DatetimeIndex(['2018-10-28 01:30:00',\n",
      " |      ...                                       '2018-10-28 02:00:00',\n",
      " |      ...                                       '2018-10-28 02:30:00',\n",
      " |      ...                                       '2018-10-28 02:00:00',\n",
      " |      ...                                       '2018-10-28 02:30:00',\n",
      " |      ...                                       '2018-10-28 03:00:00',\n",
      " |      ...                                       '2018-10-28 03:30:00']))\n",
      " |      >>> s.tz_localize('CET', ambiguous='infer')\n",
      " |      2018-10-28 01:30:00+02:00    0\n",
      " |      2018-10-28 02:00:00+02:00    1\n",
      " |      2018-10-28 02:30:00+02:00    2\n",
      " |      2018-10-28 02:00:00+01:00    3\n",
      " |      2018-10-28 02:30:00+01:00    4\n",
      " |      2018-10-28 03:00:00+01:00    5\n",
      " |      2018-10-28 03:30:00+01:00    6\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      In some cases, inferring the DST is impossible. In such cases, you can\n",
      " |      pass an ndarray to the ambiguous parameter to set the DST explicitly\n",
      " |      \n",
      " |      >>> s = pd.Series(range(3),\n",
      " |      ...               index=pd.DatetimeIndex(['2018-10-28 01:20:00',\n",
      " |      ...                                       '2018-10-28 02:36:00',\n",
      " |      ...                                       '2018-10-28 03:46:00']))\n",
      " |      >>> s.tz_localize('CET', ambiguous=np.array([True, True, False]))\n",
      " |      2018-10-28 01:20:00+02:00    0\n",
      " |      2018-10-28 02:36:00+02:00    1\n",
      " |      2018-10-28 03:46:00+01:00    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      If the DST transition causes nonexistent times, you can shift these\n",
      " |      dates forward or backward with a timedelta object or `'shift_forward'`\n",
      " |      or `'shift_backward'`.\n",
      " |      \n",
      " |      >>> s = pd.Series(range(2),\n",
      " |      ...               index=pd.DatetimeIndex(['2015-03-29 02:30:00',\n",
      " |      ...                                       '2015-03-29 03:30:00']))\n",
      " |      >>> s.tz_localize('Europe/Warsaw', nonexistent='shift_forward')\n",
      " |      2015-03-29 03:00:00+02:00    0\n",
      " |      2015-03-29 03:30:00+02:00    1\n",
      " |      dtype: int64\n",
      " |      >>> s.tz_localize('Europe/Warsaw', nonexistent='shift_backward')\n",
      " |      2015-03-29 01:59:59.999999999+01:00    0\n",
      " |      2015-03-29 03:30:00+02:00              1\n",
      " |      dtype: int64\n",
      " |      >>> s.tz_localize('Europe/Warsaw', nonexistent=pd.Timedelta('1H'))\n",
      " |      2015-03-29 03:30:00+02:00    0\n",
      " |      2015-03-29 03:30:00+02:00    1\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  xs(self, key, axis=0, level=None, drop_level: 'bool_t' = True)\n",
      " |      Return cross-section from the Series/DataFrame.\n",
      " |      \n",
      " |      This method takes a `key` argument to select data at a particular\n",
      " |      level of a MultiIndex.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : label or tuple of label\n",
      " |          Label contained in the index, or partially in a MultiIndex.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Axis to retrieve cross-section on.\n",
      " |      level : object, defaults to first n levels (n=1 or len(key))\n",
      " |          In case of a key partially contained in a MultiIndex, indicate\n",
      " |          which levels are used. Levels can be referred by label or position.\n",
      " |      drop_level : bool, default True\n",
      " |          If False, returns object with same levels as self.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Cross-section from the original Series or DataFrame\n",
      " |          corresponding to the selected index levels.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Access a group of rows and columns\n",
      " |          by label(s) or a boolean array.\n",
      " |      DataFrame.iloc : Purely integer-location based indexing\n",
      " |          for selection by position.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      `xs` can not be used to set values.\n",
      " |      \n",
      " |      MultiIndex Slicers is a generic way to get/set values on\n",
      " |      any level or levels.\n",
      " |      It is a superset of `xs` functionality, see\n",
      " |      :ref:`MultiIndex Slicers <advanced.mi_slicers>`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> d = {'num_legs': [4, 4, 2, 2],\n",
      " |      ...      'num_wings': [0, 0, 2, 2],\n",
      " |      ...      'class': ['mammal', 'mammal', 'mammal', 'bird'],\n",
      " |      ...      'animal': ['cat', 'dog', 'bat', 'penguin'],\n",
      " |      ...      'locomotion': ['walks', 'walks', 'flies', 'walks']}\n",
      " |      >>> df = pd.DataFrame(data=d)\n",
      " |      >>> df = df.set_index(['class', 'animal', 'locomotion'])\n",
      " |      >>> df\n",
      " |                                 num_legs  num_wings\n",
      " |      class  animal  locomotion\n",
      " |      mammal cat     walks              4          0\n",
      " |             dog     walks              4          0\n",
      " |             bat     flies              2          2\n",
      " |      bird   penguin walks              2          2\n",
      " |      \n",
      " |      Get values at specified index\n",
      " |      \n",
      " |      >>> df.xs('mammal')\n",
      " |                         num_legs  num_wings\n",
      " |      animal locomotion\n",
      " |      cat    walks              4          0\n",
      " |      dog    walks              4          0\n",
      " |      bat    flies              2          2\n",
      " |      \n",
      " |      Get values at several indexes\n",
      " |      \n",
      " |      >>> df.xs(('mammal', 'dog'))\n",
      " |                  num_legs  num_wings\n",
      " |      locomotion\n",
      " |      walks              4          0\n",
      " |      \n",
      " |      Get values at specified index and level\n",
      " |      \n",
      " |      >>> df.xs('cat', level=1)\n",
      " |                         num_legs  num_wings\n",
      " |      class  locomotion\n",
      " |      mammal walks              4          0\n",
      " |      \n",
      " |      Get values at several indexes and levels\n",
      " |      \n",
      " |      >>> df.xs(('bird', 'walks'),\n",
      " |      ...       level=[0, 'locomotion'])\n",
      " |               num_legs  num_wings\n",
      " |      animal\n",
      " |      penguin         2          2\n",
      " |      \n",
      " |      Get values at specified column and axis\n",
      " |      \n",
      " |      >>> df.xs('num_wings', axis=1)\n",
      " |      class   animal   locomotion\n",
      " |      mammal  cat      walks         0\n",
      " |              dog      walks         0\n",
      " |              bat      flies         2\n",
      " |      bird    penguin  walks         2\n",
      " |      Name: num_wings, dtype: int64\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  flags\n",
      " |      Get the properties associated with this pandas object.\n",
      " |      \n",
      " |      The available flags are\n",
      " |      \n",
      " |      * :attr:`Flags.allows_duplicate_labels`\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Flags : Flags that apply to pandas objects.\n",
      " |      DataFrame.attrs : Global metadata applying to this dataset.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      \"Flags\" differ from \"metadata\". Flags reflect properties of the\n",
      " |      pandas object (the Series or DataFrame). Metadata refer to properties\n",
      " |      of the dataset, and should be stored in :attr:`DataFrame.attrs`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2]})\n",
      " |      >>> df.flags\n",
      " |      <Flags(allows_duplicate_labels=True)>\n",
      " |      \n",
      " |      Flags can be get or set using ``.``\n",
      " |      \n",
      " |      >>> df.flags.allows_duplicate_labels\n",
      " |      True\n",
      " |      >>> df.flags.allows_duplicate_labels = False\n",
      " |      \n",
      " |      Or by slicing with a key\n",
      " |      \n",
      " |      >>> df.flags[\"allows_duplicate_labels\"]\n",
      " |      False\n",
      " |      >>> df.flags[\"allows_duplicate_labels\"] = True\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  attrs\n",
      " |      Dictionary of global attributes of this dataset.\n",
      " |      \n",
      " |      .. warning::\n",
      " |      \n",
      " |         attrs is experimental and may change without warning.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.flags : Global flags applying to this object.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.PandasObject:\n",
      " |  \n",
      " |  __sizeof__(self) -> 'int'\n",
      " |      Generates the total memory usage for an object that returns\n",
      " |      either a value or Series of values\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.accessor.DirNamesMixin:\n",
      " |  \n",
      " |  __dir__(self) -> 'list[str]'\n",
      " |      Provide method name lookup and completion.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Only provide 'public' methods.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from pandas.core.indexing.IndexingMixin:\n",
      " |  \n",
      " |  at\n",
      " |      Access a single value for a row/column label pair.\n",
      " |      \n",
      " |      Similar to ``loc``, in that both provide label-based lookups. Use\n",
      " |      ``at`` if you only need to get or set a single value in a DataFrame\n",
      " |      or Series.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError\n",
      " |          If 'label' does not exist in DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.iat : Access a single value for a row/column pair by integer\n",
      " |          position.\n",
      " |      DataFrame.loc : Access a group of rows and columns by label(s).\n",
      " |      Series.at : Access a single value using a label.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],\n",
      " |      ...                   index=[4, 5, 6], columns=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |          A   B   C\n",
      " |      4   0   2   3\n",
      " |      5   0   4   1\n",
      " |      6  10  20  30\n",
      " |      \n",
      " |      Get value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.at[4, 'B']\n",
      " |      2\n",
      " |      \n",
      " |      Set value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.at[4, 'B'] = 10\n",
      " |      >>> df.at[4, 'B']\n",
      " |      10\n",
      " |      \n",
      " |      Get value within a Series\n",
      " |      \n",
      " |      >>> df.loc[5].at['B']\n",
      " |      4\n",
      " |  \n",
      " |  iat\n",
      " |      Access a single value for a row/column pair by integer position.\n",
      " |      \n",
      " |      Similar to ``iloc``, in that both provide integer-based lookups. Use\n",
      " |      ``iat`` if you only need to get or set a single value in a DataFrame\n",
      " |      or Series.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      IndexError\n",
      " |          When integer position is out of bounds.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.at : Access a single value for a row/column label pair.\n",
      " |      DataFrame.loc : Access a group of rows and columns by label(s).\n",
      " |      DataFrame.iloc : Access a group of rows and columns by integer position(s).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],\n",
      " |      ...                   columns=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |          A   B   C\n",
      " |      0   0   2   3\n",
      " |      1   0   4   1\n",
      " |      2  10  20  30\n",
      " |      \n",
      " |      Get value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.iat[1, 2]\n",
      " |      1\n",
      " |      \n",
      " |      Set value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.iat[1, 2] = 10\n",
      " |      >>> df.iat[1, 2]\n",
      " |      10\n",
      " |      \n",
      " |      Get value within a series\n",
      " |      \n",
      " |      >>> df.loc[0].iat[1]\n",
      " |      2\n",
      " |  \n",
      " |  iloc\n",
      " |      Purely integer-location based indexing for selection by position.\n",
      " |      \n",
      " |      ``.iloc[]`` is primarily integer position based (from ``0`` to\n",
      " |      ``length-1`` of the axis), but may also be used with a boolean\n",
      " |      array.\n",
      " |      \n",
      " |      Allowed inputs are:\n",
      " |      \n",
      " |      - An integer, e.g. ``5``.\n",
      " |      - A list or array of integers, e.g. ``[4, 3, 0]``.\n",
      " |      - A slice object with ints, e.g. ``1:7``.\n",
      " |      - A boolean array.\n",
      " |      - A ``callable`` function with one argument (the calling Series or\n",
      " |        DataFrame) and that returns valid output for indexing (one of the above).\n",
      " |        This is useful in method chains, when you don't have a reference to the\n",
      " |        calling object, but would like to base your selection on some value.\n",
      " |      \n",
      " |      ``.iloc`` will raise ``IndexError`` if a requested indexer is\n",
      " |      out-of-bounds, except *slice* indexers which allow out-of-bounds\n",
      " |      indexing (this conforms with python/numpy *slice* semantics).\n",
      " |      \n",
      " |      See more at :ref:`Selection by Position <indexing.integer>`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.iat : Fast integer location scalar accessor.\n",
      " |      DataFrame.loc : Purely label-location based indexer for selection by label.\n",
      " |      Series.iloc : Purely integer-location based indexing for\n",
      " |                     selection by position.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> mydict = [{'a': 1, 'b': 2, 'c': 3, 'd': 4},\n",
      " |      ...           {'a': 100, 'b': 200, 'c': 300, 'd': 400},\n",
      " |      ...           {'a': 1000, 'b': 2000, 'c': 3000, 'd': 4000 }]\n",
      " |      >>> df = pd.DataFrame(mydict)\n",
      " |      >>> df\n",
      " |            a     b     c     d\n",
      " |      0     1     2     3     4\n",
      " |      1   100   200   300   400\n",
      " |      2  1000  2000  3000  4000\n",
      " |      \n",
      " |      **Indexing just the rows**\n",
      " |      \n",
      " |      With a scalar integer.\n",
      " |      \n",
      " |      >>> type(df.iloc[0])\n",
      " |      <class 'pandas.core.series.Series'>\n",
      " |      >>> df.iloc[0]\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      c    3\n",
      " |      d    4\n",
      " |      Name: 0, dtype: int64\n",
      " |      \n",
      " |      With a list of integers.\n",
      " |      \n",
      " |      >>> df.iloc[[0]]\n",
      " |         a  b  c  d\n",
      " |      0  1  2  3  4\n",
      " |      >>> type(df.iloc[[0]])\n",
      " |      <class 'pandas.core.frame.DataFrame'>\n",
      " |      \n",
      " |      >>> df.iloc[[0, 1]]\n",
      " |           a    b    c    d\n",
      " |      0    1    2    3    4\n",
      " |      1  100  200  300  400\n",
      " |      \n",
      " |      With a `slice` object.\n",
      " |      \n",
      " |      >>> df.iloc[:3]\n",
      " |            a     b     c     d\n",
      " |      0     1     2     3     4\n",
      " |      1   100   200   300   400\n",
      " |      2  1000  2000  3000  4000\n",
      " |      \n",
      " |      With a boolean mask the same length as the index.\n",
      " |      \n",
      " |      >>> df.iloc[[True, False, True]]\n",
      " |            a     b     c     d\n",
      " |      0     1     2     3     4\n",
      " |      2  1000  2000  3000  4000\n",
      " |      \n",
      " |      With a callable, useful in method chains. The `x` passed\n",
      " |      to the ``lambda`` is the DataFrame being sliced. This selects\n",
      " |      the rows whose index label even.\n",
      " |      \n",
      " |      >>> df.iloc[lambda x: x.index % 2 == 0]\n",
      " |            a     b     c     d\n",
      " |      0     1     2     3     4\n",
      " |      2  1000  2000  3000  4000\n",
      " |      \n",
      " |      **Indexing both axes**\n",
      " |      \n",
      " |      You can mix the indexer types for the index and columns. Use ``:`` to\n",
      " |      select the entire axis.\n",
      " |      \n",
      " |      With scalar integers.\n",
      " |      \n",
      " |      >>> df.iloc[0, 1]\n",
      " |      2\n",
      " |      \n",
      " |      With lists of integers.\n",
      " |      \n",
      " |      >>> df.iloc[[0, 2], [1, 3]]\n",
      " |            b     d\n",
      " |      0     2     4\n",
      " |      2  2000  4000\n",
      " |      \n",
      " |      With `slice` objects.\n",
      " |      \n",
      " |      >>> df.iloc[1:3, 0:3]\n",
      " |            a     b     c\n",
      " |      1   100   200   300\n",
      " |      2  1000  2000  3000\n",
      " |      \n",
      " |      With a boolean array whose length matches the columns.\n",
      " |      \n",
      " |      >>> df.iloc[:, [True, False, True, False]]\n",
      " |            a     c\n",
      " |      0     1     3\n",
      " |      1   100   300\n",
      " |      2  1000  3000\n",
      " |      \n",
      " |      With a callable function that expects the Series or DataFrame.\n",
      " |      \n",
      " |      >>> df.iloc[:, lambda df: [0, 2]]\n",
      " |            a     c\n",
      " |      0     1     3\n",
      " |      1   100   300\n",
      " |      2  1000  3000\n",
      " |  \n",
      " |  loc\n",
      " |      Access a group of rows and columns by label(s) or a boolean array.\n",
      " |      \n",
      " |      ``.loc[]`` is primarily label based, but may also be used with a\n",
      " |      boolean array.\n",
      " |      \n",
      " |      Allowed inputs are:\n",
      " |      \n",
      " |      - A single label, e.g. ``5`` or ``'a'``, (note that ``5`` is\n",
      " |        interpreted as a *label* of the index, and **never** as an\n",
      " |        integer position along the index).\n",
      " |      - A list or array of labels, e.g. ``['a', 'b', 'c']``.\n",
      " |      - A slice object with labels, e.g. ``'a':'f'``.\n",
      " |      \n",
      " |        .. warning:: Note that contrary to usual python slices, **both** the\n",
      " |            start and the stop are included\n",
      " |      \n",
      " |      - A boolean array of the same length as the axis being sliced,\n",
      " |        e.g. ``[True, False, True]``.\n",
      " |      - An alignable boolean Series. The index of the key will be aligned before\n",
      " |        masking.\n",
      " |      - An alignable Index. The Index of the returned selection will be the input.\n",
      " |      - A ``callable`` function with one argument (the calling Series or\n",
      " |        DataFrame) and that returns valid output for indexing (one of the above)\n",
      " |      \n",
      " |      See more at :ref:`Selection by Label <indexing.label>`.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError\n",
      " |          If any items are not found.\n",
      " |      IndexingError\n",
      " |          If an indexed key is passed and its index is unalignable to the frame index.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.at : Access a single value for a row/column label pair.\n",
      " |      DataFrame.iloc : Access group of rows and columns by integer position(s).\n",
      " |      DataFrame.xs : Returns a cross-section (row(s) or column(s)) from the\n",
      " |          Series/DataFrame.\n",
      " |      Series.loc : Access group of values using labels.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Getting values**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n",
      " |      ...      index=['cobra', 'viper', 'sidewinder'],\n",
      " |      ...      columns=['max_speed', 'shield'])\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra               1       2\n",
      " |      viper               4       5\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Single label. Note this returns the row as a Series.\n",
      " |      \n",
      " |      >>> df.loc['viper']\n",
      " |      max_speed    4\n",
      " |      shield       5\n",
      " |      Name: viper, dtype: int64\n",
      " |      \n",
      " |      List of labels. Note using ``[[]]`` returns a DataFrame.\n",
      " |      \n",
      " |      >>> df.loc[['viper', 'sidewinder']]\n",
      " |                  max_speed  shield\n",
      " |      viper               4       5\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Single label for row and column\n",
      " |      \n",
      " |      >>> df.loc['cobra', 'shield']\n",
      " |      2\n",
      " |      \n",
      " |      Slice with labels for row and single label for column. As mentioned\n",
      " |      above, note that both the start and stop of the slice are included.\n",
      " |      \n",
      " |      >>> df.loc['cobra':'viper', 'max_speed']\n",
      " |      cobra    1\n",
      " |      viper    4\n",
      " |      Name: max_speed, dtype: int64\n",
      " |      \n",
      " |      Boolean list with the same length as the row axis\n",
      " |      \n",
      " |      >>> df.loc[[False, False, True]]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Alignable boolean Series:\n",
      " |      \n",
      " |      >>> df.loc[pd.Series([False, True, False],\n",
      " |      ...        index=['viper', 'sidewinder', 'cobra'])]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Index (same behavior as ``df.reindex``)\n",
      " |      \n",
      " |      >>> df.loc[pd.Index([\"cobra\", \"viper\"], name=\"foo\")]\n",
      " |             max_speed  shield\n",
      " |      foo\n",
      " |      cobra          1       2\n",
      " |      viper          4       5\n",
      " |      \n",
      " |      Conditional that returns a boolean Series\n",
      " |      \n",
      " |      >>> df.loc[df['shield'] > 6]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Conditional that returns a boolean Series with column labels specified\n",
      " |      \n",
      " |      >>> df.loc[df['shield'] > 6, ['max_speed']]\n",
      " |                  max_speed\n",
      " |      sidewinder          7\n",
      " |      \n",
      " |      Callable that returns a boolean Series\n",
      " |      \n",
      " |      >>> df.loc[lambda df: df['shield'] == 8]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      **Setting values**\n",
      " |      \n",
      " |      Set value for all items matching the list of labels\n",
      " |      \n",
      " |      >>> df.loc[['viper', 'sidewinder'], ['shield']] = 50\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra               1       2\n",
      " |      viper               4      50\n",
      " |      sidewinder          7      50\n",
      " |      \n",
      " |      Set value for an entire row\n",
      " |      \n",
      " |      >>> df.loc['cobra'] = 10\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              10      10\n",
      " |      viper               4      50\n",
      " |      sidewinder          7      50\n",
      " |      \n",
      " |      Set value for an entire column\n",
      " |      \n",
      " |      >>> df.loc[:, 'max_speed'] = 30\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              30      10\n",
      " |      viper              30      50\n",
      " |      sidewinder         30      50\n",
      " |      \n",
      " |      Set value for rows matching callable condition\n",
      " |      \n",
      " |      >>> df.loc[df['shield'] > 35] = 0\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              30      10\n",
      " |      viper               0       0\n",
      " |      sidewinder          0       0\n",
      " |      \n",
      " |      **Getting values on a DataFrame with an index that has integer labels**\n",
      " |      \n",
      " |      Another example using integers for the index\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n",
      " |      ...      index=[7, 8, 9], columns=['max_speed', 'shield'])\n",
      " |      >>> df\n",
      " |         max_speed  shield\n",
      " |      7          1       2\n",
      " |      8          4       5\n",
      " |      9          7       8\n",
      " |      \n",
      " |      Slice with integer labels for rows. As mentioned above, note that both\n",
      " |      the start and stop of the slice are included.\n",
      " |      \n",
      " |      >>> df.loc[7:9]\n",
      " |         max_speed  shield\n",
      " |      7          1       2\n",
      " |      8          4       5\n",
      " |      9          7       8\n",
      " |      \n",
      " |      **Getting values with a MultiIndex**\n",
      " |      \n",
      " |      A number of examples using a DataFrame with a MultiIndex\n",
      " |      \n",
      " |      >>> tuples = [\n",
      " |      ...    ('cobra', 'mark i'), ('cobra', 'mark ii'),\n",
      " |      ...    ('sidewinder', 'mark i'), ('sidewinder', 'mark ii'),\n",
      " |      ...    ('viper', 'mark ii'), ('viper', 'mark iii')\n",
      " |      ... ]\n",
      " |      >>> index = pd.MultiIndex.from_tuples(tuples)\n",
      " |      >>> values = [[12, 2], [0, 4], [10, 20],\n",
      " |      ...         [1, 4], [7, 1], [16, 36]]\n",
      " |      >>> df = pd.DataFrame(values, columns=['max_speed', 'shield'], index=index)\n",
      " |      >>> df\n",
      " |                           max_speed  shield\n",
      " |      cobra      mark i           12       2\n",
      " |                 mark ii           0       4\n",
      " |      sidewinder mark i           10      20\n",
      " |                 mark ii           1       4\n",
      " |      viper      mark ii           7       1\n",
      " |                 mark iii         16      36\n",
      " |      \n",
      " |      Single label. Note this returns a DataFrame with a single index.\n",
      " |      \n",
      " |      >>> df.loc['cobra']\n",
      " |               max_speed  shield\n",
      " |      mark i          12       2\n",
      " |      mark ii          0       4\n",
      " |      \n",
      " |      Single index tuple. Note this returns a Series.\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark ii')]\n",
      " |      max_speed    0\n",
      " |      shield       4\n",
      " |      Name: (cobra, mark ii), dtype: int64\n",
      " |      \n",
      " |      Single label for row and column. Similar to passing in a tuple, this\n",
      " |      returns a Series.\n",
      " |      \n",
      " |      >>> df.loc['cobra', 'mark i']\n",
      " |      max_speed    12\n",
      " |      shield        2\n",
      " |      Name: (cobra, mark i), dtype: int64\n",
      " |      \n",
      " |      Single tuple. Note using ``[[]]`` returns a DataFrame.\n",
      " |      \n",
      " |      >>> df.loc[[('cobra', 'mark ii')]]\n",
      " |                     max_speed  shield\n",
      " |      cobra mark ii          0       4\n",
      " |      \n",
      " |      Single tuple for the index with a single label for the column\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark i'), 'shield']\n",
      " |      2\n",
      " |      \n",
      " |      Slice from index tuple to single label\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark i'):'viper']\n",
      " |                           max_speed  shield\n",
      " |      cobra      mark i           12       2\n",
      " |                 mark ii           0       4\n",
      " |      sidewinder mark i           10      20\n",
      " |                 mark ii           1       4\n",
      " |      viper      mark ii           7       1\n",
      " |                 mark iii         16      36\n",
      " |      \n",
      " |      Slice from index tuple to index tuple\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark i'):('viper', 'mark ii')]\n",
      " |                          max_speed  shield\n",
      " |      cobra      mark i          12       2\n",
      " |                 mark ii          0       4\n",
      " |      sidewinder mark i          10      20\n",
      " |                 mark ii          1       4\n",
      " |      viper      mark ii          7       1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f051c181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-03-06   -0.471385\n",
       "2012-03-07   -0.298714\n",
       "2012-03-08   -0.524158\n",
       "2012-03-09   -0.526058\n",
       "2012-03-10   -0.699619\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = pd.date_range('3/6/2012 00:00', periods=5, freq='D')\n",
    "ts = pd.Series(np.random.randn(len(rng)), rng)\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e64d2af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method tz_localize in module pandas.core.generic:\n",
      "\n",
      "tz_localize(tz, axis=0, level=None, copy: 'bool_t' = True, ambiguous='raise', nonexistent: 'str' = 'raise') -> 'FrameOrSeries' method of pandas.core.series.Series instance\n",
      "    Localize tz-naive index of a Series or DataFrame to target time zone.\n",
      "    \n",
      "    This operation localizes the Index. To localize the values in a\n",
      "    timezone-naive Series, use :meth:`Series.dt.tz_localize`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    tz : str or tzinfo\n",
      "    axis : the axis to localize\n",
      "    level : int, str, default None\n",
      "        If axis ia a MultiIndex, localize a specific level. Otherwise\n",
      "        must be None.\n",
      "    copy : bool, default True\n",
      "        Also make a copy of the underlying data.\n",
      "    ambiguous : 'infer', bool-ndarray, 'NaT', default 'raise'\n",
      "        When clocks moved backward due to DST, ambiguous times may arise.\n",
      "        For example in Central European Time (UTC+01), when going from\n",
      "        03:00 DST to 02:00 non-DST, 02:30:00 local time occurs both at\n",
      "        00:30:00 UTC and at 01:30:00 UTC. In such a situation, the\n",
      "        `ambiguous` parameter dictates how ambiguous times should be\n",
      "        handled.\n",
      "    \n",
      "        - 'infer' will attempt to infer fall dst-transition hours based on\n",
      "          order\n",
      "        - bool-ndarray where True signifies a DST time, False designates\n",
      "          a non-DST time (note that this flag is only applicable for\n",
      "          ambiguous times)\n",
      "        - 'NaT' will return NaT where there are ambiguous times\n",
      "        - 'raise' will raise an AmbiguousTimeError if there are ambiguous\n",
      "          times.\n",
      "    nonexistent : str, default 'raise'\n",
      "        A nonexistent time does not exist in a particular timezone\n",
      "        where clocks moved forward due to DST. Valid values are:\n",
      "    \n",
      "        - 'shift_forward' will shift the nonexistent time forward to the\n",
      "          closest existing time\n",
      "        - 'shift_backward' will shift the nonexistent time backward to the\n",
      "          closest existing time\n",
      "        - 'NaT' will return NaT where there are nonexistent times\n",
      "        - timedelta objects will shift nonexistent times by the timedelta\n",
      "        - 'raise' will raise an NonExistentTimeError if there are\n",
      "          nonexistent times.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    Series or DataFrame\n",
      "        Same type as the input.\n",
      "    \n",
      "    Raises\n",
      "    ------\n",
      "    TypeError\n",
      "        If the TimeSeries is tz-aware and tz is not None.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    Localize local times:\n",
      "    \n",
      "    >>> s = pd.Series([1],\n",
      "    ...               index=pd.DatetimeIndex(['2018-09-15 01:30:00']))\n",
      "    >>> s.tz_localize('CET')\n",
      "    2018-09-15 01:30:00+02:00    1\n",
      "    dtype: int64\n",
      "    \n",
      "    Be careful with DST changes. When there is sequential data, pandas\n",
      "    can infer the DST time:\n",
      "    \n",
      "    >>> s = pd.Series(range(7),\n",
      "    ...               index=pd.DatetimeIndex(['2018-10-28 01:30:00',\n",
      "    ...                                       '2018-10-28 02:00:00',\n",
      "    ...                                       '2018-10-28 02:30:00',\n",
      "    ...                                       '2018-10-28 02:00:00',\n",
      "    ...                                       '2018-10-28 02:30:00',\n",
      "    ...                                       '2018-10-28 03:00:00',\n",
      "    ...                                       '2018-10-28 03:30:00']))\n",
      "    >>> s.tz_localize('CET', ambiguous='infer')\n",
      "    2018-10-28 01:30:00+02:00    0\n",
      "    2018-10-28 02:00:00+02:00    1\n",
      "    2018-10-28 02:30:00+02:00    2\n",
      "    2018-10-28 02:00:00+01:00    3\n",
      "    2018-10-28 02:30:00+01:00    4\n",
      "    2018-10-28 03:00:00+01:00    5\n",
      "    2018-10-28 03:30:00+01:00    6\n",
      "    dtype: int64\n",
      "    \n",
      "    In some cases, inferring the DST is impossible. In such cases, you can\n",
      "    pass an ndarray to the ambiguous parameter to set the DST explicitly\n",
      "    \n",
      "    >>> s = pd.Series(range(3),\n",
      "    ...               index=pd.DatetimeIndex(['2018-10-28 01:20:00',\n",
      "    ...                                       '2018-10-28 02:36:00',\n",
      "    ...                                       '2018-10-28 03:46:00']))\n",
      "    >>> s.tz_localize('CET', ambiguous=np.array([True, True, False]))\n",
      "    2018-10-28 01:20:00+02:00    0\n",
      "    2018-10-28 02:36:00+02:00    1\n",
      "    2018-10-28 03:46:00+01:00    2\n",
      "    dtype: int64\n",
      "    \n",
      "    If the DST transition causes nonexistent times, you can shift these\n",
      "    dates forward or backward with a timedelta object or `'shift_forward'`\n",
      "    or `'shift_backward'`.\n",
      "    \n",
      "    >>> s = pd.Series(range(2),\n",
      "    ...               index=pd.DatetimeIndex(['2015-03-29 02:30:00',\n",
      "    ...                                       '2015-03-29 03:30:00']))\n",
      "    >>> s.tz_localize('Europe/Warsaw', nonexistent='shift_forward')\n",
      "    2015-03-29 03:00:00+02:00    0\n",
      "    2015-03-29 03:30:00+02:00    1\n",
      "    dtype: int64\n",
      "    >>> s.tz_localize('Europe/Warsaw', nonexistent='shift_backward')\n",
      "    2015-03-29 01:59:59.999999999+01:00    0\n",
      "    2015-03-29 03:30:00+02:00              1\n",
      "    dtype: int64\n",
      "    >>> s.tz_localize('Europe/Warsaw', nonexistent=pd.Timedelta('1H'))\n",
      "    2015-03-29 03:30:00+02:00    0\n",
      "    2015-03-29 03:30:00+02:00    1\n",
      "    dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ts.tz_localize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "51bae57d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-03-06 00:00:00+00:00   -0.471385\n",
       "2012-03-07 00:00:00+00:00   -0.298714\n",
       "2012-03-08 00:00:00+00:00   -0.524158\n",
       "2012-03-09 00:00:00+00:00   -0.526058\n",
       "2012-03-10 00:00:00+00:00   -0.699619\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_utc = ts.tz_localize('UTC')\n",
    "ts_utc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f363217b",
   "metadata": {},
   "source": [
    "转换成其它时区："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d8ee5d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-03-05 19:00:00-05:00   -0.471385\n",
       "2012-03-06 19:00:00-05:00   -0.298714\n",
       "2012-03-07 19:00:00-05:00   -0.524158\n",
       "2012-03-08 19:00:00-05:00   -0.526058\n",
       "2012-03-09 19:00:00-05:00   -0.699619\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_utc.tz_convert('US/Eastern')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ad9063",
   "metadata": {},
   "source": [
    "转换时间段："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e9cd3496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-01-31    1.335323\n",
       "2012-02-29   -0.792281\n",
       "2012-03-31    1.181952\n",
       "2012-04-30    0.280659\n",
       "2012-05-31    1.435059\n",
       "Freq: M, dtype: float64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = pd.date_range('1/1/2012', periods=5, freq='M')\n",
    "ts = pd.Series(np.random.randn(len(rng)), index=rng)\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "10e53c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method to_period in module pandas.core.series:\n",
      "\n",
      "to_period(freq=None, copy=True) -> 'Series' method of pandas.core.series.Series instance\n",
      "    Convert Series from DatetimeIndex to PeriodIndex.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    freq : str, default None\n",
      "        Frequency associated with the PeriodIndex.\n",
      "    copy : bool, default True\n",
      "        Whether or not to return a copy.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    Series\n",
      "        Series with index converted to PeriodIndex.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ts.to_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d49bfb9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-01    1.335323\n",
       "2012-02   -0.792281\n",
       "2012-03    1.181952\n",
       "2012-04    0.280659\n",
       "2012-05    1.435059\n",
       "Freq: M, dtype: float64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = ts.to_period()\n",
    "ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "87badfce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method to_timestamp in module pandas.core.series:\n",
      "\n",
      "to_timestamp(freq=None, how='start', copy=True) -> 'Series' method of pandas.core.series.Series instance\n",
      "    Cast to DatetimeIndex of Timestamps, at *beginning* of period.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    freq : str, default frequency of PeriodIndex\n",
      "        Desired frequency.\n",
      "    how : {'s', 'e', 'start', 'end'}\n",
      "        Convention for converting period to timestamp; start of period\n",
      "        vs. end.\n",
      "    copy : bool, default True\n",
      "        Whether or not to return a copy.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    Series with DatetimeIndex\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ps.to_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e4f47823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-01-01    1.335323\n",
       "2012-02-01   -0.792281\n",
       "2012-03-01    1.181952\n",
       "2012-04-01    0.280659\n",
       "2012-05-01    1.435059\n",
       "Freq: MS, dtype: float64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.to_timestamp()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ffcd13",
   "metadata": {},
   "source": [
    "**Pandas** 函数可以很方便地转换时间段与时间戳。下例把以 **11** 月为结束年份的季度频率转换为下一季度月末上午 **9** 点："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "50f2e839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function period_range in module pandas.core.indexes.period:\n",
      "\n",
      "period_range(start=None, end=None, periods: 'int | None' = None, freq=None, name=None) -> 'PeriodIndex'\n",
      "    Return a fixed frequency PeriodIndex.\n",
      "    \n",
      "    The day (calendar) is the default frequency.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    start : str or period-like, default None\n",
      "        Left bound for generating periods.\n",
      "    end : str or period-like, default None\n",
      "        Right bound for generating periods.\n",
      "    periods : int, default None\n",
      "        Number of periods to generate.\n",
      "    freq : str or DateOffset, optional\n",
      "        Frequency alias. By default the freq is taken from `start` or `end`\n",
      "        if those are Period objects. Otherwise, the default is ``\"D\"`` for\n",
      "        daily frequency.\n",
      "    name : str, default None\n",
      "        Name of the resulting PeriodIndex.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    PeriodIndex\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Of the three parameters: ``start``, ``end``, and ``periods``, exactly two\n",
      "    must be specified.\n",
      "    \n",
      "    To learn more about the frequency strings, please see `this link\n",
      "    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> pd.period_range(start='2017-01-01', end='2018-01-01', freq='M')\n",
      "    PeriodIndex(['2017-01', '2017-02', '2017-03', '2017-04', '2017-05', '2017-06',\n",
      "             '2017-07', '2017-08', '2017-09', '2017-10', '2017-11', '2017-12',\n",
      "             '2018-01'],\n",
      "            dtype='period[M]')\n",
      "    \n",
      "    If ``start`` or ``end`` are ``Period`` objects, they will be used as anchor\n",
      "    endpoints for a ``PeriodIndex`` with frequency matching that of the\n",
      "    ``period_range`` constructor.\n",
      "    \n",
      "    >>> pd.period_range(start=pd.Period('2017Q1', freq='Q'),\n",
      "    ...                 end=pd.Period('2017Q2', freq='Q'), freq='M')\n",
      "    PeriodIndex(['2017-03', '2017-04', '2017-05', '2017-06'],\n",
      "                dtype='period[M]')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.period_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2c90e328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1990Q1   -0.932629\n",
       "1990Q2   -0.347688\n",
       "1990Q3    1.497419\n",
       "1990Q4    0.934391\n",
       "1991Q1    1.552026\n",
       "1991Q2    2.195600\n",
       "1991Q3   -0.412707\n",
       "1991Q4   -0.556655\n",
       "1992Q1   -1.247738\n",
       "1992Q2   -0.514374\n",
       "1992Q3   -0.823748\n",
       "1992Q4    1.044517\n",
       "1993Q1    0.210748\n",
       "1993Q2    0.721734\n",
       "1993Q3   -2.019833\n",
       "1993Q4   -0.770188\n",
       "1994Q1    0.792026\n",
       "1994Q2    0.299494\n",
       "1994Q3   -1.282987\n",
       "1994Q4   -0.508985\n",
       "1995Q1   -1.566176\n",
       "1995Q2   -0.345332\n",
       "1995Q3    0.674558\n",
       "1995Q4    0.792798\n",
       "1996Q1    0.736296\n",
       "1996Q2   -0.292084\n",
       "1996Q3   -0.232718\n",
       "1996Q4    1.795516\n",
       "1997Q1   -0.903837\n",
       "1997Q2   -0.838623\n",
       "1997Q3    0.474351\n",
       "1997Q4   -0.590950\n",
       "1998Q1    1.409471\n",
       "1998Q2    0.116272\n",
       "1998Q3    2.241365\n",
       "1998Q4   -0.224811\n",
       "1999Q1   -0.629317\n",
       "1999Q2   -0.003193\n",
       "1999Q3   -0.470291\n",
       "1999Q4   -1.209214\n",
       "2000Q1    0.010653\n",
       "2000Q2    0.793817\n",
       "2000Q3    0.478392\n",
       "2000Q4   -0.170873\n",
       "Freq: Q-NOV, dtype: float64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prng = pd.period_range('1990Q1', '2000Q4', freq='Q-NOV')\n",
    "ts = pd.Series(np.random.randn(len(prng)), prng)\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c7e0c184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method asfreq in module pandas.core.indexes.period:\n",
      "\n",
      "asfreq(freq=None, how: 'str' = 'E') -> 'PeriodIndex' method of pandas.core.indexes.period.PeriodIndex instance\n",
      "    Convert the PeriodArray to the specified frequency `freq`.\n",
      "    \n",
      "    Equivalent to applying :meth:`pandas.Period.asfreq` with the given arguments\n",
      "    to each :class:`~pandas.Period` in this PeriodArray.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    freq : str\n",
      "        A frequency.\n",
      "    how : str {'E', 'S'}, default 'E'\n",
      "        Whether the elements should be aligned to the end\n",
      "        or start within pa period.\n",
      "    \n",
      "        * 'E', 'END', or 'FINISH' for end,\n",
      "        * 'S', 'START', or 'BEGIN' for start.\n",
      "    \n",
      "        January 31st ('END') vs. January 1st ('START') for example.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    PeriodArray\n",
      "        The transformed PeriodArray with the new frequency.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    pandas.arrays.PeriodArray.asfreq: Convert each Period in a PeriodArray to the given frequency.\n",
      "    Period.asfreq : Convert a :class:`~pandas.Period` object to the given frequency.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> pidx = pd.period_range('2010-01-01', '2015-01-01', freq='A')\n",
      "    >>> pidx\n",
      "    PeriodIndex(['2010', '2011', '2012', '2013', '2014', '2015'],\n",
      "    dtype='period[A-DEC]')\n",
      "    \n",
      "    >>> pidx.asfreq('M')\n",
      "    PeriodIndex(['2010-12', '2011-12', '2012-12', '2013-12', '2014-12',\n",
      "    '2015-12'], dtype='period[M]')\n",
      "    \n",
      "    >>> pidx.asfreq('M', how='S')\n",
      "    PeriodIndex(['2010-01', '2011-01', '2012-01', '2013-01', '2014-01',\n",
      "    '2015-01'], dtype='period[M]')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(prng.asfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "bbea29fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1990-03-01 09:00   -0.932629\n",
       "1990-06-01 09:00   -0.347688\n",
       "1990-09-01 09:00    1.497419\n",
       "1990-12-01 09:00    0.934391\n",
       "1991-03-01 09:00    1.552026\n",
       "Freq: H, dtype: float64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.index = (prng.asfreq('M', 'e') + 1).asfreq('H', 's') + 9\n",
    "ts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ffd853",
   "metadata": {},
   "source": [
    "## 类别型（Categoricals）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08653924",
   "metadata": {},
   "source": [
    "**Pandas** 的 **DataFrame** 里可以包含**类别数据**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "bd3c6338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>raw_grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id raw_grade\n",
       "0   1         a\n",
       "1   2         b\n",
       "2   3         b\n",
       "3   4         a\n",
       "4   5         a\n",
       "5   6         e"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"id\": [1, 2, 3, 4, 5, 6],\n",
    "                   \"raw_grade\": ['a', 'b', 'b', 'a', 'a', 'e']})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774d5378",
   "metadata": {},
   "source": [
    "将 **grade** 的**原生数据**转换为**类别型数据**："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "342bf820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    a\n",
       "1    b\n",
       "2    b\n",
       "3    a\n",
       "4    a\n",
       "5    e\n",
       "Name: grade, dtype: category\n",
       "Categories (3, object): ['a', 'b', 'e']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"grade\"] = df[\"raw_grade\"].astype(\"category\")\n",
    "df[\"grade\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9a311dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>raw_grade</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id raw_grade grade\n",
       "0   1         a     a\n",
       "1   2         b     b\n",
       "2   3         b     b\n",
       "3   4         a     a\n",
       "4   5         a     a\n",
       "5   6         e     e"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b745ffbf",
   "metadata": {},
   "source": [
    "用**有含义的名字**重命名不同类型，调用 **Series.cat.categories**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "900e2f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>raw_grade</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>very good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>b</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>a</td>\n",
       "      <td>very good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>a</td>\n",
       "      <td>very good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>e</td>\n",
       "      <td>very bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id raw_grade      grade\n",
       "0   1         a  very good\n",
       "1   2         b       good\n",
       "2   3         b       good\n",
       "3   4         a  very good\n",
       "4   5         a  very good\n",
       "5   6         e   very bad"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"grade\"].cat.categories = [\"very good\", \"good\", \"very bad\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb176eee",
   "metadata": {},
   "source": [
    "重新排序各类别，并添加**缺失类**，**Series.cat** 的方法**默认**返回新 **Series**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a04ce8b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    very good\n",
       "1         good\n",
       "2         good\n",
       "3    very good\n",
       "4    very good\n",
       "5     very bad\n",
       "Name: grade, dtype: category\n",
       "Categories (5, object): ['very bad', 'bad', 'medium', 'good', 'very good']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"grade\"] = df[\"grade\"].cat.set_categories([\"very bad\", \"bad\", \"medium\",\n",
    "                                              \"good\", \"very good\"])\n",
    "df[\"grade\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f3fbb486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>raw_grade</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>very good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>b</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>a</td>\n",
       "      <td>very good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>a</td>\n",
       "      <td>very good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>e</td>\n",
       "      <td>very bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id raw_grade      grade\n",
       "0   1         a  very good\n",
       "1   2         b       good\n",
       "2   3         b       good\n",
       "3   4         a  very good\n",
       "4   5         a  very good\n",
       "5   6         e   very bad"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddaca8f",
   "metadata": {},
   "source": [
    "注意，这里是**按生成类别时的顺序排序**，不是**按词汇排序**："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0ed356f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>raw_grade</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>e</td>\n",
       "      <td>very bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>b</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>very good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>a</td>\n",
       "      <td>very good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>a</td>\n",
       "      <td>very good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id raw_grade      grade\n",
       "5   6         e   very bad\n",
       "1   2         b       good\n",
       "2   3         b       good\n",
       "0   1         a  very good\n",
       "3   4         a  very good\n",
       "4   5         a  very good"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=\"grade\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9adebdd",
   "metadata": {},
   "source": [
    "按**类别列**分组（groupby）时，即便某类别为空，也会显示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b39b7b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "grade\n",
       "very bad     1\n",
       "bad          0\n",
       "medium       0\n",
       "good         2\n",
       "very good    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"grade\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7353c15",
   "metadata": {},
   "source": [
    "## 可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ee5a5628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ts = pd.Series(np.random.randn(1000),\n",
    "               index=pd.date_range('1/1/2000', periods=1000))\n",
    "ts = ts.cumsum()\n",
    "ts.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b9bb00",
   "metadata": {},
   "source": [
    "**DataFrame** 的 **plot()** 方法可以快速绘制**所有带标签的列**："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "75afef0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEECAYAAADNv0QiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAACPBElEQVR4nO2ddXgUVxeH39nNxt1DEkhwJ0jRIqXFvVRoqbuXeulXoU6Nry7UPgptKTVoC8Xd3QkQIESIu2dlvj/uarJxD/M+T56M3Jm5u5OcuXPuOb8jybKMgoKCgkLrRNXUHVBQUFBQaDgUI6+goKDQilGMvIKCgkIrRjHyCgoKCq0YxcgrKCgotGIUI6+goKDQinGoj5NIkuQNfAP0BGTgLuA08AsQAcQCN8iynFXZefz9/eWIiIj66JKCgoLCZcOBAwfSZVkOsLdPqo84eUmSFgHbZFn+RpIkR8AVeAHIlGV5viRJzwM+siw/V9l5BgwYIO/fv7/O/VFQUFC4nJAk6YAsywPs7auzu0aSJE9gBPAtgCzLpbIsZwPTgEXGZouA6XW9loKCgoJCzagPn3x7IA34XpKkQ5IkfSNJkhsQJMtyEoDxd2A9XEtBQUFBoQbUh5F3APoBX8iy3BcoAJ6v7sGSJN0nSdJ+SZL2p6Wl1UN3FBQUFBRM1MfEawKQIMvyHuP6bwgjnyJJUogsy0mSJIUAqfYOlmV5IbAQhE++7H6tVktCQgLFxcX10NWGxdnZmbCwMDQaTVN3RUFBQQGoByMvy3KyJEnxkiR1kWX5NHA1cNL4czsw3/h7RW3On5CQgIeHBxEREUiSVNfuNhiyLJORkUFCQgKRkZFN3R0FBQUFoJ5CKIFHgR+NkTXngTsRrqBlkiTdDcQB19fmxMXFxc3ewANIkoSfnx+Ky0lBQaE5US9GXpblw4C98J2r6+P8zd3Am2gp/VRQaEhkWUZvkHFQK7mWzQHlLlSTP//8E0mSiI6ObuquKCg0az7ffI6O//mXwlIdL684zrD5G4l4fiWrjiU1ddcuSxQjX01+/vlnrrzySpYuXdrUXVFQaNb8b2csAK/9fZIfdl0kMbsIgB92xTZdpy5jFCNfDfLz89mxYwfffvutYuQVFKpAoxJuy6X74m22ezorUWdNQX1NvDYKr/59gpOXcuv1nN3bePLKlB6Vtlm+fDnjx4+nc+fO+Pr6cvDgQfr161ev/VBQaC2oVLZzU+/M7MUfBxOJyyxsoh5d3igj+Wrw888/M2vWLABmzZrFzz//3MQ9UlBovrg7WcaOQZ5O3HhFW3qGehGdnKf45ZuAFjWSr2rE3RBkZGSwceNGjh8/jiRJ6PV6JEni3XffVaJpFBTKUKzVE5Oazx1DI9gYncob03sC0KONJwAP/XiQ2PmTmrKLlx3KSL4KfvvtN2677TYuXrxIbGws8fHxREZGsn379qbumoJCsyM2owCdQaZ/Ox+2PnsVIzoL9dupfdo0cc8uXxQjXwU///wzM2bMsNk2c+ZMfvrppybqkYJC8yUhU0TShPm42Gx3UKu4c1gEAPEV+OZ1ekOD9u1ypUW5a5qCzZs3l9v22GOPNX5HFBRaAKZwyTAf13L7sgpKAViw7gz/vTHKZt8Pu2J5ecUJ5l/bi1kD2yLLsuIOrSeUkbyCgkK9kZhdhJODCn93x3L7nh7XBRATs3OWHuJIfLZ538srTgCw/lQqKbnF9H51Lf8cvdQofW7tKEZeQUGh3thwKoVATye7o3DT6H7x7ossP3yJaZ/tMO8zPRRCvJzZGJ1KXrGO5YcUI18fKEZeQUGhzpy8lEufV9dyLq0AV031vcBJOUUUlOhIzxeunMW7L3I2JR8AB5XirqkPFCOvoKBQZ1YcSSSnSAvA7UMjKmy35ZlRNutD3t7I078esdm2+riIpc8qLK3XPl6uKEZeQUGhzhSU6MzLXYLdK2zXzs+NMd2DbLb9ezzZZv1SjigQdDAui/T8knrs5eWJYuQVFBTqTGaBZdTt7Vp+0tWahbf2Z8szo8wJUibWPjGCXqFegHDVaPUyJ+pZxuRyRDHy1UCtVhMVFUWfPn3o168fO3fubOouKSg0OMVafYUx7WWxNvJeLpULkUmSRDs/N1Y+Npwh7f0AGNM9iM5BHozvGQzAbUMiADibkleLnitYo8TJVwMXFxcOHz4MwJo1a5g7dy5btmxp2k4pKDQw0z/bQXRyHuffmlhOdKwsidlF+Ls7MTDSB98qRvLWqI3nHd7JHxD+fB9XR67rH8aS3Rd5Z3U0d18ZqcTM1wFlJF9DcnNz8fHxaepuKCg0ONHJYhSdmmfrF88t1lJUqjev5xRqic8s4q4rI/h8dv8qHwjWlOjEedr6ivBKdycHbh7UFkcHFaV6A1q9zPHE8i6bixkF3PW/fcSmF9T4c11utKyR/L/PQ/Kx+j1ncC+YML/SJkVFRURFRVFcXExSUhIbN26s3z4oKDRjftpzkSfHdjGv9563FoCNT42kfYA7sRnC0HYK9Kjxufu19WFfbBbt/NzK7ft8dj8e+vEg+y9mYpBl+oR7m/ct2x/PxuhU2vm5NolwYUtCGclXA5O7Jjo6mtWrV3Pbbbchy3JTd0tBocEwjbABtpxNNy9b/92P/mALH284y7VfiDmqEC/nGl/n6XFd+OfRK4n0L2/kJ/QMpmOgO6/+fZJpn+2wyZA9l1pg7Keid1MVLWskX8WIuzEYMmQI6enppKWlERgY2NTdUVBoEEwx775ujhxLyCa3WIuns4bk3GKbdgvWnTEv18bIa9QqehojasoiSRIRfm7EpIrkqGmf7eDvR66kV5gX+caQzbxind1jFSy0LCPfDIiOjkav1+Pn59fUXVFQaDBWHhUJSRN6BvPjnjhmfLaDcT2C+XzzObvt2/m54utW/QnX6vLgqA6sP5ViXn/k54N4ODuYs2JzjQ8jhYpRjHw1MPnkQbyuLlq0CLVa3bSdUlCoR77dfoEuQR5caYxyOZUkJjsfGNmB7EItK48lmQ18n3BvXp7cjZlf7DIf//ejVzZIBEz/dj6cf2siWYWl9H9jPRczbEM6c4sVI18VipGvBnq9vupGCgrNjOjkXOIzi8plmJYlI7+E1/85CcD+F6/B392JlNwSeoV6Ee7rykezolh1PAlZhhGdA1h05xUYrKakPrwxqkGLdKtUEn7uTni5aMxuJEvfFemDqlAmXhUUWinTP9vBvT/sJzmnuMI2+SU6DsZlm9c3nkoFhHCYycfuoFZx+OWxRL8+nh/uGogkSahVEqffGM+2Z69iet/QBv0cJkyTs9/feYV5W1xmIRM+2qYEQlSCYuQVFFoheoNMsVZEntz8zW67bTadTqXnK2t4atlh87a1J5PJKdQSm15oE/Hi5aLBWWPronRyUBPuW744SEPx6c19WfnYlYzsFMDg9r48OaYzIFxLivxBxShGXkGhFZKUU2RePp9WQEpucTn/9Y+74wDILdbh5KBiWlQb1p9K5eZvdlOqN9AtxFZbpqkJ83GlRxsvVCqJpfcN4ZGrOuLqKB48l7KLqjj68kUx8goKrZBl+xMAeG58VwAGvbWB3vPWciQ+m1/2xSHLMoet4s7vHd6et2b0AjCPisvWaW1uqFQSm58eBUBKmazcD9aeZtx/tzZBr5ofipFXUGhl/HEwgY83nAVgcu8Qm1J80z7bwXO/HyMxu8hGxvfeEe1xc3Lgvzf2MW8L8HBqvE7XEj93J9QqiRTjvENusZaknCI+2RjD6ZQ81pxI5qaFu0nNrXheorWjRNcoKLQynlxmKcIR4uWMt6ujufKSiUU7YwF4a0YvCkt1ZuXI4Z0CzG383Zu/kVerJALcnUjJLaZYqzdLLpi4f/EBAJ79/Sjf3n6FWRDtckIZyVeT5ORkZs2aRYcOHejevTsTJ07kzJkzVR+ooNCIbIpOtVl3UKvsSv9+u/0C7QPcuHlQW+4Z3t683d/diWu6iUxuN6eWMQYM8nQiJa+EIW9vqLDN5tNp7DyXXuH+1ky9GXlJktSSJB2SJOkf47qvJEnrJEk6a/zdYqUbZVlmxowZjBo1inPnznHy5EneeustUlJSqj5YQaERWXMiGUcHFSseHsb5tyYC2B29GmSICvO2e44vbunPkVfGNmQ365VAT2d2xqSTVWg/MeqZcUJc7dZv92IwtK5Qy5xCLb/uj6+0TX2O5B8HTlmtPw9skGW5E7DBuN4i2bRpExqNhgceeMC8LSoqiuHDhzdhrxQUynMqOY8rInzoE+5tlvy9aFSJbGOMezdFzXQOtq8aqalg9N9cuapLIDqj8X5jek+m9mkDwLPju/Dt7QO4eWBbc9uTSXULtYxJzUOWZY4n5nDTwt3M/eNok8bov/r3CZ757WilberlfUySpDBgEvAm8KRx8zRglHF5EbAZeK4u13ln7ztEZ0bX5RTl6OrblecGVt6t48eP079//3q9roJCfZNdWMqZ5DxuvCLcZvuCG6I4kpDNvcPbU6ozEJ2cyx3f7TO7ZVo6U6Pa8MKfx3DRqLllcDv6t/Nh9fFkJvdqQ1s/Vxsj/MHa03x/58BaXScmNZ9rFmzloVEdzBIPu85n8OSYLk02SX0pp+rQ0fpyun0IPAtYDw2CZFlOApBlOUmSJLt/UZIk3QfcB9C2bVt7TRQUFKpAlmVeWnGCEp2+nJEf1tGfYR2FJo1GraJ/O1+OvTquKbrZILg7ObDysSsJ8RIhn91CPDnz5gTzfkmSGNs9iLUnU9h0Og1Zlmuls3M+TYiilRVpS8ktblQjL8sy136xk77hPiTlFBPq7cLFStrX2chLkjQZSJVl+YAkSaNqerwsywuBhQADBgyo9L2nqhF3Q9GjRw9+++23Jrm2gkJ1WHMimb+PXAJodklMjUGPNvblik0svG0AEc+vBCC7UIu7swNL98Yxo18Y7tWcYI7Psj9qTsktrlAuub6IzyzkVFIuY7oHMf3znRyJz+ZQXDYatcS9w9tTWdXp+vDJDwOmSpIUCywFRkuStARIkSQpBMD4O7XiUzRvRo8eTUlJCV9//bV52759+5Q6rwrNhjNG6d2xVYiRXc58MbsfIOrR7jmfyUsrTvDEL4erfXxchqXU4NAOfnQ1zmn858/jZBU0jFBasVbP30cucdPXu7lv8QE+3RhjUzxFq5eZ2Cuk0nPU2cjLsjxXluUwWZYjgFnARlmWbwH+Am43NrsdWFHXazUVkiTx559/sm7dOjp06ECPHj2YN28ebdq0aequKSgAkGk0Mp/c3LeJe9J8MZUYPJ9eYC5+crKamjeyLPPL/ng6B7nz4Y1RLLxtAKvnjAAgObeYZ38Xk595xVqGvL2BiOdXcuBiVp37/MXmczz68yESjG8RH6yzDdu+f2T7Kt8iGjIQdj6wTJKku4E44PoGvFaD06ZNG5YtW9bU3VBQsGHP+QwOxWfzv52xhHq74OSg1DmoiE5B7jiqVZxIzMHTGD1UpBUy4jtj0skp0jK+Z7Bdf/2u8xkUaw209XW1q7p5PDGHnEItfV6zJGPN/eMoa58YWac+f7LxrN3tS+8bTHt/NwI9q67GVa/JULIsb5ZlebJxOUOW5atlWe5k/J1Zn9dSUFCAGxfuZv6/IuIsURHpqhSNWkWwlzPJucWcSckDxBtQTpGWm7/Zw4M/HmTdSfu5L5tPpwHw9rW9bbbffWUkAOn5Jdz0ta3aZ0FJ1XUoPtsUw6t/n7C7L7Og1Kzbv3vu1ebtjmoVPdp4VsvAgyJroKDQamjugmLNAV83RzILSjmWmIOzRkWx1sCfBxPM+8vKPwBc+/kODsZl0znIvVwUzQsTu+HjquH9tWdqFYP/3prTADw2uhM+ZconmmrbdghwI9jLmS9m96NbiCft/FxrFB2kyBooKLRQUvNsRbd+vGdQE/Wk5eDr5sj5tAKyC7WM7xEMwA+7LQGIeXbKCZqKqrT3dy+3T62SaB9g2d4nzOIfd3Sovnnt+/o6ftojpJ9lWeatVadYfjgRgP8Z4/on9Aohwt+txuGfipFXUGihrD9pCVi7a1ikeWJRoWJ8XB3Nbq0rjWJs59MKGNDOB0cHlXkC20SpzmBeHhjpa/ecflYj8Gv7hZmX84p1lfal7APl7VVCMCC3SMfCref5aU8cKglCvev2hqYYeQWFFsqhuCwkCe4f0Z6nxnZu6u60CEwlDQFGdPY3Lz8yuiMB7k4cScimWGvxpR9NyDYv92hjP/8gyMo3Hmx1/pyi0golDx7e8DD3rrvTZpupZXqBRQJ6QISvWZ6itihGXkGhhZKUU0yfMG/mTuzWYhQjm5p2fqJcoa+bI4Eeziy8tT9/P3Ilo7oEMjWqDbvPZ9L1pdXmuPdVx5LNx1ZU6jDCqkxiiJcz9w6PxFGtQquXya1gNL81YSsnMo8ABrOAnCQJV026sQDKY6M7svTewXX+zIqRrwZqtZqoqCh69OhBnz59WLBgAQaDoeoDFRQakIyCUpuCIApVM6yjPz3aeLLkbjF/MbZHML2MfvSnx3Yxt+v7+jriMgo5GGeJdQ+qJJol2Lgv2NOZ/0zqzsLbhNbVtZ/v4Eh8Nicu5Zjb5pRYlh08j/DTPYN4dWoP8op1nEsr4NcDYiJ4Yu+QOo/iQYmuqRYuLi4cPnwYgNTUVG6++WZycnJ49dVXm7ZjCpclm0+ncsf3+5Ak6BV6+UkY1IU23i6sfMy+emxZSebFu2M5HJ/NhJ7BvH99n0oLjiy+eyArDl8yR9/0ayeU1c+lFTDtsx0AxM6fBMDJjJPm41xCf8HT5VGu6hLIK4gM3GOJOYzoHEDnQPsqoTVFGcnXkMDAQBYuXMinn37apBKjCpcv76wWYXeyDL5uzb96U0viqi6WylimaJenxnau0h3WKciDp8d1MUe+eDpXLNVsMvKeDkKzsdCQTLivC04OKo4lilH+wlv718soHlrYSD75rbcoOVW/UsNO3boS/MILNTqmffv2GAwGUlNTCQpStEIUGhfrqIxwXyU2vj75fHZ/MgtLmfzxNrIKtbTzc6VjLUfUW5+5ikd/PsiRBGG4c4u1eDprOJlxklD3ULo63MmG7DeQVXnka/Px89BxKUuFj6sGZ039ZS4rI/laooziFZoKawMQqYRN1isujmpCvV0Y0VmM6APrICHc1s+VhbcNMK/3nreWmNQ8TmWeortfd3LyhR8/syST6SumkxcsBpuV+f5rQ4saydd0xN1QnD9/HrVaTWBg6yi6oNCyUFslw5h8vwr1y1NjurD3QiZPWU3G1oYgT2fuGhbJdzsuALBkz2ni8+KZ2n46X+3QQxikF6WTWmjMeZBK612bvkUZ+eZAWloaDzzwAI888kitCg8oKNSV/BId1/YLZcENUU3dlVZLWz9XdlnpxdSFu66MwNtVw7qTKeyMOwPuoDEEkZWnwgN4e+/b5rZql3hSc/0qPNe3x75l56WdfDnmSzSq6pVoVIx8NSgqKiIqKgqtVouDgwO33norTz75ZNUHKig0ACbfrkLLIMzHlceu7sS+2Ex2JSXg4g7Zee5Acbm2KucEgr0qjo3/8OCHAJzOPE1P/57Vur7ik68Ger2ew4cPc+LECY4cOcLTTz+NSqV8dQqNj94gk1+iw9NZGZ81JX+d+4vVF1ab1wu1hdzw9w3sSNxR4TGppadwCV8MwL6zEl4uGh7s8yAAn139GR4aD8b0cmTBDX2qvH5mcfVFfZW/FAWFFkRGQQmyTJMVjlYQ/Gf7fwAYFT4KZwdn4vLiOJV5igfWP8Cx24+Va78mdg2XXD8AwKD1YHdMEQMjfHko6iEeinoIgCC3IByccvFzL39vd17aiaejJSeiJkZeGY4qKLQgUnJEynt1tcQVGhbThKl1Fqs1sizz5u43eXrL0+ZtRQl3AODvYZutHOYRxqb4Tby/7310BoscQl5pHvevu5+bVt5k3pZVXP2qU4qRV1BoQfxu1D4PVox8k6HVW/IUUgpFkRFro/vNsW84k3WGzw5/RmxuLEtPLzXvK7o0E0NxqPE8tmHY4yLGAbDo5CL+OveXefsvp3+xaeeocmTJqSUVPljK0iLcNbIst4hIFiV2XqG2GAwySbnFVcrKnk4WFY26BNdPyrtCzdmasNW8vDFuIxnFGfx65lfzto8OfsRHBz8CINBVhFm/deVbDA8dzm/7MtlyJo1tZ9NJzrGdeO3m2828/MrOVxgcMpiFRxeyPXG7Tbs5/efw7r53OZlxkiFthlTZ32Y/knd2diYjI6PZG1BZlsnIyMDZWRlhKdQMg0Hmlb9OMGz+RuIzCytsJ8sye2MzmdKnTb1mRCrUjDmb55iXl5xawjNbnmFv8l67baMzRIb+iLAReDt7c8/w9nw2ux8Aswe1tWkb4hZisz7u93H8fvZ389uCiTHtxgAQnxdfrf42+5F8WFgYCQkJpKWlNXVXqsTZ2ZmwsLCqGyooWPH2v6dYbKxOdDGjsEJJ22+2XUBvkHFXZIWbBb9N+Y2HNzxsNsJXt72aDXEbbNpcyL2Ak9rJZtLU01ljFiuzxlVj/74D/DjxR2avmg2ItwN3jTtH0o5wQ5cbquxns/9r0Wg0REZGNnU3FBQahLS8Er7edsG8vmhXLIPb++KgLv+SvWy/GLndfWVEY3VPAcguzubONXfyxrA36OwrirM81Ochuvh2YcnEJYz5TYys+wb2ZULkBPoE9GHZ6WV8fexrLuRcwN/Fv9ru5gf7PEihtpBuft14ftvz5u29A3qzfdZ2inXFqCQVw0KHsT95f7XO2eyNvIJCa2bVsSSb9XUnU1i6L55bBrez2V5YquNsaj5PXNO51oJZCrVjX8o+YrJjeHvv2/x31H8B8HEWchLBbsHsuXkPP0f/zKT2k/B3EdWmxkaM5etjX5NelE5UQFS1r2UKpwTo6d8TN42b2VXt5eSFl5PQvvd19iVPm1etczZ7n7yCQmtm0a5Y83KEsWrRIWPhaGs+XH8WgPYBiiBZY2MKkzTIBvYk7wGgnaflIeyqceXuXnebDTyAu8ZS3NvkQ68p7Tzb4e/iT4BrQLl97hp38krzOJhysMr5SmUkr6DQROQUaTmfVsCjozty/8gOuDs5cNt3e4lOzi3XduHW8wC08VYm9huL05mn2Z20m8T8RAAc1Y6czTqLg+TA4JDKy/JZT6L2D+pf733zcBRvc7evvp3nrniu0rbKSF5BoYnIKRTx1u383MyTqd2CPTibko9Ob1te0iRj0CfMu1H72NzYdWlXjbI968ITm5/g/f3vm6UK8kvzySvNw9PJs0ofu1ql5uUhLwMQ6VX/c4rujpY3BetKU/ZQjLyCQhORVyKMvHW0TOcgD0r1BmIzLKGUBoOMLMPtQ9rZnZC9XCjUFnLfuvsY+ctIPjzwISfST9jsN8gGu66LZaeX8eiGRwFYdGIR+5L3Vft6AHF5okLU6azTbE/cbhMpUxnXd76eY7cfqzRqprZYu4MyijMqbXv5/sUoKDQx+cUidd3DSmws0uhzj00vAIQgWZ9X15JXoiPU5/KuAmUdnvjt8W+Zu30uSfmWievr/r6OWStn2RxzJusMr+9+nc0JmzmUeoj397/PXWvuYtelXeXOH50ZTUqBJSbdQVXem51UkISbpunnRXydfc3LCXkJlbZVjLyCQiMjyzJZBaXklwgjbz2SN1V6is0QRj4jv4Q8Y7tpUaGN3NPmxepYofro4iAedhdyLjD297HEZMWg1Ws5m3WWkxknbTJS5++db16+7d/bzMv3rbuP8znnbc5//d/Xc81v15jXc0pyCHIN4qtrvmJy+8nm7ScybN8gmoI27m3My6Y3jYpQjLyCQiPzxC+H6f/GOs6m5gPgbjWS93ETolVvrDxFen4JZ1JEmy9v6VfvZeFaGqmFqQwOGczG6zfabE8pTCGn1KLj8vCGh81uG71BX+H5jqcfR5ZlTmScYEv8FvP2uNw4Vl9YTbG+mFldZzE0dCivDHnFPHqe1mFafX6sWhHsGlzttkp0jYJCNTiTkoeXi6bOhjYlt5jlhy8B8NWWcwB4udgvAPL3kUu8+reYVPO3Iz97OaE1aEkuSKaXfy/cHd35duy3bIjbwE/RP5FZnFlOrCs+L56kgiQOph5kUMggHol6hLaebckqzmL6iumAeBNYdGIRHxz4wObYH07+YBYF83ES8fDODs6smLYCSZLMsepNiUat4cOrPqS9V3umLa/8oaOM5BXqzPHEHAyG5q0tVFsKSnR8teUcY/+7lUFvbWDQW+v5fseFqg+sgD8OJpqXswq1DGjnU86Af3mLCLlbe8LiHw7zqf/Ju5aCzqCj3+J+ZJdkE+wmRrADQwaaE4de2P4CpzNPA3Bvr3sBSC5I5p619wAwIGgAUYFR+Dr70sG7A2tnrqWzT2dWxKzgj5g/yl3PWvXRz8VSis/b2btZGHgTV7e9mkivSGZ2nllpuzobeUmSwiVJ2iRJ0ilJkk5IkvS4cbuvJEnrJEk6a/ytVBxuheyLzWTyJ9vNhYpbA6+sOE7E8yuZ+NE23lx1irf/jTbvS8kt4dW/T/LMr0eqPI9Wb+C5346aJ1EB4jIL8XVzZHqU8Km62dGhGd8zmJsGtmXXeRE1MbJzAMFel6+rxnpyNcg1yLxsihUHOJ5xHIBwj3AAMkssYZZtPcoIgbmHMKvrLNKK0riQU/nfbd/AvrXveCPx4qAXK91fHyN5HfCULMvdgMHAw5IkdQeeBzbIstwJ2GBcV2hlnEoSiTvn0gqqaNlyWLRLiIWdTMrlpz32J7V+PZBAYanO7j4TJy7l8sv+eOb8cti8LT6zkHAfFx4Z3RGwZLmWpWOgJUQuq7C0Jt1vdVhPLJrkBABUkorXhr4GWBQZwzyEQOC62HUADAsdxoTICeXO2dWnq3l5/y0WDZgN12/g5q4389U1X7F4wuJmNXKvCLWqckXSOvvkZVlOApKMy3mSJJ0CQoFpwChjs0XAZqDy1CyFFkdmgTBAPq6to7B0UWnFE3VlycgvxdW34n8hlTFfJruwlI83nGVG31AOxWUxvW8oHQM9+O2BIfRoY9+IRIV7m5er0phv7cRkx5iX23u1t9l3RfAVAGyO3wxYRvKmB8PcgXPtJi5ZSwU4qZ1w17iTr80nwCWAuYPm1mf3m5x69clLkhQB9AX2AEHGB4DpQRBYwTH3SZK0X5Kk/S1BTljBlr0XGif7sLFIzROFHF6d2sO8bXLvEKJfH8/jV3fiwxujzNu3x6RXei5TiGRsRiEL1p1h0sfbKCjVM6KzMDADInxxcbQ/CusT5sWkXiE8NaYz82f2rstHavGczjxNoEsgB289aB6pm/B0siQmOUgOBLoGopJUJOaJuY+KEpf8nP1s1v+e8TffjfuuRRQnqin1Fl0jSZI78DswR5bl3Op+WbIsLwQWAgwYMKB1zt61UuIzC81+47ziyl0XLYXD8dmAqLzk5+ZIRkEpIV7OOGvUPDGmMwUlOkK8nEnKKWbuH8cY2z3IbuHlixkFxBhDJE3kGr+jQZG+5dqXxUGtMheXuNw5nXWaLr5d0KjKvy1aZ366alxRSSq8HL3IKhHl+Kz99tZo1OJcDpIwgf4u/jYCY62JehnJS5KkQRj4H2VZNk1Xp0iSFGLcHwKk1se1FJqOg3FZJGQV8t32C2QXlvLGypM4O6hxVKvILdZWfYIWwLqTKQR7OjMwwhcvowsq2MviLnFzcmDT06PQqMUgpv8b6/l663n0ZaKLRr63mZdXiKSZKyJsYw4qCplUKM/57POcyTpDF98udverJJXZRWOaYDW5Ytw0bnazVk0sGr+Iv2f8Xc89bn7UR3SNBHwLnJJleYHVrr+A243LtwMr6nothaYjJjWfaz/fyfgPt/HaPycZ9+FW1p5M4Z7hkXQJ9iC3qPkZ+VKdgYKS6r9h7I/N5N/jyfRr541KJdHeX4wSQ8pEtjhr1Cy731Jb881Vp3h3tSUCJzXXtnbnZzf3I9zX8qBojS6BhmLaChED3sXHvpEH+OKaL+gT0IcPRol49yJdEWDxz1dEv6B+5dw/rZH6GMkPA24FRkuSdNj4MxGYD4yRJOksMMa4rtACKSrV889RkcBj8jOn5JagUau4dUg7PF0czK6IpuJ4Yg4Rz69k8a5YSnRi8vSeH/bT45U1LNsfz5gFW4h4fiWfbYph3H+3suJwos3xRaV6rvtyF3qDTDujtMDLk7vzzLgujOpSXs+7b1sfcxgkwKrjljC/3WXmKTycNXx4Y/MPxWvOdPfrXuG+dp7tWDJxiTnVf0iIeAB/MvqTRulbc6c+omu2AxUNTa6u6/kVas+bK08yumsQg9v72owe0/JKeGd1NC9N6m52SVREal4xA9/cYHdft2APAj2c8XTWkJaXb7dNYzH5E1HR/qUVJ0jMLub5CV3ZekZM5D/721Fzu/fWiKSZx5ce5pd98Uzt04ZZA9tyLNGSMWnSkmnr58rDV3Ws8JpTo9qYs1fjM4tIzy/Bz82R538/atPOxVFN/3Y+LH94GA4qZRRfE/xd/Onp15O2nm2rbmzkmSue4eG+D9uIeF3OKBmvrZBirZ6f98bx9bYL3PT1biLnrjJPKAJ8uP4Mvx1IYNIn23j+96N8aUyvt0d0kqXE2KguAax7YgQ3DRSvwR2MsdyezhoyC7Tl/NKNRVl52W1nK4/ScjNGtOw8l8HzfxwDhBCYiepm747sHMjzE7ry3R0DAJiz9DDn0wsoLNXT1teVAA8nugRZJv6iwr3pGdr8466bC6czT5NelG6uq1pdnB2cFQNvhaJd00JZeTSJ9PwSbh8aUW7frIW7bYw6wM974ogK9yYmNY8fjQk+CVlFLN0nkkjuH9Herq/YlIiz/smR5gSdDgHuNm08XRxIzy9h4kfbWD1nODvPZdCjjSfero51/ZjVIq+M312tksoV3bi+fxg6g4yTg4oXJ3en5ytrzPu2nkkj0/g5x/cI5jY736k91CqJB0Z2MD9ktsekE5cpNMhfndqDKzu1rmiNQ6mH6O3fu8rkm/qgUFvIdX9fB8CkyEkNfr3WjDKSb6E8/NNBXvnrRLlRZ3p+STkDD5CYXURidhHXLNhabh8IHRV7ZOQL4+fnZjHY06JC6R7iyYMjOwAW5cTTKXks2x/P7G/2MPCtDWjLGNr6olirp//r6/jjYIJNH0ca48+PJuTQ9aXVNsfcP7I9/70xivkze+Pu5ICzxvKn/+uBBLKMSV0f3RRV4+gXSZKYc00nAJ5aJuQOwn1d0ahVaFpJkY/9yfu57d/b+P7E9w1+rWNpxxj00yBAaNG0925fxREKldE6/gIvY0y64yYOXMyy2+5MSh4bTqXY3Qfw5ZZz5dwep5PzeO0foYJobfgCPJxY9fhwOhldEdYCW8/9LtwfpToDSdm2USb1xc5z6WQUlPLksiN0felfNkWL6Ny7r4zk6bHi1V5X5uFnipQx8fVtA8zLcRkFnLiUi4ezA04OtRul3j9CPPBMGcABrUg1slhXzJdHvwQwC4HVlNzSXDbFbaqy6DTA/hSLzMDkDpMraalQHRQj38Ipm3BTNnwP4JlxXUjNKzHHbUe/Pr5cm4Vbz7Mv1vYBMe5DMeqfdUU4qkomDMd1D2ZAu/L6cybXhT3S80vMxrkyirV6tp9N58Xlx7h/sfjnT8gqstpvMD+IAj2dyrmIXp7cneUPDyvX/+GdAsx1U09cyuXf48lM7h1CbSmbuVrVhHZL4vvj37MnaQ8gSuzVho8Pfsxjmx7j7/NVx6Un5ifirnFn6aSl5WQMFGqOYuRbIPlWPuizZYx8Wn4pkgQxb05g/ZMjiZ0/yexWMeGsUfPudb2Z0DOYPS9czb3DRaHhTzaepVgrwg9LdZZ/5ufGd6UyvFw1/PbgUN67zpJ+r5Jgq50J0GKtntPJedzw1S7u/N8+YlLzkGWZnAri7B9YcoBbvt3Dkt1xrDmRgt4gk55vX7CrS5AH1/UP4xGriJirugba6MBYs+rx4bw+vad51N+9Ah2Z6tLJOGdx34jWZZiyS7LNy2svrmXGihnVGpFbczRNRBwt2L+AvNI83tj9Bo9vfLxcu33J+/jl9C94O3nTw79Huf0KNUcx8i2QFKvR+sKt520MckZ+CT6ujjioVeaJUpVKYuGtQqM80l/EgN8wIJwvbulPkKczcyd0A2Db2XT6vb6OXecyzBouYPG5V8WUPm24aWA4yx8exsBIX7u6Nm+tOsW4D7dy3qha+d2OWD7eEEOfV9ea/eLWbD5t+6C4kJ5PWl75t5W1T4xAkiScNWqeHmdJnGnnW7EOe5iPK7cMaouj0W9u722kJqx9YgQf39TX7J9vLeRrbQcSMdkx5oSj6iDLMrG5sWhUGjKKM5i9aja/nP6FjfEb0eptH+4L9ot8SusHi0LdUIx8C0OWZVYdFYk37fxcySnScjrZEuZoitUuy9gewfzz6JX88eDQcvtUKokPru8DQGGpnpu+3m12ifxw18Bq981Zo+bta3sTFe5Nx0B3zqfl24z4DAaZH4wyviZ+2RfPf9efAYRuzLD5G1lp/Hz2RotTP93Bz3vjaR/gxiQr90qnQFuf+4/3DOLNGT0rdTOBmDSNfn08MW9OoFuIfTGr6iJJElP7tMHVsXUFrRVoC+jo3ZF+gRYtnTNZZ+i1qJdNPdWK2By/mSJdEU8PeBrARsM9uSDZpm2xXjzAGyOC53JBMfItjNXHk/lgnTCKz44TbpS0fMvINj2/tMJScT1DvSoclc/sH4av1T7Tg6NzkH2Bp6qI9Hcnt1hnroR008LdjHp/s02bAe18bGLrl+2PJzG7iCeWHeZSdhE9jGGODiqJXx8YgrNGRaFRCjjSz43Pbu7H8VfHceDFa8qFfw7r6M/sQe2q1VeVSsKhlUTB1CeZxeJNLF+bj4ejh03x6B9P/QiIeqpPbHqCUn3Fmvemgh4zO8/k4aiHbfbdvfZuFhywqKEUasU8zjvD36mfD6GgGPnmTGZBKa//c5LzaZbX5T1GF8hHs6KIausNQGpuCbIsc8NXuzhwMQt/j9pFdnx7+wDaG905r/x1AmeNiiDP2p2rfYA4z1O/HuGd1dHsOp9hnoid1CuE7c9dxUc32ab6/3tcjOpKdQZGvbfZbNCPzhvLFRG+5giZtr6uvD69JyCyU+2pQCqIN6EzWWfKbU8uSOb6v6/nfM55ADbGbeTF7S+iM1jmeg6nHmbkLyNZf3E9BaUFuGnccHWwuL5Wx1pCVNfHrWfVhVUV9iOtMI1Al0Cc1E7c3etucwk/gKSCJL4/LsIyi3XFXCq4xENRDzEsdFjtP7iCDYqRb8a8tPw4326/wOgPLJXkd55Lp29bb6ZFheLv7ogkwaWcYrIKtWYfeHwlUS2V0betDy9PsWiEFGsNtRbTsn4D+GKzbUbtfSPaE+bjalMMw8PZ4uJwUEmUGmPsQ7ycze4PV2MEy9PjutDmMi+kUR2Wxyxn5l8z2Xlpp832bYnbiM6MZtryaXx++HPe3fcuK86tsDHUu5N2A8LYpxen46Hx4I4edzAuYpzda5keGCZkWTaPylMLU83KkBqVxlyHtSxZxSK6y7rEn0LdUYx8M6ZsJufaE8mcSclnTHfxT+DkoKa9vxsfbzjLRat4+afGlkkDz7oICfupDkM6+HF1V7v1XWpEqLcLIzoHmCd6rbF2C216ehT3XBlJ7zAR2fLwVR2YPciiU9LWauL0KmO/OgfZ+t+bmr1Je3ly85O8t+89Fh5d2NTdMbM3eS9gWyMV4LVdr5mXvzjyBYn5wqX217m/2J+8H61eS3qRKIiy6OQikguSGRA8gHDPcN4f+b5d4a+4XNsyiR8d/IhBPw3i1V2vsuPSDhuBsekdpzOtwzSb9gbZYNaA93byruUnVrBH65ohamW4WGVl3vH9Xjoa5QTuHW4J0esZ6sW5tAKzq2NM9yCGdyqjmviRMbRxXg5V4eSg5ts7riDi+ZWE+dRttPzDXQPR6g3cs2g/W85YomSs5wwi/d14cXJ3Zn4hRpu9w7y5sqM/4UbjPi0q1Nz2wZEduKZbEF2CazdP0FC8vvt1YnNjzev39LoHldT046f8UuHm08uWkoY7E3eWa9fGrQ0qScWepD3sSdqDq4MrhTrbt8H+Qf3Ny6PCR/FQ1EN8fvhzjtx2hDmb5nAx13ZC/dvj3wLw25nfALi/9/3mfY5qR9648g3euPINFp9czLv73iWrOIvs4mzAto6rQt1RjHwzoESnR0LC0cFiGAwGGQ9nS0LN5tNpJGUX06+tt02q/DPjurDi8CUWbhWvy2/N6GV7cp3VhFhRNrh4Q14K/PMETP0Y3Mroq7zbHrpNZcNTb+BTD9ozGrWKRXcNZNe5DPq29aZEa7Bb8s4kD+zv7oSbkwP3DC8fa65SSU1m4N/Z+w7tvdtzbcdry0V+RHhG2Bj5i7kXifSKbOQe2hKfG8/mhM0AxObGMm/nPMa2G8v96++3abflxi34Ovuy7uI6ntz8JEA5Aw9CzteaB/s8yIN9HgTE59+RuAODbEAlqcpFRfUL7EeQm30XTN9AMS+z/uJ6XDXiwd4Sime3JJp+uKHAYz8foucra8gx6scUlupo/8IqfjuQYFOw4nRKHjP6htocW7bIs034ZE4ivGE1qs+IgZJ82PIOnF4JOz+27ciFrVCYAQe+p0OAu41bpa4M6eCHs0ZdYSbo/Gt7M6pLAD3a1C2Msa7oDDqzL9nEhosbWHJqCa/tes0mEsRE2XmL4+nHG7SP1eGTQxaXys+nfub3s7+XM/AAPk5i1Dym3ZgKz/XX9L8qrbAU4h5CqaHUHI2TVmSb22AdlVOWnv49CXUPZcelHZzNPouDyoEw99ZfyKMxUYx8M2DNiRRK9QYeXXqIBevO0P1li0Jil2APlj9siTQY2dnWXy5JEoPbW2RVbeLCz66xaUtGDPxxL+wXr9KknxWjehOLpliWa5jRWFd6hnrxvzsH4qxp2vjoF3e8yKCfBqE3iDcLWZaZs3mOef/K8yvLHZNTYusGe2H7Czy79VnzelZxFr+e+ZWntzyN1tDwFbRkWTZPhKokFTq5fEGXT0Z/wltXvmXzgFozcw1bbtzCvb3u5euxXzMxciIgRuqVEeAiBhImP35aoTDyHbxEpnVVPvae/j3ZFL+J749/T5BrEI7qxlEvvVxQjHwTUlCi4x2rsnFbz6Tx8YazNm0+uL4PXYM98HHVMDDCl7Z+5TM4F989iI1PjeTfx4fb7kg4YFmW1MKon7YKdTu9Cj6wmqQNsJIvKLIvdNZakWUZg2wwG/ETGULnJ6NYFCoPcQvh+s7Xk12SzY+nfjQn8RhkA7G5sYwOH82yycu4IvgKAP698C8JeQkk5icy4pcRvLbrNdbEriEmK6bBP8v6uPWczjrNnH5zzJEsnXwsWbgPRz3MqPBRTOkwxea4Nu5t8HX25bF+jzE4ZDBvXvkmO2/aWWWElakAdmqh0CIyGfshbUSFpqoebNYFtO0V61aoG4pPvonYEZPO078eISmnGH93J7ILS80aKj6uGsJ8XFl2/xCz/3rX3KsrlK3VqFW0L6Pxjl4Lx3+DblNg8kfw7Ri4dFDsG/QApJ4U7hmAkjxw8gBdMagdQV8Kh3+EoY82yGdvjszbNY8/zv5hXt95aSe9A3qbNVfevPJNkgqS+PXMr8zfO5+NcRsJ8wgzHzM2Yizd/LoxOGQw+5L3ATDhjwnlrhOdGU03v24N8hm0Bi2b4zebfeuzu80mtzSXmOwYXhz8IlctuwqA4WHDKzmLBQeVAx6OVc+BtPVsi4PkwN6kvYwIG2E28jd3uxl3R3dmdppZ6fFRAVH8eOpH2nm2Y/5wpUpofaMY+SZi9jdC1a+9vxtL7hnExI+3kW30yV/bL4yXJtvWtKyxGyP9rDDaXaeAmx/4dYRzxjJ+of0hajZ8Zfxnz7wAQT2FD7/zOIj+B/YuvGyMfKG20MbAgyXu+3DaYTQqDX0C+thUG9qbvNccoujr7MuESGHQQ9wqV7JMyE+oz64Dov+/nP7FZr5gcvvJODs44+zgzIdXfQjAqLBR7Ly0k26+9fuQ8XX2pXdAb/PbT3JhMipJRbBrcLkMV3uMixjH4JDBeDt712u/FASKu6aJCfF2po23C5/fbNEF6VUfJeLidhkvIDRpCBsApoxG9yAI6Q33G0fy/z4HiyaDQQsdroL+d0JBhngbuAy4Y/UdNuvhHuGczRJus7TCNAJdA3FUO9LBuwOrrl3F4JDBNu3bebYzh0xaZ4UCjG03lteGWuLSFx5dyKa4TfXa/4c2PGRj4Ie1GcbLQ14u127BVQvYOmtrg4R3BrkGcSrzFD+e+pFj6ccIcQtBo66e60WSJMXANyCKkW8k8kt05JfouJhRwJoTyTgZwyX/M1GM2Id29Cd2/iROvDqO6WUiaGpMegysegb8O0OAUZGxu1XySagx5tnHGOYXtxMu7hDL7kEQORy0BZB8rG79aCGcyjxlXp7ecTrpRenEZMewOnY1GUUZ+Dn7mfeHe4TzzghbXZWbu95sXg50FRPjvs6+/DrlVz4Y9QGj247GSW3JDXhs02N17rPeoEdn0JFbmsuBlAM2+74c8yUuDuVzHDQqDW6a8slp9YG/qz8F2gLm753PjsQdig58M0Jx1zQSd32/j8Px2eZ0fYDHru5E9zIhg25OdbwlsgyfDwJZDz1ngmnSLKALDH4IIkeCk9F/7+xp8cEDXP0KdB4P+cZiHvF7ILRf+Wu0Ikr0JTbrcwfOZXnMcgCe2fIMEZ4RRHhF2LSxdtvsuXmPOb4boFdALz4d/SmD2ww2G3YvJy/237Kfo2lHmb1qdp37/Nqu1/j1zK+4OLjw7VgRKfXhVR/y+5nfGR9ZviBMY9DJ21Ze+eZuN1fQUqGxUUbyjcDxxBz2xmbaGHgA7xrWEq0SvRZe9ba4ZQY/aLt//NvQpYwR8DdG10z/EoY/CWoNeIWCZyhcOlS//WuGWEe7vDb0NVw1rjbRHrG5sTbrZbE28CZGho+0Gbmb6OXfC2e1yHswyAYWHFjARwc/AkR0zxeHvyA2J7bS/moNWn498ysARboicxJWpGckn1/zOVM7TK30+IZicnvbMn0Dg6svUa3QsChGvhF4+99Tdre3sxMOWSdit1uWJ/8XnKvh2x9j9BeH9rfd7hMJp/6G3Ev1179miCns76XBLzG943QAfhj/AzM6zjC3sXbXmHioz0M2vvbqIEkScwfNBWBFzAq+P/493xz7hn/O/0NsbiyfH/mcGX/NqPQcJqkCE8fSj6GSVIR7hNeoL/WNRq3hzh53MihkEPtv2a/EujcjWp6Rl2VY8x9IOtrUPak2FYU+DutY8Qix2qx7GX6/Ryzv/sKy3T3YfvuydLwaXs6CgDKiZt5tQVsIC7rBvm/KHyfLcPx3KC0ov68FYapANCx0mDkePNwznNeGvYZaEhFN9kbyD0Y9yIxOlRtke4yPEG9SphE8wNxtc/nu+HeAJeN2w8UNdoum5JXm2awvj1lOqHtotSc5G5InBzzJN2O/sfsWo9B0tCwjbzBA4kHY9Sn8MK3q9s2EmNR8RnQWWYFtfV25tl8oNw4IF2GRJXlwYVvNT2owwIbXYcdHcOxXYXTj91j2u9dArlVl58/A0yoVfeVT5TNg43bDb3fBnw/UrN/NDFOykym935qxEWMB6jXyw1XjiofGg4ziDCI8I3h16KsA5nkAgFd2vsKczXPMIZrW5GmFkV8wagE+Tj4U6YqqzEhVuLxpWUZ+50fwzWixXJQJ70TC9g+btEvW6PSGcqOvvGItCVlF9GvrzaanR/HL/YNZcEMU75iKXm//rwhfrKmh3zIftr1vWS/KguJsGPsG3PkvhPWv8NBqoXG2XS+j50K80Bvn1F+QYasX39AUagv58+yfNS4mbQ/TiNpeNMprQ1/j+YHPMyJ0RJ2vY41JB2ZsxFiu7XRtuYgXU0EOk4KjNaaRvK+zr1lvpqldNQrNm5Zl5KPLVJ8pyoT1rzRNX8qQlldC/zfW89SyIwDkFGm5eHwnx797GJAZGOFLpCaLEE8r43lhK2z7QCyvfLJmejHW/neA5cZJVs9QaFe+jmuN8TeGXgYZVS2Lsm33x++zLG94te7XqwGfHPqEl3e+XK4YRk3JLc01L9tL3Xd2cGZ2t9l2J1frgskoj20n3hS+HvO13XbRmdEcTj1MXG4cHx/8mBPpJ0jIE8lUHo4ePD/wed688k3u7HlnvfZPoXXRsox8RWTFNnUPOJWUS06Rlj8OJZJfomP6Zztg2e0MSf2Fzg4pDPUvhP/2sB19H1piWU4/A+c3255UVwp/zyk//3B2nYhrd/GFwB5i2xljOTbPOsbYm+g2BW7/R0TcAPxyi2VfWdeQUcyLg4vhzFrIqf+sTsulZZacEt+badIU4GzWWT4//DnaGiRwmRKePh39af12sgo+vfpTlkxcQhdf8SDtFdCLJROXMHfgXHObbr7diM2N5dZ/b2XSn5P4+tjXzFo5i1d3vUqASwCRXpFo1BqmdphqU06vUTi92lYXSaFZ07KMvGnGvlOZEmTb/9s419droTDT7q4DFy2CXn8eTOBCegESYmQ+jMOQHS92Hv5J/JZlIT1gwtUf9n4NWktRbk6ugAPfizkIaw4uMp5DD1fcZbsvuIyefG2RJJEUZRrhmnRvABIPQGE6DDBeuzRffL6/HoGfrhcPswq+p7pi8qED5kIVq86v4tq/ruWLI18w+c/JnMg4wTW/XlNplab4vHhzpmuvgHr6zqqJj7MPfQL62GzrE9CHm7rexMiwkbT1aMvI8JEVHt/Nr1vTCXnpdfDzjRa3qUKzp3kZeVkWBqQi9CXQ/iq4+RfLNq+2jZeZ+esd8G6kXbfKisOJ5uWXVpxAwoCLJJKMXnH4Af6ZI3YWG10EC0daDOc18yB8kNB4/6Cz5fx5xrJtptFpUbaQG3AyJlD1udk2imb0i+BYz2GZpjcFEwn74ZurQe0Eo1+CTmPFG4hJRsHE+U3CIKyeW68j+12XLNcxTUx+c9wS/XOp4BLv7H2HlMIUPjn0idm9UZZDqZYcAOvkpqZEkiQ+vfpTVl67stKM0WFtmrDIdeoJy/KhH5uuHwrVpsGNvCRJ4yVJOi1JUowkSc9X2jgtGr4ebR4Fyts/IvP5G9AmGg1oST6yoxunU/LJunEFr3a6h6R2g2ofy13Wz1wRmRdEn6L/EeuJB+CbMUI+ACEZHJtRyBPXdDYX8Ziu2kGAlENykHHSLv2M+C3r4dJhSBK+ewbcBVc+Ae5GnfjiHMg1fl5jOTRKjGFzH/WB99qLvrgHi0nWzuPhno3wSjYMf7o230LlBHQW1wjsIV7T/zKKlulLwNXXkjC16hnb4zLOQ8Je2P05/FX3NH4Tf8b8iZPaiTHtxnAm6wwl+hJismK4r/d9vDT4JcDWgF/IuWD3PCa9+B8m/FBvfatPrgq/imGhw/h67Nccve0o84fPZ1DIIDZcv4FZXWc1XccyrKSSj//edP1QqDYNauQlSVIDnwETgO7ATZIkda+ofQo63vDzEdEa2fHo/p5HyvJjxN54A8VaPYbSfOIL1Iz7cCv9fornN91ani88BwVpIqQQoRFTLU79A++0EyGZRpbsvsgXm8+x6XQqF9KN8d+yDB9HiRG8iW+uFgbMWHwjJlUkqHQJ9uDXB4SG9lXqwxjcgwm+0RIPDQiDHbPesm6a1LMuw5dtLIpsegilnhSjYpPRP/MvtOkLagfxE9ZfuFWq0P2uNS4+YgT3842iLwBdjRmOM42jaFPfTBxdCr/cavwcdXPd6A167ll7D70W9WJf8j5mdJzBiLARlOhLOJp2FBmZYLdgbuhyA/f0usfm2LJVikyYCn109ulsd39T4+zgzJfXfMngkMFIksSk9pP4Zuw3BLoGNm39WFMkVeQIKEitvK1Cs6Ch/1oGAjGyLJ+XZbkUWApUGOCuzlMRudqVVZ/diPzxIC6sEbHluvRMbvloJfnZGSSWqFC7ncXBQ7hotDiINP7ibP49lkTPV9Zw8lJuRZewcOB78TtBRIno9AZeXH6cd1ZHc+f3+7j9O2OM8oUtFZ/j0I+w8ili4+OIkmLoEuxBG28XXp/ek9HeyajCBoBve3jssOUYgw6SrSZSTS6Z4N6WbXu+gld9LcY+N7F8FJFXI5ZIcykTQx7cC2Yaq0u1HwU9ryt/TEaM8NuDbZ3ZWrDk1BL2JFkmerv5dTMLgUVniqIrpqzUK4KusDn2lZ2v8PXR8tEr2SXZOEgO5VQjLys+6gPr51W8P/OCCFM2DYSO/wGb3hTL3u2Em7SRK4gp1JyGNvKhQLzVeoJxmxlJku6TJGm/JEn73Yug3zkZz41O3KHxQl9s0VD/Lf9WPKVCFhUm4dr2W5yD/gXgmD6ZO4MD4ew6dp4Tk3LrT6VQFoNBpv/r63jyl8Ok5ZUItwiIP+Tzm8lc+65N++LMRHJWzrNNuvIMg84TwNUPOo6BkhzY9w3T1g5nudPLtHXTwe4vuNV9P+6FieAnyp/hW6aoc+wOy7JporT7VHjeaNRPLhdunfi9EHYFuAWUn3wNKuMrb0j63iLeOHwixHpIlG0c/egXocskuHs9jHzeEnZpQldMXdiWaJtD0MWni9mPbppcNWWlBrhaatqa4s8/PlSmli2w49IOgtyCqqx61GopyRNRaZUFLSx/SLyF7flKrFu75EwP/i3vlj9OoVnR0CqU9v6DbB79siwvBBYC9HR2kQEkA/Q+IZVtCkCug77ctv0uzuy/uJHFu4W64o97LnL70Ai8rATAjl/KIaOglD8OJXIiPpU1JUa3Q0Eq/DANMS78EQ+KCJSy2OD0DJhCwaNugXFvgoOzxbhtWwAx62z6oU7cB6utph1MRhHgod2QdVG4PArTIXQAXP89eFhlljp7iSgb0wi4JEe4ZVx8LfVan7sIWReEoW0sgnrA3ERAFq/rHmVC9nwj4SZj1FD4FcJPn2I1GV7HUoK5JbmMChvF5oTNAHTw7mB2t5hkCUzhiKYRPggjX6AtL7uQWphKdGY0T/R/ok79atGknbEsx+4QuRXWD7zEA0KCGiD7oggYKEwXf5+TF0DYQFEIPvofGPVc4/ZdoUY09Eg+AbBOxwsDqpwl9c2HiftlCo1JiJKD8Lf/6e7GMR+rUbosm18Xn0rbSU9JVPNJyS2hz6trSc+3yMieS7MIOy3IfVropQMxF86bt+91ncMx53uEgbdm2GPg4m07eh02h7OTfqVEtgplW1KmzJmP1Qg+sJuoumTCK1Tow6jLPGe9y2Qvth0s2oGo0+rsJQx/Y49AVSpQqcVErLNn5W0nL4DpX4CHsUpSUWbtpBuMZJdk4+nkac5KdXZwxtfZF8k4hpjSfopZL8XTUfRtYuTEcsqIJk5miAd8v8DWLaNcKWlWonn/mwgrHrHdn2IcBIX0EQbfNOE65UNRm8AzBIY+Jlw2WRcbpcsKtaOhjfw+oJMkSZGSJDkCs4C/Kmqc5AvOXS0jr3VD1Ljeez+yTsUWZ2deDrCoATroZJbN1zN1jzDyfUoK+cfpRV6c2JUAD/EPv/aE5YHw3G9iZOlEKT1U4o/ygKET6jzLMyfQYDtJd6jrU8IFYSq8YY1KxUW3PiTIlYiMWY/kQRhm04SltQ/emo5jbNfbDrX431XqxjfutcErDKJuhjnH4VljdEtlcxtVkFOSg5eTF6uuXcXamWsBoXo4METI2Vqn9UuSxI6bdvDGlW8wp98cc+p/ka7I3MYUX39Zar7oSsSbVVq07fbDS2zXM86KvJSeM0W9gbTTYrt1sl2v6wFZhMsqNFsa1MjLsqwDHgHWAKeAZbIsn6iofb7kx4yu8ylVCV/8adcgLqaKSdTA//nSKUEY9Mf7Pc6yXsKXOGuLGOUXq4Txu8tzH3tnlhLrfDNxF8Qf5ldbzpm13HtLlpH7LkN3IlXl/fcASbIvB0JvEe6HCsgoKCEdIeeb3N5OsWJ7k6OmiVZTWb6yjHhaxM0D9L5RjJjaRIl1fd0mMBsdtYMIs/TrBKn25Zar4vPDn1OoK8TL0Qt/F39C3C01VD00osi09TYQo3mNSoMkSYwKHwUIF02Rrohdl3axPGY5vs6+l2fJud/vhnciYOcnwv041TjXEzYQtEWw5T0oyReJer7twc3o/lpuFKKzFq4L6Cp+59n/H7KLLIvrtCJ0mZmc6tqN3DVrm7ordmnwWCxZllfJstxZluUOsiy/WWljgwvZeJHvKCbMMvxS2KeyJLO8vlj449t5tiPgkhjxO8gSvroenFR7IgOqhL1IG18HIProHi6k5pC6dgFdpDhuUa/jVyehAb5F35ul+qvK92GS0JI5YWhHQYmt/z89v4T9sZlW66X4I3zDwX0nwl1rYIpVyKQ9+VdfY5JLYAWRpA5OIm7+PylwrTFjM3KkcH2EVfzAadYEdoWza0WhcBD/6Ibycyv2WB8nwk1NWu/WmDRl3DXuFR4f7CrmD5ILknlw/YPct+4+YrJjaqwF32o49bdlWVcM/W4VEVIJe+HNYNj0BhxaLNwzfh3FQ9oaN8vENg6OYr4ovwZGftdn4joFGVW3bSGUnBWurPQvvqiiZdPQvDJejYRNuAaAbA9Y1GUnv/YWpcX0xmCbNu5tKIk2vj7KMnf2GkeOo5azgd0gJ9484g2Qcoj8vC0vaZawxul53tCIsMl/9Vdwh/ZZEuQAyhE5CoCvuZaCUp3xEjJ7L2Qy/bMdXPflLnR6A3qDzLnUfJYhRKboNFb4zzuKvuNUQcGOSQvgjlXCJ18Z1v5/SYLHjwp1yZZIQDdxT/5rfLAtmgJfDq/WoTqDjjHtxhDkVl46+cn+T3J799sZGVaxBIBJ1+VY+jGbWqiVyQa0WgwGsJZDuNOod2QtrwHCnZOfKkbtpiiakCjxN6hS27b1CK6ZkT+0WPxuBnpT9YUuTbh5DXl5VbRsGpqlkW/76iu0W/YLaXRHliR+utKTf/tLqCUVX47+nB5+PSg5c9rcfliGGPmf8PIVI0bjJNEo1WFkINrRdkT9qPZRZFSAxE+O13HREMjQ4o+Jv20v+HeEeTmcc+pGbpGQE9h9PpMbvtpFQpZ4zRz1/mY6vLCKPw4lssp9OrycaZmM9AoTMeSmaJOyOHtCRC3S0h0c7b8ZtASs5zQSDkDsNpFcVY3RXHZxNt5O3nb3+bn48fQVT1daMMMUbWNdpOOattdUr9+tjexYMFgJuLUdLH5f/z/xhnnnauGCObtOJLe5+omKYePegttWgE+78ud0D6yZkTcWYuHA98KFV8cciqbEUCTsgTZBRInLsqGy5vVK6n8/pPBA9UTimpWR7xrswe65VyM5OuLauzd77l6Cu4MvGq8jJPlKqHQGum2KJWnePAp27sJ1wABUbm647TyGi4MLZ9rYxo5PUu/lR08Prg8N4ZCTpRyZzhg5em3fUP70uYurShdwCX/cgyzRMK6ODizdF8/G6BRu+nq3zXlNxh4QER5lRze9roOIK+vra2n5WPtxrbN932sv/L8VYJAN5JTmVGjkq4Ozg60u/l/T/+KdEe/U+nwtmkzjfNS1XwuFUdMkfvhAeOwQtBsCvW+waCq5+om/7SEPi+gye7gH1czIOxirRh1aDJ8Phn+frdVHaWpKL17kdN9+5Pz1F0XHjwNgyM6plxoHVSHrdGR89RUXZ99SdWOamZHXqFUEe1n+KT1dHNHJoljFgY4SsiSR8tZbZC8VAmXeN96A24jh5G/aTDu3cOIMheX81rtdxPnWurnSK7ItuwaKmF5JggU3RuHl6oTB+DV4WsXV923rDcBjPx+2OV+fcG98XDWojRO9pbrGe3q3WMIGinkGgM1v2e6rxEBczL2IQTaUm1itKff1vs+8HOEZcXnWH81JsCiDtukrFEbt0c5qcFKdiX73IDHxWl3jVpwDKquw4Raqf1N0RGhPpcx/h/z1GwAwFBaS8OBDyPrqzTfVFkO+ZWBUnYdKszLy9ujp3xOANG8Jqa3Fj+02fDheU6bgPnIk+vR0BuYHcuriAbJVxpDGHtcCkGc0xku8hDslpVMP+rX15t2ZIoQx0NNSj9JkuAHeMe631sJZ8fAwlj80lEMvj2X14+KfZFpfq1Gqgn3UDpaIobKknKhwEtbkQx8UPKhOl5escvIuywzX06uF/PPRZWLdpRLVzcBuluWediLGyuIeJMTqTBnklSHLQkyw7RDLthYa4VS4X/xt6jPFg9O5p7BT+Zs3U3L2bIXH1Qd6KyOvT0+vsn1DZ7zWmQ+v+pBlp5chI+NxOJq8iwlIrq60eVe8crsPF8Z2/FEVfbfnkJR5BI/rQT34QS5mFhItxQOWCRGVSuKPhyw+8cev7kSotwvBnrav9c4aNV2CPDidIo7tE+ZFn3Bv8/5OQR5sfGokkf62pdsUKmHmtyKEz3p52a3C5zvk4XLN4/PicVA5EOpet0IoWqMf+tG+j9bpPC0WkzxwzDpAqtj1Apa5pcAe5TOb7WGqJZyfUvl5QUzo6oqEeyjWmByXEyeyaatKsGtmFGy3rcwW+t8FnBsjgjCKT0Xj3LVrvV+z5MIF9NnZqJwsA9OiEyfwGDWq0uOavZH3cvLi3t73ApDedSF5//6Lx6iROPiIWX8HP5Eg5fDXRrMozlmnB8DNk+eCSijMsZ3xziq2TbEP8nTm4as6VtqHV6f24PahEeW2tw+oOHRPwQ69rhOJM2mnhcvARAU1BBLzEwl1D0Vdds6jhpiyYT0cPep0nmZP3B4hatf7esu2ggzLZCeIjOmqvs+nzlS/LoGHlZG3lzRojamuQEgfeOIERK8UPvmt78HY16t3vWaAbDCgTbUocLr064djuCUhTxsfV+/XLE1I4PyEiQCEL/zKvD3hgQcJ+/yzSo9t9kbeGqcuQhZWm5Rsu0OtBis/mLzkL26L2EixvrwwVkVFJOxxKVtMsPYKqyAcUqHmTDP+QRoMIj3+5AqhBKorFRFEViTkJdR5FA9wR487ALiukx21zMaiOBe+GCZkATpe3TDX+M4Yzhs5XIzCZVlMblvj6lf+uLJ4lA9Xrbitcb6kOoVhvjLOA3iGiii0frcJI595vvLjmhm69HTQ6dC0a4v2YhySMagjYM7jpH34EaWxsfV+zYLtFlHDwn37bfblb648m7zZ++StcerQwe72iJ9+xPfOO3F76yUORwqfq724ag+NB3uS95TbXhFvXtuLa7oF0dfKTaNQT6hUcMMPYlSXHVcuyiK5IJkTGScIc6+7pLKrxpWHoh6qNNSywTm9SrgmVjVAYZeyfGAcURfY8deaitPUF77tRebs8gdFbH11MGWCa1wgarbQNdKWH5A1RwoPHSJn+QoA3IeJSWrTPI//Aw/gOXkyees3YCgoL4xXE3RZWeizswHQ5xeQumCBeV/O3yKhzTSil0srnyBvUUZeExZG4PPP0eY9W3lTlz59CHruWUKn38iZdsaXk2KLONlNXW/invUS95UO5mLuxWoXe57apw3f3D7g8pysayz0xont6JXmTbE5sYz5TWjOtPVs2xS9qj2n/4WP+8HFMuUQNxjdEZnnKy9xWV8YDLYJR+2uFJXExlaedF5jVGpL9vb/JgkJ48JM21BZE2onIddt7evvOVOorR5aLGS/mzGyLHPxpptJW7AAycUFt6FDyrXxGDcWubSUknPnan2dvE2bODtkKBeuFRPfWYt/wJBrqZGhSxaeDPcRI3Dq3Bl9fuVJWC3KyEuShN8dd+AYZn90p1ap8Q4RCRt9N1/CQ+PBI0VDmf3Zacbu0zJo/r/0OasjPj/e7vEKTYAplK8g1Vzm8Lvj35l3T+0wtSl6VT1kWSR36SwDCn6eBZnn4Pvxlm1ZsZCbYClAf7JCjb7ao9fZrl/cLmrvmgjuCUMfFVXE6publorf6Wfg7TBRRW3JTNvymnqdCMnsWya2O3KkUGtd9bSowFaP9YDrm8Jdlge3a//+uPQV80q+d95p3u7cWbiUL73wArKumlXqypC3WmQiay9dQpeZaVaq9ZwyxdymzXvvAaDy9MCQ24qMfHUYPPYOdCq4eYuBb49cwYgPt1K4d695/9xfDcTmxJY7Lr80n8T8xHLbFRqYMa/DxPfF8lmhz2+SC/51yq/4OPtUdGTTc3I5fDMaVj4JgKzVIjuJ8MTM835kLf1JSPGaRrXj3xbuqYR9FZywDphCGE1x7oumCB0aE+0asPh3RT58a/dNzDpABvcyUiJqB+g6ybJe23rNDYjeOIrO2yjUNr2mTyfktVdx8POjW/Qpc4QfgGO7djj37ElpzDlKztVurqE00WKHtAkJ5CxfDkCb+W8T/tWXhH70EV5ThJqt2t3Dxr7Zo9UZ+UFDZpK7ZL5YWVFeFS7LDU5nni63fdbKWYz/fTw/nPiB/cn7y+1XaCAcHEUxc0d3uCiKVGSVZBHiFkJX3/oPQ6tX4oyZ0IeWwIpHODN0GHFrHJBlSNnrRPK819F/PBxWPg2OHsJ/3WkcXNwBG14T5SMrQq8TZfcSquHaMRiEzx+gUxmp6q6T4b7NovJYQ2JPVbXAKN2dlyLecMBW4MyEn1V0W0bt3RwNQd6mTZwZOIi8DRsojbuIc/futJn/Npo2FefHtJn/NgBFhw/X6pr69Aw0Rm+FNjGR0vPiYSGp1biPHInnuLHmtmqvqoNCWp2RBxjWbxpe19lJ5JAkfApg+clfy2WKmTTG39v/HneuudP8IGiMNOXLHpUaOaQPS6N/JnXP55zMOEmQaw0iPJoKq1Gnfu8SDHl5FCY7kBPrYmkS7wLIUJon0qxNoaPbPoAVD9k/r8EAC0fC11eJN4Wyrpiy7PwY/jIW/QjsDldYFTMPG2AbrtpQ3PInDLwPwgdbthWkiSphH1gVS7dn5HvfCJONZQiXP9CsJmETHhT3qOjIUUpjzuEYYUe/pwyOHTrg2KEDuf/8U6tr6jIycOoiJs+LT5cfkFrj1LlTledrlUYeQO0pnnCOkRY9Gu9ZNwLgE5NCXF7lsazX/X0dOxN3MuinQeZi0QoNR4ybF2/6+3J19BfEZMeYi300a/KSRO1boCjdEv6ZtMfiYspPdIYuEy1GzJ7IV1lyEyHluGXdVJXJHrJsW+TdxVvIZV/9iqi7O+iB6nySuuPmBxPfgztXwcNGd1RBWvkasPZCOB1dxducMUud1JMN29dqYopuAcjbuAHtpUs4966g2I8VkiThfuUwio4eRdZWL8ijYNcu9Pn55G3ahCEvD2eTkT8pvgu/e++1e5zPrFkEPld5+cXWa+SNrzEOAZaRg9/tt4vfufD7WYtmRkXRNvevv58iXRGb4zc3WD9bGulF6dy66lbicus34SNaZ5sW30HTAnITcpOg21SY+gmFaeX1cNzbFKPV+8BNPwsjBuDfRYy0O48HB5fymi+JB+HTAbbb8irxU5etn2sSgxv+pFBC1biUP6YhUamNNRMkYeRNn+9KMW9hzpC1x0hjGG26sf7s7i+Eq6uJMBlYgNIY4UZyHzGiWsc6deqEXFKCNqXqsFJ9Tg5xd97FmQFXmN8cnLp1RdOmjVk+wWPsWLvHqtzc8LvzjkrP32qNvMpDZKOqPD1o99OPtHnvPRyCRehWSKbMsn3fseDAAob+PJSj6UcrPVd9G7SWSqm+lKuWXcXhtMP8eubXejvv6czTvKC1jXgK/vWuejt/vZOfBgt6iIgZzxDodxtF2I7wfGbPxqFjFDqtrVwGagcx0m47WKT4l5aJp/76KlHMA0TdARAPE3skHoQ/y4zUPeuePFZnTBXBsuOFfEHfW+Dql+E/yZVLH/hEiozcA/8T66ufh31fV+2uaiCKjgs5CLW/0MNyGdAfp/btKzvEjEOQeJjpUssL8JUmJJLy7ntmITNtYvmAD7eBA3GMiEAuFAKNju1qH0rcojJea4LkID6a64ABuPbrB/1E0WbHjh2YufMcM3fq2d3lG7p3l/ilzS/ljg9zDyMhX4RzZZVkldvfGpFlmRd3vMjQNkOZ1F5EPHx88GO6+HbB38WfO1bfYW67PGY5k9pPqvPkqFav5bq/LZmo76Wmc8lBTXutDk78CT1m1On8DcLZtZCbgCyD5NEGQ2kpRecu4TP9ahyCQlH5heE981rSPvsc/dbvKNi9B7fBZUTWTL7pwnRwsiOPceufEGosNF52JC/L8NUISLYanIx4tnnVAHYLhAtboTRfTDZLUtVvFRpnGHA37PjIHE4LCPdNSNVukvqmcO9eHDt0QJskHrJBc+dW+1iHQKORTylv5C89+yxFBw+S+d13dNq1k6Kjx2z2t/vpR9ReXkhWGjVqz9pr+7RaI+81bRoqNzc8J0yw3T5lKmn/Ff7RwadlBp+Wubu3rdjQsDbDuCL4Cj48+CFQXu+mNfLU5qfIKsliX/I+1sauNRv5r499DcCESNvvMbskm/f2vce3476t03WTCmxHqeO1aigw/oPv/braRl42GCiJjsa5ewVlFeuL4hzzhOnZFUGoti3BfVQKckkJLsMn4DXJEg7oOX4cmd99R9bSpbj064vK0cql42pUSy3IsBR8P2csiD36RegwWiy7+EBeGRmPoixbAz9+Pgx+sB4/ZD3gG2mJ+PHvXHlba8IGgKy3uGxAlCZsZCMvyzJFR4/iOX48ju0jSZ3/jtlPXh00oaGgUlF0+LCNDSo8eJCigwfN62eHDAVAcnLC96470WdkmhUtHfzF/EXwvHl1+iyt113j5ITXpElIKtuP6BIVZbN+yQfySvPMRaEBvhzzJT38LQVIskuyq33dS/mXWlxETm5pLmsvrmVfspgwC3AVo8wSvSXJx1qu10S+1iJ5qjVoeX/f+6QXVS19amJf8j6mLhehfS8OepF/ZvwDc47CM+eh2xQorH4d0KzFi7lw7UwKDxwg65dlJL36arWPrRE/CvGv0nw1+mI12ktpZP0kqoBpgmz9zc69egEiueV07z7o861cM6aRvCnMEIRRdHCGwVZRNyX5sO8b2wpKuVav99O/qNTAl168SOpHH9leuzEwvYWA5SFWHXyMgRKZF8DJOHqtZRH4upD+yScYcnNx6tgBvzvuoFv0KbN3oDqo3d1w7dePzEU/kPTSSwBoU1K5ePNsu+3bvPMOgY8/Tshrr5oHA4FPP03Ak0/ifX3dNJdarZGviLIhR47uwrj39O+JSlJxc9ebARgcMphfp/zKLd1uqfZI/lTGKcb9Pq5e/dWNwdksW/1rkzTvifQT5m0phZbXzmGhw2jj1oa0QouB2pqwlUUnF/HB/g+qdU1ZlrlrzV3oZeGX7BvUl3ae7YQv181PGEFrA1gFpgmqi7NvIfmVV8j+eWnNUsuz44Uv+NzGituknIB4oX2kHfBiud0ORt+tibJyGKUXYy0rbsYok78fF79TT8Hhn6D9VeBoJV9tvBfy+S1cnDiMxCefsBREjxxZqea7PieHc+PGk/HFl2R89WXFn6sh6GgVHaVxrrhdWXyNRv73u6HEmMqfVnkYYX1QdoI0b4P4O6juRKs9Qj8UHoPsX38jb/16Ss6cqbCt++irym1Te3nhf9+9SOq6qbBedkbewccHl759cXzpSUonjSCgUMNt3W/joaiHOHLbEeYOsvjduvp2xdfZl0Jdoc2otiJOZYoRx/4USzKVvoKCGM2FhLwEs7EeFjqMe3vdS1phGnqDns8OWyRMrYtg393zbqZ2nEp6Ubr5gVBsnCwsrU41IeBkhm2YXLm4eFd/oYFSze/PXqja+ek18OevekYY3MUz4Mcbyu8//DN8Y6wNGz4IrVNkuSZqfzsx4FaUxliFQnoZpWnzk8Vo/fBPYsJ14nu2B03+EAD9tzdQeD6T3FWr4chPIrlq1o+Wcnp2KNhlKVuZ8f3/SHnnXXNd0gYnuFftjtO42MbaO3rYvrk0AAW7dhEzciR5G0SFp5ILFyg5fRq/B+7HMSKi1ud18Pen4xahEFl04oSNOqX7yJEEPPEEnpMm4Tlxgq0rr5657Iw8QMTPP9Fh9r2EtO2OnJXN0/2eJCowym5bb2PlmuqM5k2jXZN+eWphKlGLo1h8cjFRP0SxIW5DvfS/vlh5fiUT/pjAM1ufAeCd4e8Q5BqEXtaTUZxhNtxlCXUPJcg1CBmZ9ELhninQCnfA2otr2XCx6s95OO2wzbqXU5mQSbcAQLaUrKsCXaaddtWMUQYgSfSnKENDyYH1tuJeBr0xSadQCHzdvRbtJTEZ6nvHHXhNm4rn1Cmo3csXkAl8xhICmPH9/8hdZfRTq9SicAqICeadH4usUe9w2xMYE5lKCyyjOfnEChjyEDhVrI8vGwxkLxOVoIJfeRl0OjK//968LXPRIgoPHqrya6k1KrXIIbDOZq0u0z61LPecYVvwPeEAnCmfyV5bio6fIPs3EU5tGmkXHxMToR7X1D1XQxMUiENICLpLSegyxedo+/13hH/1Jf7330foB+8TaqUw2RBclkbehIO/PxgMNhMhZfFxEoktJr+8LMusPL/Sbmz9hRyhopdTImK+z2SJP5p3972LXtbz9p6367P7dWbZ6WU2656OnmaJ5uSCZGKyYxgfMZ6efj1t2gW6BppH3j+eEqn51r74OZvn8MH+Dyp9i8kuyUZCoqN3x3LnByxytAmV63KAkGItPnoU1yGDy+2TDdWowSvLZu2X2HUBnF8VhO7rmcI9A+iObSD1iAf6qPuRhzyMNiWV9E8+Re3tTdDzz9HmnXcIffddu6f2u/tu83JJdDSJTz5lcSOZYsZN2aqlheVPYAw51OZb/MF63ygY9rjd6+nz89GmpJD28ccU7BQyEe5WlYMMRcUUHT1KytvzuTT3+cq+lbrz7Hl4cGfNj/PvJNxW7sFCtbIkBz4fAt+NFxnAP11f9TmqSex115G7UiigqtzEQ/rSsyK5yDGsfsJRHcPDKTx4EF1aGmpfX9yGlFevbEhabXRNdVA5C1/hxVtvo1u0/ckdfxfhZ92WsI1V51exJWEL53POE5cXx4N9bCe8TEbeNOpPzLN9zUwpTEFn0OGgavqv/WTGSQ6miofbhMgJOKockSSJDl5Cs//fC/9SqCvkiuAreG/ke7yw7QXaebajf1B/HFQORHhGALDo5CJmdJpBWpGt//x/J/7HgKABjAwfaff6OSU5eDh68NuU3+xLOfsb506W3gzDnxITcQPvhXZDbZrlrl5N4hxRJNz3llvwv/8B4u64w7y/6PBhEUKbnybCFa1rmJoozARtIYar5sHShQCkrM8gtHAo3LyM1OfvI+eCB/IJdwxHXiP7Z6G66DlxYoXfb2UUHz8uaiOULa/X246byPgmWZpvGcnrxn+Ng2P5twaAc9eMscnUBNCEWAqh63NyyN8mSu9pL8ahTUklf/NmvGdMR6pvl0FdErFu/VM8fA8YFUnLZsEWZor5m3pEn5NLxvf/M6+rqqELUx18Zt1I4pNPkZedjUNQPev5V4OmtzZNiHmEo6r4haZPQB9C3UP54+wf5rh5EJrn3xz7hpu63oSbxg2DbFG3zCwWrgN70glzNs3hk9GfNLlG/ZE0UW1+3XXrCHazGJtwz3B6+PVgyaklAPQNFO6Ct4a/ZXN8uGc4i8Yv4vbVt3Mw9aDdqJrtidsrNfJeTl4Vl/bziRRl62S90HkBOPEHPH3WpvCFycCrvbxwHz1aPKjWrUWblETcbbdz8ebZRK5YjvOKCSJaZ56dgtNG14zOYJEj0JeokPWQ8vQ95FwQceyZi3+2Oay6UQ8hb74JkkTSCy8AUHj4MF7Tpgm/vH8XiLoZ+t9hiSaxxtkLhj+N9uQqIFv0Mz0NupQPSzQUFdkYeKfu3Qh4RLwldNqxnbPDrkSbmIjkbPHjx4w03h9Zxsco+9EskCTx03aoyKA1VY9ycBFJZGfXQp9ZRt38C+KtyF6+QQUYioqIf9BWO0ifk0P6Z2Iequ3339Xb/6i78Ts25OWhrqDwUUNyebtr/Pzwu+8+UKkqDHuUJIl2nu1sDDzAqgur+OjgR1y1TMyKP7zhYYr1xTirnblUcIlSfSlxeXF09O7InH5zzFE7WxK2kFyQzKHUQzy4/sFqT1TWNyfST+Dt5G1XCMwUE++mcaOTT8UCSH0C+uAgOXAp/xJphWkMazOMz67+jHt63cPgkMGVVuHKKcnBy7GSkZLaAZ44Xn77+51EJSlsxeO8b77J/E/pGB6OSy/LxF/RkaOWcEydne/71F8gqdFKloedIbAPibt8yDpTseFQ+1ZvJOk981q8r51hDt8tOiwesGic4ZG9cOUc4ZaxN9iQJLj6JUo1HXAIFA83XXKyWfZW1usp3L+fouMnKD5leRvVtG1L+z/+wGO0iLd38PPDbfhw8tauJfevv82x2BZk8rdupeTsWZoVQd3hMau5gxt+EL//vF8Imb3mA5/0sxSIryYZ335H4e7dNtvy1q0zL9dnvoXJDQTUuWJUra7f6FdsZqi9vECnw1BQiC4zk+LT5cOc7ut9HwDdfLtxV0/bdPsiXREF2gK2J4qEqpHhI9EZdPRf0p/N8Zvp4N2Bu3vdzfMDn6dfoIgdnvn3TObtnMf2xO3miJzG4M+zf3Lf2vt4fOPjrDi3gsEhg+2OVtp5ChGtEl3lEUVqlZpgt2AS8hI4n3Oedp7tGBE2gsf7Pc6o8FFcyLnAniT7hj6zONM8qV0hHiH2tx8TIapyiaV/1hpFACoXF9o8INwppXus1AAzz1uSi3Z+Clvfhx0fUuR2JSkfC1eNc+/e6AtKyUuo3N2g9qmZ1n3E0p/xf+hBSk6dImvp0modk/HttyQ++RRFBw7g1Ek8cJP+8yIJDz1E4cGDZP34ExdvuZXY664j+xdL5raDnb45WD2UHPz8CPvyCwIefwwAfW4e8ffdz/kpU2td7KJB6T1LZNF2vMayba+loDVnVlc8SW8li6BNTSXurrttDHyb99/H9847zdmpzt27V0vCtzZImsYvQakYeW9vAJJeeIELM6/jwrRp5dr0D+rPxus38r/x/+OJ/k+U229dHHxU+CibfeMjRIUgSZJ4b6QIj8srzeN8jnj9jMmqRGGwHpFlmZd3vsyupF1sjN9ot68mogKiAOjoU3VkhK+LL6tjV1OkK6Knv2V0eF3n63DTuLE6drXd45ILkm3cRHaRJLhhMfS63nai8bwIS9PnWEqimUas1ngNjETjrkN3wSrO+vNBogaqwQBr/4Pu3zeJ3+pL7DdnKTkpHrjOXbqYNbwBXLu2ES4XI6H/XUCwVdJKTXDpI3TXk+dVnaylz88n9b33zRE5zt27o3K3vFmkvvc+pQkWzZ/cf8V3rfL0xO/B8uqTgc9b1ArV3l54jBqF3wMPgEZDgdFPD1Cwu/p1kBuNGV/Ck6fE2869xszgdS/btnk30pI4teY/cGYNpEbD6/6wVfzvZXzzDQU7d1K43xLmrAkJxv+B+83rQS9UX76gunTcugX30aMJmd/4wReXtU8eLPHVeWstYVn6/HzU7rav6aYsUHuYRvEP9HmAYFdbw9XFx5IKHegayPfjvufONZZyYTXJEK0Lpkgfa0aG2feXezt78+PEHwl0rXqSyORyCXELsZEHdlI7MSRkCNsStiHLss0bQ7GumKySrHLflV26TxU/siz0TPZ/Z055N+QJIx+64AM0wXbOpS1E46JHm2pHCfB/k0g+4EnWWdv7HL7wKwwlJWT/akloc+kktGicOnfCuUePclnUNcFUMg5EAebKJjtLymiJ+z/6CJk/WgqNFB06hOsASzk/ubQUVCo6795lt48OPj60ee89Ut9/n4AnxGBFkiQc/P0p3GepVlUaGwtXNmAlqdogSeYyeJVm0CYeAEkFuz4VP5MWALIo0DLiGUovXjQ39Zw4kYAnn0ATGmrz9+nUtf6L1WgCAwn//LOqGzYAl/1I3mPMNeVeu3VJFaj+GRkVNgoQk5aAWePGQ+NB/6D+fDDyA54e8DSjwkbRxt22gsyA4AGsv249X10jXjVNk7QNSaG20CaxCWD5tOW4O1bsb+4d0LvqkTaQUyomMu/rfR/ODraZjQOCB5BSmMLda+/m9zMWaefUQmF0q3N+M5IkNNlHzRXuFl0pemNtS5VHBeJN+ak4uOrRFjiUU/Qlbmc5Ax88bx7uI0bgOWaMTdih/8ufAODSq1edDDwIoSlTIfoSq+QYexSfstQxcO7TG5WjIx5XX23TJuPrbwBwHThQbDAYKu2j15TJdNqy2eah6DZMRCw5RkQgubpSfKp56LlXiIsPdDe+cQ9+yByBBIhC6pcOW9ZXG8NEsy4gXzpC0QFLuLRz7144hoWZDXzofxcQ9MIL5QZ4LZ06jeQlSXoPmAKUAueAO2VZzjbumwvcDeiBx2RZXlO3rjYMDn5+dN61k1M9eoJR+jP5jTfxf+D+CuNZ3x35LlnFWQS7BXNLt1vMkSgejh5IksTYCKH9fHuP2+0eH+QWRJBbEO082zWKkb9j9R2cyjzFkJAhDAwZyICgAXTwrp9Z/uR84d/uF9Sv3L42buIBty95H/uS9+GmcUMv6wlwEW9FNTLyJrzCARmy49DnigeM2t0NNr0NXcbbVkHKPI+Lfym5F13JueCCd3uR7SnLELOuK5Brc2rX/pbPoDaKQ/k9+EDFD5Fa4tRRuMFS579D+LffVBjFURx9CrWvL+1X/mM23MGvvELgM0+jS0kh9noRcqkJD0flKRKjnLrbCRGtAte+/cj57XccO3TAqUsXcv/+h+CXXjKHGDcHig4fxrFjR2GAJUlMwGqLQO0k3u5MRP8jfkCUPoy2zMfoPx6FId/yN+c1ebLNNcqKGbYW6jqSXwf0lGW5N3AGmAsgSVJ3YBbQAxgPfC5JUt0EGBoavSVxp3DPHuLuFBOsaZ9+Rsxo29GTi4OLeYT+3MDnzMaqMpeOPXydfRtF4dI0uRvmEcY9ve6pMLu3Nrw9/G2mdphKpGf5NP8Qd9uJ02e2PsPz257n7rUiEqJWRt5kxBP2YsgzjuQzj8KW+fDTLNu2KcfxbCuydguSnTDcKJK/SvPU6DJtDTyIsm0mTJXFyr8C1B1HoyZ5wc6dZFcyAVtyKhrnrl1x8PExTwSq3d3QBAbi3MMioBf03LMEv/QS3jfNImLx4hr3x2PsGLyvv47gV17Ga9o05NLSWtcnbQgMpaXEzrqJuNvKDJo0LsJHP+kDiJoN92+z3W9VvDz7ggtpR20zhNV+dqpUtULqZORlWV4ry7Jp6no3YExTZBqwVJblElmWLwAxwMC6XKspkGWZ9E8/RXvpEqnvv19hu2s7irJlA4IGVNjGHr7OvmQUi9C+Yl0x05ZP48+zf9a6vzqDrlwmrrXmzoiw2ostVcTAkIG8eeWbdkejVb0t1MrIB3QVr+vRK9HnCkOt1hvnNfKTLfVBdaWQn4JDf3FvcuNcOT1jDgAlBZbICbW3N46RkXTeu8fGzeF9/XVIGk2DjO5UVjrhaZ9+hi6r/INe1ukoOXu2Qv+wpFLRef9+Ap97DverrkITFETIK6/YhOtVF7WHByGvv44mMBC3wYNQeXmR9dPPVR9Yz2T9/DPpX35VLpxZn5UN2FZqsqbIsS+nnt9E0sdLKM4yOieiboGom8xtkvb4kH1efDeRSxbS7rO3mzxXpbGoT5/8XcC/xuVQwLrUT4JxWzkkSbpPkqT9kiTtT0urvupgQ6HysDztz1op0GV88y26dPuTpA/0eYD9t+wv55OuClcHV2KyY1h/cT2X8i9xPuc8L+982SZapybM2TSHUctGmUXD+i7uy91rxKj5qf5PVRhN01BoVBo+u7riySaTxk+NUKmEgFX0PxhSxJ+YSmfl8jLJIBg1dYgoM4F463K0PR82r0b8uowO/64qV5TBKTKSrseO1khDvCYEz5sHkoQ+I4OzIywT4IaSEmRZRpeWhlxaimO7imvCqt1F6be6qhRao3J1xXv6dPI2bsRQUnkIbX2T/OprpH34Iaf7D6DwgEUQT59teQhqL10qJ1WR/Yt4Q8v+828urAkkbrMvWs8oMRiYl4P8rMUUOXlrcf5nMq77HoNDS2DdKw3yttacqNLIS5K0XpKk43Z+plm1+Q+gA0xT//YekXa/SVmWF8qyPECW5QEBATVzd9QnQS/MxfWKKwhdYJHK1afZGvXMRT/YPVaSpFoZrMR8IXvwxOYnSC2yRIC8tOOlGp9LlmW2JGwhtzSXfov7cTH3IjqDjiNpR/B09GRW11lVn6QBGBE2gs03bMZd4043X4u/+OUhL1dyVBX0u5XiLAdyfl2C5OyM6twakfGo0kCMURzNJFPsFkD7VSvNhxraDKYkJRu1jw/dok/hGB5u5wINj8+sG2n7nVGgTKsl7fPPKY6O5nSfKDK+/NIcs90UafAuffuCTkdJTOOE95ZFLiwkd+Uq87reSnwuZvTVnBk0GJ31gFBta8YKkp1J/dkiGa0vsrzdugYYk+GKc2DFw7DjQ4izTYpqbVRp5GVZvkaW5Z52flYASJJ0OzAZmC1b3rMSAOv/njCgkmrETY/vbbfRbvEPuA8fTpfDtup8rgOEGybj668pjau/eq/XtLMkdlRWR1Zr0DJ62WhWX7DEnG+M20ivRb24lC++1rISCvuTLXHAoe6hNX7LqE/8XPzYedNOlk1ZxnfjvmPxhMVc37kOIlPebYnf6kdplh65uBgyzkLXSUILJt+oe59hFAFzC7Cpy6nPyqLo8GGce9kRRWtk3IYMwXPqFADSP/6EWGNBibSPPqY0XrzNaQIb38g7dxVvLyXR0VW0bDjyNm7EUFpKcXS0eX7MhCEvz/wA0mVkULCjvAhaSZJFvkKXblGxdA+xo6x6qQHVOJsBdXLXSJI0HngOmCrLsrWE3l/ALEmSnCRJigQ6AVXLCTYTVM7OYKwC0+XwIdotWUzgs6KSvEnZrz64pdst5mza13e/bt7u4ejBsbRjzF41m2nLpzF9+XTSitJ4Y88b7EzcSVZxFm/uFsk5piLk1kYdIDrT8g/aHATRTP7PK4KvqPPEr8HBE11RGRdFcC+haWMy8if+ECqGxonasE9FGGTcffehvRhnzh5taqzLBZqKNgNkLlkMajWathW7axoKTdu2SK6uFOzY0WjXlEtt5SZ0yckUHztmlkYGEe5sImvpLxTs3sOlZ59DazXw8rv/fnxmz6Y0LhHZYKD41ClzgmPIM/fh3sbognrkAFz3Hbj4QqqlOE5rpK4++U8BD2CdJEmHJUn6EkCW5RPAMuAksBp4WJbl5l09owwRPy4hcsVycxiZ7x23I7m4UHrhQr1dQ5IkZnayVPYxTUT6OvvyR8wfHE07ala8BKH3cv/6+xnxywize+eZLc8we9VsVl5YiZ+zHw/0EZmOS09bojYu5loSQFoDqZ8vAsA1oITIz4wVmpy9hMsm66JImko4AJEjzEU1XPr1Q3J2pjTmHLJWi4Off0Wnb1QcI8tHJQEUHzmKU+fOdjXqGxpJpcJr0kRy/12NPi+v6gPqgRI7/1c5y1eYI2Ailv1CyFtvEfiMqH2Qt2YNcXfcYdbrMUUsOXfrhmOH9silpejS04VukRH3iVZvj/4dRVWt4J5NUl6wMalrdE1HWZbDZVmOMv48YLXvTVmWO8iy3EWW5X8rO09zxKVPH5tJN0mlQhPaBu0l20QpWadDn5ND5k8/oU1OxlBYWPZUldLGvQ3bbhShX/f3vp8Izwjytfmczz5fxZEWjqYdZV/yPvoG9uXhqIeZ2mGqzf7c0vLhgi0ZU+SHX/d8nLcZlQSdvSHsCsg8Bwt6QN4lmwLSDr6+tFtsmVNR+9ZMd6ah0IRWrFletmZsY+IxbjzIMsXH7YjENQDWriG1vz+uAweSt349+swsVB4euPTujdrDA7+77yLoP/8xtzUUFuIzezbt//6L8K8X4jFurHmepTQ2lpLz55CcnOhy5DAOIWHQ9xa49hvLhQN7CCNfnboDLZTLPuO1Jjj4+JK3bh1x99xrlkNI+/BDzgwaTMprrxMz6irOT5te4/N6O3tz5LYjzOw0EzeNG9nF2TY1VSti3pB5NuszOolyd28Me8O8LSogivnD59e4Ty0BF1+rV3xJBQOMvltj0RY8beP0rZUXHZpJjHTZyBjXK65AchHCaCZdpabAMUK4icoOaqqDPi+Pgj01885qk0RSneeUKYR/8TkeY8eiz8qi+OTJcg9k31tvIWDOHADk4mI0bdogqdW4Dx+OJEnm+1x05AgF27bj0q+vJWx12mfQ22pEH9hVVPzKqb+5tlqj10HycVhyHRTUn9xJ0ztrWxCm8mAF27eTv2MHHqNGkfHNtzZttPHxFB48hGu/vvZOUSEqSTxvQ9xCWB+3vsr2+2bvw9nBmWvaXcOVS6/kyf5PmuPgJUnir+l/kV2SbdaDb004hITgFtUNtdMSy8a2g0VyzIT34F/xSl+2KIckSUQs/ZnMH38yy/42ByKW/YKs06O9dAm3oUO4cN116IqK6tU1WFNMqp7pX3yB56SJNcp+zfjmWzK++orwrxfiPnx4tY7Rpaai8vQk1Cj5YBpEFR06ZLc4i7UUiYO/7QPbwccHh8BA8jduovTCBXxumV3xhQOMEV+p0ZVr4jQ0ecnw7RizjDbb/wvj3qz8mGqijORrgJOV+6Zwz14yvvnGbruLN99c62tUJIVgok9AH74f9705WsbLyYtjtx/jzp532rSL9IpslQYeRISMOritZcO9myxViHpdJ4qAe4ZBcO9yx7pERRH63ruoPTzK7WsqXHr3xrVfX7wmTxJupUVizsH7xqYr4mEa+WoTEsj+/fcqWlswFBWR8ZXQZYp/4MFqyxbr0tJwCLSEUFu7SgOefLJce02I1QPcnhhbcDBFh0TUTFm9HxsCjNdJPlpxm8bg5AqLgQfxdlFPKCP5GhD28UdoL10i8elnyPz++wa5Rp+APtzZ404yijPwc/ZjU/wmfpn8CxnFGXx77FvmDppbuySiVoKhuBi5uBi1jy88mw0ZMZZSgSBKwj17rsn6Vx84hodXWI6yMXHp25eiQ4eQHKqvgW4tqoZeT3H0aVx69qj4ACO61FSbcFHrzF17tVbdhg5FcnVFLiy0UwBFzGcUI1x0dhVKTbh4C1ffpjfFSN5UgtGgF9o4Nag2VSesC8cD5NtRTgVIOgo/Xgd3/gt+xozy/MqTSJWRfA1Qe3vj3L17tarG6PPza3UNSZJ4csCTvHnlmzw54En+nvE3rhpXwj3CmTd03mVt4AFzeTu1t5cQqvJvHqGQrZHwL78AQC4uqrJt0ZEjFJ85gzZejEb9HxVlB9M++bha19KmpZYr/OJz260V1tGVHBzoevAA3aJP4WQnQsk0n+F6xRVVX3ym0eVqJWbG6rnwdiiYZEJK8uGXW0St4YooLYSvRsDrAbZKmNUh45wIFDAVdzcVtinL8d9FmPAuYya5LMP7ldd9UIx8LfCcbIlt7rhlCz633orfgw/Qcctm83brohMK9YfeqPNS06pMCjXHVKAk7dPPyN+2vcJ2hoICYm+cxYWp0yg+eRLJyQn/e+/FY/x4CnbuQpeWxqmu3TjVtZuNTk/JhQvk79ghtl9KMpc3NBH8wgs2Geg1wff229C0a4vPTdXI9O55rYjMKs4RP2v+Y6k6lWKMLvpiKJz6G9bPq/g8sdsg6QjoS+GbaypuZ03MBvigG5zfDKH9RWGUAXdB4n6hv3Tqb9hjVQEr+Zj4ffpfodNUUnWIq+KuqQUeo0bhe/vtOHXriiYokOD/vGDe137VKs5PnEjJ+fO49C7vE1aoG6aRvEMTRp5cLpgifwx5ecTfey9djx4pV+RELi0l7i5LfdXC/QdwiYpCcnTEc9xY8lavJm/DBvP+3L//wfe2WwE4P8F2lK4Jqz+JCaeOHem4pgbq5i6+kJcEy26H85ss29NOQ1E2ZBtzTeRKQi2TrPz67tXIVM5LgSXXWtY7XgMqNbQdIuST37B6s+kxAzSucM74XeZdgos7wLvqZDllJF9LguY+j/f06eW2O4aHgYMDpeeUkXxDkPWzSPJSRvKNT9x999usG0pKODN8BEVHjpi3FZ84gZNRstkxIgKwLXVYWaFw91H2K5U1Ci4+wphbG3iA3ERYPN2yXlnd47wkcZ6+txgrmeVXLn623zYyjy7Gh16Pa8u3TTku5DsAJhoVcZdcC8turfj8RhQjX89IGg2O4eGihJqR4lOnkPUtKuG3WaLLyjKXaXS00qNRaDgC5jyO7+23AVC4ezeGggLzvpIzZzHkGAu3WD10NW3FiNxUHMWEysPDxsg7BATgdd1MXPr1Q+3t3aTJX7j6CeXSdleK9adOiwQ7Yz1hAPw6ignSNf+B3V+UP0d+ipDScPUTI+23Q4W7xR77v4Mt74Cb1Wjd0VX8VjvAuLeE2qqncdJ58QxYOEoshw+0HJdadRUvxcg3AA4BAegyMpB1OhIefZQLM64l7dNPm7pb9UL+9h0kzHmi1hPLdSH9s88BCP3k4zqX4VOoHv4PPEDgc5YC4Nb1cnUplslBa9ek5xhR61fSaAg3hhlLGg1eU6dScvYssiyTNG+eCJv09qbdD4vouNXKmDYFvpEibPHidnDyEjkWvpFwwdiv+7dClwnCyO/61FJW0Jq8JHGcu9XDKsWOLk5OIvwjauwS3Mt+f4Y8DHevgTnHRfSPNcG9Kz7ODsp/SgOg9vNFn5lJ/ubN5K0TiU3WSnmF+/eXE2RqKSS/9hp5q1eTv2lT1Y1riaG0FIOd78ckDlfdBBuF+kFSqWj7PxEynL30F+TSUgr37yfhkUcB8L7+erxvFKGHnpMm2Ug1mFw2XtOn49K7F4aCAqK7dSd76S+igUqN5OCAqpKC5o2Cn9Vbhylj2tqQ+nUCt0CwKsJDca7FHfPHfaKIuHugcNeYMI3k89PgwCIhn3DaIqNM+1Fw/SKYYTW5ao1KBY9atPUZ/46IKhv8sP32dlAmXhsABx9fCjIzKU2wFP8wGfXSuDgu3nIr3tdfT8jrr1V6Hn1ODrrMTNDpmlw1UZZlcv/+26z4p0ttuAIv5ydNxlBcROdtlnJuhsJCSs+fJ+Dxx5pV7dHLBYdAMTrNXLQIyVFjFhRT+/gQ/Oo8kCSCXpiL17RpNsc5hoUS8ctSnLt1A0ni0nO2I2DvmXb8z02Blc4R494SvwfeDweNekeOriKm3pr54aK4PMBR40NLWyjE8h49CJ/0EwqXuz6DNcbgDF2JyMhWaeDJk8K1o6qi6IvJZdN2KAw2yoN1ugbm5cA8r4qPM6KM5BsAtZ8vhtxcSqwSQ2RjlR2TtnX+lspfT3Xp6ZwdPoLzEyZyfsrUSts2BkUHDnDpWctre8GuXQ1yndKERLTx8TYFW0rj4kgwapVowsIqOFKhIbEOb8xbu84c095p+zYklQpJkvC97TZzLVprXPr0QXJ0RNJoaPOBpYxm8LxXKq181ah4trEs97xO/A7uCTctFRnVIHz0ZfnnCYvrBWC0sRiOXwfxkACLgQeL5MaVc8SovyoDD0JJ9Z4NcJOdkowP7ICbf630cMXINwAm8aucv/4yb9MmJZG5eAmp7wptjsp82trUVGJnz242Lp20Tz7l4i1iFt918GBUnp4UbN9ergybPXRpaeSsXFllOxPZSy1/yMWnhVZQ3J13UbBVjOodmnJy7jLGWvK49OJFio+fQNOubY1LD1rLFXhNbfrBixnreq+uvpblLhMgtJ9YLjuSL8sjByDA6o2g22Tb/S5W5x39Ys36FzbA/vWDe0LnsZUeqhj5BkDtY7yZsoznxAn43HILcnExKW++SdHhw+Z9FZE45wm0F21V8Urj4jAUFFSo711y7hyxN89Gm1JBOnQdSP/MUqc17OOP8L1F+BwNuVVLGF+4/gYuPfW03WLV9ig6bAnHS3joIQwFBWiTLRN8mpAQe4cpNBbGYjrFx46hdq+5/o/p/rkOHIjK1bVeu1ZnJr4vahCoK5BxsB7J97sduk2xrHuGCY16a6wjZ6Z8BLf+KZZNETyNhGLkGwC1p+WPP3jePNyGDinfyGAoV5UeRLJP0cGDADZRDefGjuPchImcHTnKJozNRN669RQdPEj655/XwyewRbL6Z1R5eOAYGQGALrNqw60zGmhtfHwVLYXfv+TsWbxvuAHPiRPRJiaS9vEnYBV+WjYrUqHx6LxvL1327TW7zFSeNTfyKjc3Ou/eZZZMaFYMvBduryDkEWwlNKZ8JAy9idv/Kt/ey+halFTQ+0ZoEwWvZMMd/5Rv24AoRr4BcAgSgkiBzz6L2tPTJtrAISSEgKeeRC4pQXuxfMWmzJ9+AsD7hhvwveN22hilV0GIOMmFhTYTumaMmXj1Laegzy+wiXyQJAm1t4iJ1mdXb3QOUFrmzQSgNCGBC9ddb05518bFoc/JwTEykpA3RDnEgt22RZbNuuAKjY7awwOViwuugwaK9VqM5EHoyjS7UXx10LgI4z7rZ+HeaTcUuk6G+7dZxMKscfKAh/eKH5NKqiTZuoYaAcXINwBO7SPpuGE9vnfeIdatBJQ6rlmNo9Honxs/AX2+7ag8/WNRi9RzwngkScJryhSCXphr00aflV3umjrjRGXhvn01LthQGWcGDDBLCZgmzUxFHPSZmZUea9IEB7j0zDMU7ttnXi8+c4Zz14yxqTx0foaItNCEBKNydcVjzBhKTp+ul8+hUH+YQlibOuKrSeh/B3Q1ZqY6usGsHyGkEvmSgC5NLqKnGPkGQhMaai5eLTk6EvbpJ4R//TWSo6ONyyHl9dfMbhtr9411BqHvbbeZa12CCK0si/bSJfNy4hNPlNtfV4JefslcdNrBV8w56Kow8mX3x91zr3m5YHv5ItGmQtamcD0HK4nY8IVf0Xnvnlr0XKG+8Rg3jtAPP8Tv/vuauisK1UAx8o2ExzXX4D5cTLhYS6rmrPjL7LdOffc983a1r6/N8cGvvGxe1mdnI8syBmNYpqzTUXT0KJ5Tp+DSv7/QXK+HmpWm8wM4WoUumh5A9t4oABLmPEHcvfcRe6OtAqBcUoKhSMjWapMrLitneghqgi2RNJqQENSenjX7AAoNgiRJeI4fp7jOWgiKkW8CHNu1M1edB9BlZCIbDGT/9hsgJlw1ZSYYPceOpcuRw6BWU3LmDEkvvsiZKwaiS0vjwszr0Gdm4nHNNXhNmYxcWGjOtK0LJjcNiNBJEypnZyRXV7vuGlmWyVu9moJt28wPr9CPPjLvzzcmOOmSLBEzkSuW4//Qg+Z1U9UfTajlweKgRNUoKNQKxcg3EX5334Xv7WJ2PuObb4ju3gNDXh4eY8fiZ/Tll0Xl5IT7qFFk/fgjOb//gVxaStGJE2a/tfvIkbiPEHVe8zdusHuOmmCaxA396KNyaecOPj523TUmfRlrPMeNpcuB/QAkv/oauvR0dGlpqLy88Jw4Eaf27Ql47DEcO3RA7e1tjr127mqJqVa7N1KFHgWFVoYia9CE+N52K5mLFpG3erV5my6tcrmAssauJNoyMalyckLVpg3uo0dTeOgwsiyb5wVqQ/rChai9ve0WJde0tVXaNB9jJcQW9MIL5kgMUzk3fUYGKe++iz4nB7ehQ2yKQrRf/qfNvISmbVt8br4Jj7Hjav0ZFBQud5SRfBOi9vc3L3uMFVlrXlOnVNQcAM+JE2zWi6OFdELwvFfM29xHjEAbF2cuZFwb9Hl5FO7Zi/dNs8qVZQNw6tiJknPnzEJi2qQkdFlZZmOu8vLCZ9aNNhmOJgz5BehzcsqlwEsajW24pkpF8Msv4zZ4UK0/h4LC5Y5i5JsQ64krlz696XrsKN6zKi9X5j5ypE31etNbgGPbtuZtXlMmI7m4kPvv6nLHV5eS6GgwGHDt199+P0aMQC4spGDbNmRZJuaq0ZwdMhRDQQH+Dz1Ilz27y1URcuokMgLzN25En5mJ2su71v1TUFCoHoqRbyY49+iJpNFUy73id+89dFi31mabysOSmKJyc8MpMpKsxYurdP+UJfuPP0l49FGKT4piBJrQNnbbufbvB5JE0dFjlJ47Z7NPXUFpvoilS23WrcM+FRQUGgbFyDcxXtOno2nbFpe+UdU+RpIkHMPD8bn5JgCce/Qwl1wz4dRZCCWlf1mBTrUdZIOBpBdeIG/denJXi/qYppj1sqhcXXGMiCDzf/+jYIdtzHtFpflMrhwT1SqyrKCgUCcUI9/EtJn/Nh3XrqlVzHHwyy/TLfoUkb//Vi5NPGiu0O3W2pNAqABtYqJ52eTPt1YfLIvXtKnIJSVkr1hhY9idu3at8JhO2y0a8a79+lW7bwoKCrVDia5ppai9vPAYM4bCAwcwFBZWSyvEnr5MZTj3EpVzSk6ewnPiBLxmzCBr6S84drCj42HEwd+fNu+/j+RYgdKfgoJCvaKM5FsxnlMmo8/MtKvnnvL22+Stt02Ysq7ZCRD0YuWa1y49epiXVZ6euA8fTvhnn1ZZf9Vr8iQ8x1auga2goFA/KEa+FeM2UMSoJ7/0MkVHj5q3Fx07RuaiH0h45FHSPv7YvF2bkgII2QW1ry++t8yu9Pxqb2/cRgixKrVH7RQJFRQUGpZ6MfKSJD0tSZIsSZK/1ba5kiTFSJJ0WpIkJZulCbCOcinYLcS95NJSYq+/wbw9/XOh6y3LMiWnonEICqL933/RaXP1CnWb5GZVbkpGqoJCc6TORl6SpHBgDBBnta07MAvoAYwHPpckqWZ1whTqBe8bbwQgbcECSs6dI7p3H7vtkl9+hbx163AbOlRIC5SJca8IyThh3CL1wRUULgPqYyT/X+BZwLrM0TRgqSzLJbIsXwBigIH1cC2FGhL84n/My+cnWWpOtnlnPiDCGmWDgexfRTHggMcfq9H5nTqKSVZ78scKCgpNT52MvCRJU4FEWZaPlNkVCljXe0swbrN3jvskSdovSdL+tBom7ihUjaTR2GTIgihJ6DVtGv6PPCJqqMaJl7DgV19FY6XhXh18Zs/G9447lJh3BYVmSpUhlJIkrQfs/ef/B3gBsBcmYS9t027lalmWFwILAQYMGFBxdWuFWuN/3724DRlM0dGjpLz+hllewFRUOeV9UfGpNpV+VM7OBD3/XNUNFRQUmoQqjbwsy9fY2y5JUi8gEjhiTMUPAw5KkjQQMXIPt2oeBig57E2IS69euPTqhcc116AJElmsJsmC/PUb8Joxo0ZZtwoKCi2DWrtrZFk+JstyoCzLEbIsRyAMez9ZlpOBv4BZkiQ5SZIUCXQC6q/wqEKtMRl4sB25B7/8Up1kiRUUFJonDZLxKsvyCUmSlgEnAR3wsCzL+oa4lkLtcfDzQ3Jywvv661G5uDR1dxQUFBqAejPyxtG89fqbwJv1dX6FhqHrkcNN3QUFBYUGRMl4VVBQUGjFKEZeQUFBoRWjGHkFBQWFVoxi5BUUFBRaMYqRV1BQUGjFKEZeQUFBoRWjGHkFBQWFVoxi5BUUFBRaMZIsNx9NMEmS8oDT1WzuBVSlb1udNjVt21TtWtu1/YH0JrhuS/huWtNnqe59ru45W8Jnboo+dpFl2X55NlmWm80PsL8GbRfWR5uatm2qdq3w2tW618p9afGfpUn+p1vT/atO28q+55bsrvm7ntrUtG1TtWtt126q67aE76Y1fZaaUJ//063p/tW0rQ3NzV2zX5blAU3dD4WGR7nXlwfKfW4cKvuem9tIfmFTd0Ch0VDu9eWBcp8bhwq/52Y1kldQUFBQqF+a20i+1SNJUn4V+zdLkqS83rZwlPt8edAS7rNi5BUUFBRaMU1i5Kt6+rV2JEkaJUnSP1brn0qSdEcTdqnBuJzvtXKfLw+a+31WRvIKCgoKrZgmM/KSJLlLkrRBkqSDkiQdkyRpmnF7hCRJpyRJ+lqSpBOSJK2VJEkpQNqCUe715YFyn5snTTmSLwZmyLLcD7gK+ECSJMm4rxPwmSzLPYBsYGbTdLHB0GH73Ts3VUcaicv1Xiv3WbnPTU5TGnkJeEuSpKPAeiAUCDLuuyDL8mHj8gEgotF717BcBLpLkuQkSZIXcHVTd6iBuVzvtXKflfvc5Dg04bVnAwFAf1mWtZIkxWJ5ApZYtdMDreLVTpIkB6BEluV4SZKWAUeBs8Chpu1Zg3NZ3WvlPiv3uWl7ZktTGnkvINX4x3AV0K4J+9JY9ADOAciy/CzwbNkGsiyPauQ+NQaX271W7rNynzFuH9XIfSpHoxt509MP+BH4W5Kk/cBhILqx+9KYSJL0APAYMKeJu9JoXI73WrnPyn1ubjS6rIEkSX2Ar2VZHtioF1ZodJR7fXmg3OfmTaNOvBqffj8DLzbmdRUaH+VeXx4o97n5owiUKSgoKLRiGnQkL0lSuCRJm4yJECckSXrcuN1XkqR1kiSdNf72sTpmriRJMZIknZYkaZzV9v7GBIsYSZI+toq/VWgG1PO9flOSpPjLOVW+uVJf91mSJFdJklZKkhRtPM/8pvpMrZ7qlp+qzQ8QAvQzLnsAZ4DuwLvA88btzwPvGJe7A0cAJyASMXOtNu7bCwxBxOL+C0xoyL4rP016rwcbz5ff1J9L+WmY+wy4AlcZ2zgC25T/6Yb5adCRvCzLSbIsHzQu5wGnEAkS04BFxmaLgOnG5WnAUlmWS2RZvgDEAAMlSQoBPGVZ3iWLv4ofrI5RaAbU1702Hr9bluWkRuy+QjWpr/ssy3KhLMubjOcpBQ4CYY32QS4jGm3iVZKkCKAvsAcIMv0TG38HGpuFAvFWhyUYt4Ual8tuV2iG1PFeK7QQ6us+S5LkDUwBNjRsjy9PGsXIS5LkDvwOzJFlObeypna2yZVsV2hm1MO9VmgB1Nd9NsbY/wx8LMvy+frtpQI0gpGXJEmD+GP4UZblP4ybU4wuGIy/U43bE4Bwq8PDgEvG7WF2tis0I+rpXis0c+r5Pi8Ezsqy/GGDdvoypqGjayTgW+CULMsLrHb9BdxuXL4dWGG1fZZR6CcSoVy31/j6lydJ0mDjOW+zOkahGVBf97qx+qtQO+rzPkuS9AZCCmFOI3T98qUhZ3WBKxGvZkcRac6HgYmAH8L/dtb429fqmP8gZuBPYzXbDgwAjhv3fYoxxl/5aR4/9Xyv30WMAA3G3/Oa+vMpP/V7nxEjehkxcWs6zz1N/fla44+SDKWgoKDQilHK/ykoKCi0YhQjr6CgoNCKUYy8goKCQitGMfIKCgoKrRjFyCsoKCi0YhQjr6CgoNCKUYy8goKCQitGMfIKCgoKrZj/A3ewpe0i5bfKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(1000, 4), index=ts.index,\n",
    "                  columns=['A', 'B', 'C', 'D'])\n",
    "df = df.cumsum()\n",
    "df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27c8ce9",
   "metadata": {},
   "source": [
    "## 数据输入 / 输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7fe4ad6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ./output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad55d44",
   "metadata": {},
   "source": [
    "### CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf54096",
   "metadata": {},
   "source": [
    "写入 **CSV** 文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fa563dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./output/foo.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9731d6d",
   "metadata": {},
   "source": [
    "读取 **CSV** 文件数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9665207d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>-1.167799</td>\n",
       "      <td>0.738410</td>\n",
       "      <td>-1.672759</td>\n",
       "      <td>0.015277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-02</td>\n",
       "      <td>-2.724309</td>\n",
       "      <td>0.632798</td>\n",
       "      <td>-0.636592</td>\n",
       "      <td>-0.681891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>-3.703608</td>\n",
       "      <td>1.061687</td>\n",
       "      <td>0.681637</td>\n",
       "      <td>-1.339778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>-2.927774</td>\n",
       "      <td>1.389132</td>\n",
       "      <td>0.400533</td>\n",
       "      <td>-0.593600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>-2.345763</td>\n",
       "      <td>-1.160127</td>\n",
       "      <td>0.042910</td>\n",
       "      <td>0.139708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2002-09-22</td>\n",
       "      <td>39.464274</td>\n",
       "      <td>-27.807296</td>\n",
       "      <td>25.223890</td>\n",
       "      <td>-6.409600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2002-09-23</td>\n",
       "      <td>40.930645</td>\n",
       "      <td>-28.886537</td>\n",
       "      <td>23.734247</td>\n",
       "      <td>-9.226805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2002-09-24</td>\n",
       "      <td>41.084929</td>\n",
       "      <td>-27.327071</td>\n",
       "      <td>23.358181</td>\n",
       "      <td>-9.834518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2002-09-25</td>\n",
       "      <td>40.744915</td>\n",
       "      <td>-25.252634</td>\n",
       "      <td>22.224009</td>\n",
       "      <td>-9.500594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2002-09-26</td>\n",
       "      <td>40.393599</td>\n",
       "      <td>-25.562739</td>\n",
       "      <td>22.057440</td>\n",
       "      <td>-8.915915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0          A          B          C         D\n",
       "0    2000-01-01  -1.167799   0.738410  -1.672759  0.015277\n",
       "1    2000-01-02  -2.724309   0.632798  -0.636592 -0.681891\n",
       "2    2000-01-03  -3.703608   1.061687   0.681637 -1.339778\n",
       "3    2000-01-04  -2.927774   1.389132   0.400533 -0.593600\n",
       "4    2000-01-05  -2.345763  -1.160127   0.042910  0.139708\n",
       "..          ...        ...        ...        ...       ...\n",
       "995  2002-09-22  39.464274 -27.807296  25.223890 -6.409600\n",
       "996  2002-09-23  40.930645 -28.886537  23.734247 -9.226805\n",
       "997  2002-09-24  41.084929 -27.327071  23.358181 -9.834518\n",
       "998  2002-09-25  40.744915 -25.252634  22.224009 -9.500594\n",
       "999  2002-09-26  40.393599 -25.562739  22.057440 -8.915915\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('./output/foo.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbc78c8",
   "metadata": {},
   "source": [
    "### HDF5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d1c1df",
   "metadata": {},
   "source": [
    "写入 **HDF5 Store**："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ac385d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method to_hdf in module pandas.core.generic:\n",
      "\n",
      "to_hdf(path_or_buf, key: 'str', mode: 'str' = 'a', complevel: 'int | None' = None, complib: 'str | None' = None, append: 'bool_t' = False, format: 'str | None' = None, index: 'bool_t' = True, min_itemsize: 'int | dict[str, int] | None' = None, nan_rep=None, dropna: 'bool_t | None' = None, data_columns: 'bool_t | list[str] | None' = None, errors: 'str' = 'strict', encoding: 'str' = 'UTF-8') -> 'None' method of pandas.core.frame.DataFrame instance\n",
      "    Write the contained data to an HDF5 file using HDFStore.\n",
      "    \n",
      "    Hierarchical Data Format (HDF) is self-describing, allowing an\n",
      "    application to interpret the structure and contents of a file with\n",
      "    no outside information. One HDF file can hold a mix of related objects\n",
      "    which can be accessed as a group or as individual objects.\n",
      "    \n",
      "    In order to add another DataFrame or Series to an existing HDF file\n",
      "    please use append mode and a different a key.\n",
      "    \n",
      "    .. warning::\n",
      "    \n",
      "       One can store a subclass of ``DataFrame`` or ``Series`` to HDF5,\n",
      "       but the type of the subclass is lost upon storing.\n",
      "    \n",
      "    For more information see the :ref:`user guide <io.hdf5>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    path_or_buf : str or pandas.HDFStore\n",
      "        File path or HDFStore object.\n",
      "    key : str\n",
      "        Identifier for the group in the store.\n",
      "    mode : {'a', 'w', 'r+'}, default 'a'\n",
      "        Mode to open file:\n",
      "    \n",
      "        - 'w': write, a new file is created (an existing file with\n",
      "          the same name would be deleted).\n",
      "        - 'a': append, an existing file is opened for reading and\n",
      "          writing, and if the file does not exist it is created.\n",
      "        - 'r+': similar to 'a', but the file must already exist.\n",
      "    complevel : {0-9}, optional\n",
      "        Specifies a compression level for data.\n",
      "        A value of 0 disables compression.\n",
      "    complib : {'zlib', 'lzo', 'bzip2', 'blosc'}, default 'zlib'\n",
      "        Specifies the compression library to be used.\n",
      "        As of v0.20.2 these additional compressors for Blosc are supported\n",
      "        (default if no compressor specified: 'blosc:blosclz'):\n",
      "        {'blosc:blosclz', 'blosc:lz4', 'blosc:lz4hc', 'blosc:snappy',\n",
      "        'blosc:zlib', 'blosc:zstd'}.\n",
      "        Specifying a compression library which is not available issues\n",
      "        a ValueError.\n",
      "    append : bool, default False\n",
      "        For Table formats, append the input data to the existing.\n",
      "    format : {'fixed', 'table', None}, default 'fixed'\n",
      "        Possible values:\n",
      "    \n",
      "        - 'fixed': Fixed format. Fast writing/reading. Not-appendable,\n",
      "          nor searchable.\n",
      "        - 'table': Table format. Write as a PyTables Table structure\n",
      "          which may perform worse but allow more flexible operations\n",
      "          like searching / selecting subsets of the data.\n",
      "        - If None, pd.get_option('io.hdf.default_format') is checked,\n",
      "          followed by fallback to \"fixed\"\n",
      "    errors : str, default 'strict'\n",
      "        Specifies how encoding and decoding errors are to be handled.\n",
      "        See the errors argument for :func:`open` for a full list\n",
      "        of options.\n",
      "    encoding : str, default \"UTF-8\"\n",
      "    min_itemsize : dict or int, optional\n",
      "        Map column names to minimum string sizes for columns.\n",
      "    nan_rep : Any, optional\n",
      "        How to represent null values as str.\n",
      "        Not allowed with append=True.\n",
      "    data_columns : list of columns or True, optional\n",
      "        List of columns to create as indexed data columns for on-disk\n",
      "        queries, or True to use all columns. By default only the axes\n",
      "        of the object are indexed. See :ref:`io.hdf5-query-data-columns`.\n",
      "        Applicable only to format='table'.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    read_hdf : Read from HDF file.\n",
      "    DataFrame.to_parquet : Write a DataFrame to the binary parquet format.\n",
      "    DataFrame.to_sql : Write to a SQL table.\n",
      "    DataFrame.to_feather : Write out feather-format for DataFrames.\n",
      "    DataFrame.to_csv : Write out to a csv file.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]},\n",
      "    ...                   index=['a', 'b', 'c'])\n",
      "    >>> df.to_hdf('data.h5', key='df', mode='w')\n",
      "    \n",
      "    We can add another object to the same file:\n",
      "    \n",
      "    >>> s = pd.Series([1, 2, 3, 4])\n",
      "    >>> s.to_hdf('data.h5', key='s')\n",
      "    \n",
      "    Reading from HDF file:\n",
      "    \n",
      "    >>> pd.read_hdf('data.h5', 'df')\n",
      "    A  B\n",
      "    a  1  4\n",
      "    b  2  5\n",
      "    c  3  6\n",
      "    >>> pd.read_hdf('data.h5', 's')\n",
      "    0    1\n",
      "    1    2\n",
      "    2    3\n",
      "    3    4\n",
      "    dtype: int64\n",
      "    \n",
      "    Deleting file with data:\n",
      "    \n",
      "    >>> import os\n",
      "    >>> os.remove('data.h5')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(df.to_hdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "485a71a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_hdf('./output/foo.h5', 'df')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5a0373",
   "metadata": {},
   "source": [
    "读取 **HDF5 Store**："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "15df2b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-01</th>\n",
       "      <td>-1.167799</td>\n",
       "      <td>0.738410</td>\n",
       "      <td>-1.672759</td>\n",
       "      <td>0.015277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-02</th>\n",
       "      <td>-2.724309</td>\n",
       "      <td>0.632798</td>\n",
       "      <td>-0.636592</td>\n",
       "      <td>-0.681891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>-3.703608</td>\n",
       "      <td>1.061687</td>\n",
       "      <td>0.681637</td>\n",
       "      <td>-1.339778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>-2.927774</td>\n",
       "      <td>1.389132</td>\n",
       "      <td>0.400533</td>\n",
       "      <td>-0.593600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>-2.345763</td>\n",
       "      <td>-1.160127</td>\n",
       "      <td>0.042910</td>\n",
       "      <td>0.139708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-22</th>\n",
       "      <td>39.464274</td>\n",
       "      <td>-27.807296</td>\n",
       "      <td>25.223890</td>\n",
       "      <td>-6.409600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-23</th>\n",
       "      <td>40.930645</td>\n",
       "      <td>-28.886537</td>\n",
       "      <td>23.734247</td>\n",
       "      <td>-9.226805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-24</th>\n",
       "      <td>41.084929</td>\n",
       "      <td>-27.327071</td>\n",
       "      <td>23.358181</td>\n",
       "      <td>-9.834518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-25</th>\n",
       "      <td>40.744915</td>\n",
       "      <td>-25.252634</td>\n",
       "      <td>22.224009</td>\n",
       "      <td>-9.500594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-26</th>\n",
       "      <td>40.393599</td>\n",
       "      <td>-25.562739</td>\n",
       "      <td>22.057440</td>\n",
       "      <td>-8.915915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    A          B          C         D\n",
       "2000-01-01  -1.167799   0.738410  -1.672759  0.015277\n",
       "2000-01-02  -2.724309   0.632798  -0.636592 -0.681891\n",
       "2000-01-03  -3.703608   1.061687   0.681637 -1.339778\n",
       "2000-01-04  -2.927774   1.389132   0.400533 -0.593600\n",
       "2000-01-05  -2.345763  -1.160127   0.042910  0.139708\n",
       "...               ...        ...        ...       ...\n",
       "2002-09-22  39.464274 -27.807296  25.223890 -6.409600\n",
       "2002-09-23  40.930645 -28.886537  23.734247 -9.226805\n",
       "2002-09-24  41.084929 -27.327071  23.358181 -9.834518\n",
       "2002-09-25  40.744915 -25.252634  22.224009 -9.500594\n",
       "2002-09-26  40.393599 -25.562739  22.057440 -8.915915\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_hdf('./output/foo.h5', 'df')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10785160",
   "metadata": {},
   "source": [
    "### Excel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c97aece",
   "metadata": {},
   "source": [
    "写入 **Excel** 文件："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ba4a1ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('./output/foo.xlsx', sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df48377",
   "metadata": {},
   "source": [
    "读取 **Excel** 文件："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "16aaa56d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>-1.167799</td>\n",
       "      <td>0.738410</td>\n",
       "      <td>-1.672759</td>\n",
       "      <td>0.015277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-02</td>\n",
       "      <td>-2.724309</td>\n",
       "      <td>0.632798</td>\n",
       "      <td>-0.636592</td>\n",
       "      <td>-0.681891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>-3.703608</td>\n",
       "      <td>1.061687</td>\n",
       "      <td>0.681637</td>\n",
       "      <td>-1.339778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>-2.927774</td>\n",
       "      <td>1.389132</td>\n",
       "      <td>0.400533</td>\n",
       "      <td>-0.593600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>-2.345763</td>\n",
       "      <td>-1.160127</td>\n",
       "      <td>0.042910</td>\n",
       "      <td>0.139708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2002-09-22</td>\n",
       "      <td>39.464274</td>\n",
       "      <td>-27.807296</td>\n",
       "      <td>25.223890</td>\n",
       "      <td>-6.409600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2002-09-23</td>\n",
       "      <td>40.930645</td>\n",
       "      <td>-28.886537</td>\n",
       "      <td>23.734247</td>\n",
       "      <td>-9.226805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2002-09-24</td>\n",
       "      <td>41.084929</td>\n",
       "      <td>-27.327071</td>\n",
       "      <td>23.358181</td>\n",
       "      <td>-9.834518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2002-09-25</td>\n",
       "      <td>40.744915</td>\n",
       "      <td>-25.252634</td>\n",
       "      <td>22.224009</td>\n",
       "      <td>-9.500594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2002-09-26</td>\n",
       "      <td>40.393599</td>\n",
       "      <td>-25.562739</td>\n",
       "      <td>22.057440</td>\n",
       "      <td>-8.915915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0          A          B          C         D\n",
       "0   2000-01-01  -1.167799   0.738410  -1.672759  0.015277\n",
       "1   2000-01-02  -2.724309   0.632798  -0.636592 -0.681891\n",
       "2   2000-01-03  -3.703608   1.061687   0.681637 -1.339778\n",
       "3   2000-01-04  -2.927774   1.389132   0.400533 -0.593600\n",
       "4   2000-01-05  -2.345763  -1.160127   0.042910  0.139708\n",
       "..         ...        ...        ...        ...       ...\n",
       "995 2002-09-22  39.464274 -27.807296  25.223890 -6.409600\n",
       "996 2002-09-23  40.930645 -28.886537  23.734247 -9.226805\n",
       "997 2002-09-24  41.084929 -27.327071  23.358181 -9.834518\n",
       "998 2002-09-25  40.744915 -25.252634  22.224009 -9.500594\n",
       "999 2002-09-26  40.393599 -25.562739  22.057440 -8.915915\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_excel('./output/foo.xlsx', 'Sheet1', index_col=None, na_values=['NA'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750671b3",
   "metadata": {},
   "source": [
    "## 各种坑（Gotchas）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf1b6b8",
   "metadata": {},
   "source": [
    "执行某些操作，将**触发异常**，如:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5cb4e8c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12316/2648304181.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"I was true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1535\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1537\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1538\u001b[0m             \u001b[0;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m             \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "if pd.Series([False, True, False]):\n",
    "    print(\"I was true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c048ccdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1     True\n",
       "2    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series([False, True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f24bd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
